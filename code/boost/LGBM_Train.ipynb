{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    },
    "id": "Uq_TJqbdhfQu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_callback 수정 \n",
    "from typing import TYPE_CHECKING, Callable\n",
    "import wandb\n",
    "from wandb.sdk.lib import telemetry as wb_telemetry\n",
    "\n",
    "MINIMIZE_METRICS = [\n",
    "    \"l1\",\n",
    "    \"l2\",\n",
    "    \"rmse\",\n",
    "    \"mape\",\n",
    "    \"huber\",\n",
    "    \"fair\",\n",
    "    \"poisson\",\n",
    "    \"gamma\",\n",
    "    \"binary_logloss\",\n",
    "]\n",
    "\n",
    "MAXIMIZE_METRICS = [\"map\", \"auc\", \"average_precision\"]\n",
    "\n",
    "def _define_metric(data: str, metric_name: str) -> None:\n",
    "    \n",
    "    \"\"\"Capture model performance at the best step.\n",
    "\n",
    "    instead of the last step, of training in your `wandb.summary`\n",
    "    \"\"\"\n",
    "    if \"loss\" in str.lower(metric_name):\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "    elif str.lower(metric_name) in MINIMIZE_METRICS:\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "    elif str.lower(metric_name) in MAXIMIZE_METRICS:\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"max\")\n",
    "        \n",
    "def wandb_callback(log_params: bool = True, define_metric: bool = True) -> Callable:\n",
    "    \"\"\"Automatically integrates LightGBM with wandb.\n",
    "\n",
    "    Arguments:\n",
    "        log_params: (boolean) if True (default) logs params passed to lightgbm.train as W&B config\n",
    "        define_metric: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`\n",
    "\n",
    "    Passing `wandb_callback` to LightGBM will:\n",
    "      - log params passed to lightgbm.train as W&B config (default).\n",
    "      - log evaluation metrics collected by LightGBM, such as rmse, accuracy etc to Weights & Biases\n",
    "      - Capture the best metric in `wandb.summary` when `define_metric=True` (default).\n",
    "\n",
    "    Use `log_summary` as an extension of this callback.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            .\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()])\n",
    "        ```\n",
    "    \"\"\"\n",
    "    log_params_list: \"List[bool]\" = [log_params]\n",
    "    define_metric_list: \"List[bool]\" = [define_metric]\n",
    "\n",
    "    def _init(env: \"CallbackEnv\") -> None:\n",
    "        with wb_telemetry.context() as tel:\n",
    "            tel.feature.lightgbm_wandb_callback = True\n",
    "\n",
    "        wandb.config.update(env.params)\n",
    "        log_params_list[0] = False\n",
    "\n",
    "        if define_metric_list[0]:\n",
    "            for i in range(len(env.evaluation_result_list)):\n",
    "                data_type = env.evaluation_result_list[i][0]\n",
    "                metric_name = env.evaluation_result_list[i][1]\n",
    "                _define_metric(data_type, metric_name)\n",
    "\n",
    "    def _callback(env: \"CallbackEnv\") -> None:\n",
    "        if log_params_list[0]:\n",
    "            _init(env)\n",
    "        # eval_results: \"Dict[str, Dict[str, List[Any]]]\" = {}\n",
    "        # recorder = lightgbm.record_evaluation(eval_results)\n",
    "        # recorder(env)\n",
    "        eval_results = {x[0]:{x[1:][0]:x[1:][1:]} for x in env.evaluation_result_list}\n",
    "\n",
    "        for validation_key in eval_results.keys():\n",
    "            for key in eval_results[validation_key].keys():\n",
    "                 wandb.log(\n",
    "                     {validation_key + \"_\" + key: eval_results[validation_key][key][0]},\n",
    "                     commit=False,\n",
    "                 )\n",
    "        for item in eval_results:\n",
    "            if len(item) == 4:\n",
    "                wandb.log({f\"{item[0]}_{item[1]}\": item[2]}, commit=False)\n",
    "\n",
    "        # Previous log statements use commit=False. This commits them.\n",
    "        wandb.log({\"iteration\": env.iteration}, commit=True)\n",
    "\n",
    "    return _callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZlm5HSmhfQv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    },
    "id": "s6qgJ8MLhfQw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#경로에 맞게 수정\n",
    "#X=pd.read_parquet('/data/ephemeral/level2-dkt-recsys-06/data/train_ppd_final_sfcv.parquet')\n",
    "#test=pd.read_parquet('/data/ephemeral/level2-dkt-recsys-06/data/test_ppd_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/ephemeral/level2-dkt-recsys-06/data/' # 경로는 상황에 맞춰서 수정해주세요!\n",
    "csv_file_path = os.path.join(data_dir, 'combined_train.csv') \n",
    "\n",
    "X = pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_v4_1.csv')\n",
    "test =  pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_Test_v4_1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y=X[\"answerCode\"]\n",
    "g=X[\"userID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat=[ 'userID','assessmentItemID','testId','KnowledgeTag',\n",
    "       'SolvingTime','CumulativeTime',\n",
    "       'Month','DayOfWeek','TimeOfDay',\n",
    "       'problems_cumulative','problems_last7days','problems_last30days',\n",
    "       'CumulativeUserProblemAnswerRate','CumulativeProblemCount',\n",
    "       'ProblemAnswerRate','TagAnswerRate','CumulativeUserTagAnswerRate','TestAnswerRate',\n",
    "       'categorize_solvingTime','categorize_ProblemAnswerRate','categorize_TagAnswerRate','categorize_TestAnswerRate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:816qoywj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>228</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-music-18</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/816qoywj' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/816qoywj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_211517-816qoywj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:816qoywj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240119_212957-i7hakdgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/i7hakdgv' target=\"_blank\">floral-gorge-19</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/i7hakdgv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/i7hakdgv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322873, number of negative: 697897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3596\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020770, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "[1]\ttraining's auc: 0.815758\tvalid_1's auc: 0.779584\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.818951\tvalid_1's auc: 0.783728\n",
      "[3]\ttraining's auc: 0.823073\tvalid_1's auc: 0.785622\n",
      "[4]\ttraining's auc: 0.824396\tvalid_1's auc: 0.786497\n",
      "[5]\ttraining's auc: 0.825577\tvalid_1's auc: 0.788166\n",
      "[6]\ttraining's auc: 0.826326\tvalid_1's auc: 0.788244\n",
      "[7]\ttraining's auc: 0.82718\tvalid_1's auc: 0.788858\n",
      "[8]\ttraining's auc: 0.827549\tvalid_1's auc: 0.789922\n",
      "[9]\ttraining's auc: 0.82827\tvalid_1's auc: 0.79072\n",
      "[10]\ttraining's auc: 0.828963\tvalid_1's auc: 0.791688\n",
      "[11]\ttraining's auc: 0.829468\tvalid_1's auc: 0.792005\n",
      "[12]\ttraining's auc: 0.830111\tvalid_1's auc: 0.791723\n",
      "[13]\ttraining's auc: 0.830634\tvalid_1's auc: 0.79214\n",
      "[14]\ttraining's auc: 0.831122\tvalid_1's auc: 0.792197\n",
      "[15]\ttraining's auc: 0.83158\tvalid_1's auc: 0.792486\n",
      "[16]\ttraining's auc: 0.832064\tvalid_1's auc: 0.793204\n",
      "[17]\ttraining's auc: 0.832411\tvalid_1's auc: 0.793364\n",
      "[18]\ttraining's auc: 0.832879\tvalid_1's auc: 0.793614\n",
      "[19]\ttraining's auc: 0.833258\tvalid_1's auc: 0.794009\n",
      "[20]\ttraining's auc: 0.833679\tvalid_1's auc: 0.794087\n",
      "[21]\ttraining's auc: 0.834001\tvalid_1's auc: 0.793836\n",
      "[22]\ttraining's auc: 0.834311\tvalid_1's auc: 0.794151\n",
      "[23]\ttraining's auc: 0.834652\tvalid_1's auc: 0.794498\n",
      "[24]\ttraining's auc: 0.834952\tvalid_1's auc: 0.794744\n",
      "[25]\ttraining's auc: 0.835306\tvalid_1's auc: 0.795102\n",
      "[26]\ttraining's auc: 0.835635\tvalid_1's auc: 0.79523\n",
      "[27]\ttraining's auc: 0.835904\tvalid_1's auc: 0.795346\n",
      "[28]\ttraining's auc: 0.836207\tvalid_1's auc: 0.79551\n",
      "[29]\ttraining's auc: 0.836475\tvalid_1's auc: 0.795333\n",
      "[30]\ttraining's auc: 0.836718\tvalid_1's auc: 0.795554\n",
      "[31]\ttraining's auc: 0.836975\tvalid_1's auc: 0.79536\n",
      "[32]\ttraining's auc: 0.83723\tvalid_1's auc: 0.795499\n",
      "[33]\ttraining's auc: 0.837465\tvalid_1's auc: 0.795551\n",
      "[34]\ttraining's auc: 0.8377\tvalid_1's auc: 0.795484\n",
      "[35]\ttraining's auc: 0.837938\tvalid_1's auc: 0.795594\n",
      "[36]\ttraining's auc: 0.838172\tvalid_1's auc: 0.795779\n",
      "[37]\ttraining's auc: 0.838376\tvalid_1's auc: 0.795848\n",
      "[38]\ttraining's auc: 0.83857\tvalid_1's auc: 0.795824\n",
      "[39]\ttraining's auc: 0.838748\tvalid_1's auc: 0.795938\n",
      "[40]\ttraining's auc: 0.838911\tvalid_1's auc: 0.795813\n",
      "[41]\ttraining's auc: 0.83909\tvalid_1's auc: 0.795998\n",
      "[42]\ttraining's auc: 0.839255\tvalid_1's auc: 0.795874\n",
      "[43]\ttraining's auc: 0.839429\tvalid_1's auc: 0.795819\n",
      "[44]\ttraining's auc: 0.839593\tvalid_1's auc: 0.795934\n",
      "[45]\ttraining's auc: 0.83973\tvalid_1's auc: 0.795926\n",
      "[46]\ttraining's auc: 0.83988\tvalid_1's auc: 0.795985\n",
      "[47]\ttraining's auc: 0.840048\tvalid_1's auc: 0.796001\n",
      "[48]\ttraining's auc: 0.840221\tvalid_1's auc: 0.796088\n",
      "[49]\ttraining's auc: 0.840351\tvalid_1's auc: 0.796255\n",
      "[50]\ttraining's auc: 0.840481\tvalid_1's auc: 0.796608\n",
      "[51]\ttraining's auc: 0.840638\tvalid_1's auc: 0.796537\n",
      "[52]\ttraining's auc: 0.840756\tvalid_1's auc: 0.796685\n",
      "[53]\ttraining's auc: 0.840881\tvalid_1's auc: 0.796747\n",
      "[54]\ttraining's auc: 0.841022\tvalid_1's auc: 0.79689\n",
      "[55]\ttraining's auc: 0.841161\tvalid_1's auc: 0.79692\n",
      "[56]\ttraining's auc: 0.841287\tvalid_1's auc: 0.796851\n",
      "[57]\ttraining's auc: 0.841412\tvalid_1's auc: 0.796972\n",
      "[58]\ttraining's auc: 0.841512\tvalid_1's auc: 0.796917\n",
      "[59]\ttraining's auc: 0.841627\tvalid_1's auc: 0.796991\n",
      "[60]\ttraining's auc: 0.841743\tvalid_1's auc: 0.797034\n",
      "[61]\ttraining's auc: 0.841872\tvalid_1's auc: 0.797018\n",
      "[62]\ttraining's auc: 0.841981\tvalid_1's auc: 0.796874\n",
      "[63]\ttraining's auc: 0.842097\tvalid_1's auc: 0.796851\n",
      "[64]\ttraining's auc: 0.842209\tvalid_1's auc: 0.796762\n",
      "[65]\ttraining's auc: 0.842319\tvalid_1's auc: 0.796762\n",
      "[66]\ttraining's auc: 0.842423\tvalid_1's auc: 0.796817\n",
      "[67]\ttraining's auc: 0.842513\tvalid_1's auc: 0.796799\n",
      "[68]\ttraining's auc: 0.84261\tvalid_1's auc: 0.796902\n",
      "[69]\ttraining's auc: 0.842717\tvalid_1's auc: 0.796879\n",
      "[70]\ttraining's auc: 0.842815\tvalid_1's auc: 0.796975\n",
      "[71]\ttraining's auc: 0.842894\tvalid_1's auc: 0.797075\n",
      "[72]\ttraining's auc: 0.842967\tvalid_1's auc: 0.797043\n",
      "[73]\ttraining's auc: 0.843059\tvalid_1's auc: 0.797025\n",
      "[74]\ttraining's auc: 0.843146\tvalid_1's auc: 0.797092\n",
      "[75]\ttraining's auc: 0.84323\tvalid_1's auc: 0.797032\n",
      "[76]\ttraining's auc: 0.843314\tvalid_1's auc: 0.796995\n",
      "[77]\ttraining's auc: 0.843406\tvalid_1's auc: 0.797041\n",
      "[78]\ttraining's auc: 0.843489\tvalid_1's auc: 0.796963\n",
      "[79]\ttraining's auc: 0.843562\tvalid_1's auc: 0.796959\n",
      "[80]\ttraining's auc: 0.843656\tvalid_1's auc: 0.797114\n",
      "[81]\ttraining's auc: 0.843727\tvalid_1's auc: 0.797101\n",
      "[82]\ttraining's auc: 0.843804\tvalid_1's auc: 0.797032\n",
      "[83]\ttraining's auc: 0.8439\tvalid_1's auc: 0.797163\n",
      "[84]\ttraining's auc: 0.843992\tvalid_1's auc: 0.797163\n",
      "[85]\ttraining's auc: 0.844056\tvalid_1's auc: 0.797204\n",
      "[86]\ttraining's auc: 0.844131\tvalid_1's auc: 0.797176\n",
      "[87]\ttraining's auc: 0.84419\tvalid_1's auc: 0.797144\n",
      "[88]\ttraining's auc: 0.844262\tvalid_1's auc: 0.797236\n",
      "[89]\ttraining's auc: 0.844327\tvalid_1's auc: 0.797165\n",
      "[90]\ttraining's auc: 0.844391\tvalid_1's auc: 0.797206\n",
      "[91]\ttraining's auc: 0.84446\tvalid_1's auc: 0.797103\n",
      "[92]\ttraining's auc: 0.84451\tvalid_1's auc: 0.797258\n",
      "[93]\ttraining's auc: 0.844556\tvalid_1's auc: 0.79732\n",
      "[94]\ttraining's auc: 0.844632\tvalid_1's auc: 0.7974\n",
      "[95]\ttraining's auc: 0.844678\tvalid_1's auc: 0.797307\n",
      "[96]\ttraining's auc: 0.84474\tvalid_1's auc: 0.797172\n",
      "[97]\ttraining's auc: 0.844799\tvalid_1's auc: 0.797222\n",
      "[98]\ttraining's auc: 0.844855\tvalid_1's auc: 0.797206\n",
      "[99]\ttraining's auc: 0.844905\tvalid_1's auc: 0.797226\n",
      "[100]\ttraining's auc: 0.844969\tvalid_1's auc: 0.797213\n",
      "[101]\ttraining's auc: 0.845031\tvalid_1's auc: 0.797201\n",
      "[102]\ttraining's auc: 0.845082\tvalid_1's auc: 0.797247\n",
      "[103]\ttraining's auc: 0.845135\tvalid_1's auc: 0.797149\n",
      "[104]\ttraining's auc: 0.845196\tvalid_1's auc: 0.79719\n",
      "[105]\ttraining's auc: 0.845265\tvalid_1's auc: 0.797252\n",
      "[106]\ttraining's auc: 0.845331\tvalid_1's auc: 0.7973\n",
      "[107]\ttraining's auc: 0.845381\tvalid_1's auc: 0.797377\n",
      "[108]\ttraining's auc: 0.845433\tvalid_1's auc: 0.797339\n",
      "[109]\ttraining's auc: 0.845483\tvalid_1's auc: 0.797172\n",
      "[110]\ttraining's auc: 0.845539\tvalid_1's auc: 0.797195\n",
      "[111]\ttraining's auc: 0.845589\tvalid_1's auc: 0.797318\n",
      "[112]\ttraining's auc: 0.845635\tvalid_1's auc: 0.797437\n",
      "[113]\ttraining's auc: 0.845679\tvalid_1's auc: 0.797561\n",
      "[114]\ttraining's auc: 0.845721\tvalid_1's auc: 0.797569\n",
      "[115]\ttraining's auc: 0.845762\tvalid_1's auc: 0.79757\n",
      "[116]\ttraining's auc: 0.845815\tvalid_1's auc: 0.797584\n",
      "[117]\ttraining's auc: 0.845853\tvalid_1's auc: 0.797554\n",
      "[118]\ttraining's auc: 0.845897\tvalid_1's auc: 0.797462\n",
      "[119]\ttraining's auc: 0.845945\tvalid_1's auc: 0.797551\n",
      "[120]\ttraining's auc: 0.845967\tvalid_1's auc: 0.797569\n",
      "[121]\ttraining's auc: 0.846009\tvalid_1's auc: 0.797503\n",
      "[122]\ttraining's auc: 0.846044\tvalid_1's auc: 0.797588\n",
      "[123]\ttraining's auc: 0.846084\tvalid_1's auc: 0.797581\n",
      "[124]\ttraining's auc: 0.846144\tvalid_1's auc: 0.79773\n",
      "[125]\ttraining's auc: 0.846199\tvalid_1's auc: 0.797803\n",
      "[126]\ttraining's auc: 0.846231\tvalid_1's auc: 0.797778\n",
      "[127]\ttraining's auc: 0.846285\tvalid_1's auc: 0.797688\n",
      "[128]\ttraining's auc: 0.846335\tvalid_1's auc: 0.797791\n",
      "[129]\ttraining's auc: 0.846371\tvalid_1's auc: 0.797778\n",
      "[130]\ttraining's auc: 0.846413\tvalid_1's auc: 0.797769\n",
      "[131]\ttraining's auc: 0.846453\tvalid_1's auc: 0.797792\n",
      "[132]\ttraining's auc: 0.84648\tvalid_1's auc: 0.797835\n",
      "[133]\ttraining's auc: 0.846527\tvalid_1's auc: 0.79787\n",
      "[134]\ttraining's auc: 0.846563\tvalid_1's auc: 0.798036\n",
      "[135]\ttraining's auc: 0.846595\tvalid_1's auc: 0.798057\n",
      "[136]\ttraining's auc: 0.846629\tvalid_1's auc: 0.798036\n",
      "[137]\ttraining's auc: 0.846665\tvalid_1's auc: 0.798109\n",
      "[138]\ttraining's auc: 0.846709\tvalid_1's auc: 0.798101\n",
      "[139]\ttraining's auc: 0.846752\tvalid_1's auc: 0.798238\n",
      "[140]\ttraining's auc: 0.846789\tvalid_1's auc: 0.79822\n",
      "[141]\ttraining's auc: 0.846829\tvalid_1's auc: 0.798242\n",
      "[142]\ttraining's auc: 0.846869\tvalid_1's auc: 0.79845\n",
      "[143]\ttraining's auc: 0.846912\tvalid_1's auc: 0.798389\n",
      "[144]\ttraining's auc: 0.846953\tvalid_1's auc: 0.798432\n",
      "[145]\ttraining's auc: 0.846984\tvalid_1's auc: 0.798446\n",
      "[146]\ttraining's auc: 0.847033\tvalid_1's auc: 0.798389\n",
      "[147]\ttraining's auc: 0.847064\tvalid_1's auc: 0.798379\n",
      "[148]\ttraining's auc: 0.847099\tvalid_1's auc: 0.798373\n",
      "[149]\ttraining's auc: 0.847114\tvalid_1's auc: 0.798309\n",
      "[150]\ttraining's auc: 0.847148\tvalid_1's auc: 0.798345\n",
      "[151]\ttraining's auc: 0.847171\tvalid_1's auc: 0.798306\n",
      "[152]\ttraining's auc: 0.8472\tvalid_1's auc: 0.798281\n",
      "[153]\ttraining's auc: 0.847233\tvalid_1's auc: 0.798251\n",
      "[154]\ttraining's auc: 0.84726\tvalid_1's auc: 0.798283\n",
      "[155]\ttraining's auc: 0.847292\tvalid_1's auc: 0.798316\n",
      "[156]\ttraining's auc: 0.847346\tvalid_1's auc: 0.798274\n",
      "[157]\ttraining's auc: 0.847381\tvalid_1's auc: 0.798334\n",
      "[158]\ttraining's auc: 0.847424\tvalid_1's auc: 0.798291\n",
      "[159]\ttraining's auc: 0.847444\tvalid_1's auc: 0.798258\n",
      "[160]\ttraining's auc: 0.847473\tvalid_1's auc: 0.798347\n",
      "[161]\ttraining's auc: 0.847518\tvalid_1's auc: 0.798379\n",
      "[162]\ttraining's auc: 0.847562\tvalid_1's auc: 0.798453\n",
      "[163]\ttraining's auc: 0.847589\tvalid_1's auc: 0.798453\n",
      "[164]\ttraining's auc: 0.847658\tvalid_1's auc: 0.798444\n",
      "[165]\ttraining's auc: 0.847708\tvalid_1's auc: 0.798482\n",
      "[166]\ttraining's auc: 0.847747\tvalid_1's auc: 0.798418\n",
      "[167]\ttraining's auc: 0.847764\tvalid_1's auc: 0.798421\n",
      "[168]\ttraining's auc: 0.847785\tvalid_1's auc: 0.798446\n",
      "[169]\ttraining's auc: 0.847824\tvalid_1's auc: 0.798597\n",
      "[170]\ttraining's auc: 0.847849\tvalid_1's auc: 0.798615\n",
      "[171]\ttraining's auc: 0.84788\tvalid_1's auc: 0.798455\n",
      "[172]\ttraining's auc: 0.847908\tvalid_1's auc: 0.798528\n",
      "[173]\ttraining's auc: 0.847931\tvalid_1's auc: 0.798544\n",
      "[174]\ttraining's auc: 0.847972\tvalid_1's auc: 0.798538\n",
      "[175]\ttraining's auc: 0.848006\tvalid_1's auc: 0.7984\n",
      "[176]\ttraining's auc: 0.848018\tvalid_1's auc: 0.7984\n",
      "[177]\ttraining's auc: 0.848054\tvalid_1's auc: 0.798554\n",
      "[178]\ttraining's auc: 0.848087\tvalid_1's auc: 0.798593\n",
      "[179]\ttraining's auc: 0.848138\tvalid_1's auc: 0.798567\n",
      "[180]\ttraining's auc: 0.848148\tvalid_1's auc: 0.798567\n",
      "[181]\ttraining's auc: 0.848173\tvalid_1's auc: 0.798553\n",
      "[182]\ttraining's auc: 0.848202\tvalid_1's auc: 0.798636\n",
      "[183]\ttraining's auc: 0.848223\tvalid_1's auc: 0.798679\n",
      "[184]\ttraining's auc: 0.848249\tvalid_1's auc: 0.798663\n",
      "[185]\ttraining's auc: 0.848298\tvalid_1's auc: 0.798663\n",
      "[186]\ttraining's auc: 0.848347\tvalid_1's auc: 0.798641\n",
      "[187]\ttraining's auc: 0.848385\tvalid_1's auc: 0.798645\n",
      "[188]\ttraining's auc: 0.848404\tvalid_1's auc: 0.79864\n",
      "[189]\ttraining's auc: 0.848419\tvalid_1's auc: 0.79864\n",
      "[190]\ttraining's auc: 0.848448\tvalid_1's auc: 0.798665\n",
      "[191]\ttraining's auc: 0.848482\tvalid_1's auc: 0.79864\n",
      "[192]\ttraining's auc: 0.848527\tvalid_1's auc: 0.798769\n",
      "[193]\ttraining's auc: 0.848571\tvalid_1's auc: 0.798776\n",
      "[194]\ttraining's auc: 0.848585\tvalid_1's auc: 0.798782\n",
      "[195]\ttraining's auc: 0.848641\tvalid_1's auc: 0.798752\n",
      "[196]\ttraining's auc: 0.848669\tvalid_1's auc: 0.798734\n",
      "[197]\ttraining's auc: 0.8487\tvalid_1's auc: 0.798739\n",
      "[198]\ttraining's auc: 0.84875\tvalid_1's auc: 0.798716\n",
      "[199]\ttraining's auc: 0.848786\tvalid_1's auc: 0.798764\n",
      "[200]\ttraining's auc: 0.848809\tvalid_1's auc: 0.798805\n",
      "[201]\ttraining's auc: 0.848833\tvalid_1's auc: 0.798805\n",
      "[202]\ttraining's auc: 0.848861\tvalid_1's auc: 0.798645\n",
      "[203]\ttraining's auc: 0.848873\tvalid_1's auc: 0.798645\n",
      "[204]\ttraining's auc: 0.848921\tvalid_1's auc: 0.798723\n",
      "[205]\ttraining's auc: 0.848932\tvalid_1's auc: 0.798737\n",
      "[206]\ttraining's auc: 0.84895\tvalid_1's auc: 0.798711\n",
      "[207]\ttraining's auc: 0.848976\tvalid_1's auc: 0.798702\n",
      "[208]\ttraining's auc: 0.84899\tvalid_1's auc: 0.798817\n",
      "[209]\ttraining's auc: 0.849015\tvalid_1's auc: 0.79883\n",
      "[210]\ttraining's auc: 0.849039\tvalid_1's auc: 0.798784\n",
      "[211]\ttraining's auc: 0.849059\tvalid_1's auc: 0.798734\n",
      "[212]\ttraining's auc: 0.849097\tvalid_1's auc: 0.798672\n",
      "[213]\ttraining's auc: 0.84914\tvalid_1's auc: 0.798705\n",
      "[214]\ttraining's auc: 0.849168\tvalid_1's auc: 0.798284\n",
      "[215]\ttraining's auc: 0.849192\tvalid_1's auc: 0.798251\n",
      "[216]\ttraining's auc: 0.849205\tvalid_1's auc: 0.798254\n",
      "[217]\ttraining's auc: 0.84923\tvalid_1's auc: 0.798327\n",
      "[218]\ttraining's auc: 0.849256\tvalid_1's auc: 0.798371\n",
      "[219]\ttraining's auc: 0.849291\tvalid_1's auc: 0.798423\n",
      "[220]\ttraining's auc: 0.849313\tvalid_1's auc: 0.798421\n",
      "[221]\ttraining's auc: 0.849325\tvalid_1's auc: 0.798416\n",
      "[222]\ttraining's auc: 0.84934\tvalid_1's auc: 0.798402\n",
      "[223]\ttraining's auc: 0.849347\tvalid_1's auc: 0.798402\n",
      "[224]\ttraining's auc: 0.849378\tvalid_1's auc: 0.798348\n",
      "[225]\ttraining's auc: 0.849425\tvalid_1's auc: 0.79837\n",
      "[226]\ttraining's auc: 0.84946\tvalid_1's auc: 0.798425\n",
      "[227]\ttraining's auc: 0.849476\tvalid_1's auc: 0.798446\n",
      "[228]\ttraining's auc: 0.849492\tvalid_1's auc: 0.798467\n",
      "[229]\ttraining's auc: 0.849511\tvalid_1's auc: 0.798402\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's auc: 0.849015\tvalid_1's auc: 0.79883\n",
      "Fold 0 VALID AUC : 0.7988297278957484 ACC : 0.7265469061876247\n",
      "\n",
      "Fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:i7hakdgv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>228</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-gorge-19</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/i7hakdgv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/i7hakdgv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_212957-i7hakdgv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:i7hakdgv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240119_213059-6nhv9okt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/6nhv9okt' target=\"_blank\">sunny-terrain-20</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/6nhv9okt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/6nhv9okt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322899, number of negative: 697890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3600\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020789, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654645 -> initscore=0.639519\n",
      "[LightGBM] [Info] Start training from score 0.639519\n",
      "[1]\ttraining's auc: 0.815787\tvalid_1's auc: 0.777028\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.820279\tvalid_1's auc: 0.785055\n",
      "[3]\ttraining's auc: 0.8234\tvalid_1's auc: 0.787929\n",
      "[4]\ttraining's auc: 0.824691\tvalid_1's auc: 0.790848\n",
      "[5]\ttraining's auc: 0.82617\tvalid_1's auc: 0.792507\n",
      "[6]\ttraining's auc: 0.826795\tvalid_1's auc: 0.793412\n",
      "[7]\ttraining's auc: 0.8277\tvalid_1's auc: 0.794527\n",
      "[8]\ttraining's auc: 0.827978\tvalid_1's auc: 0.794628\n",
      "[9]\ttraining's auc: 0.82867\tvalid_1's auc: 0.796228\n",
      "[10]\ttraining's auc: 0.829233\tvalid_1's auc: 0.796305\n",
      "[11]\ttraining's auc: 0.829995\tvalid_1's auc: 0.796972\n",
      "[12]\ttraining's auc: 0.830568\tvalid_1's auc: 0.797162\n",
      "[13]\ttraining's auc: 0.831058\tvalid_1's auc: 0.797915\n",
      "[14]\ttraining's auc: 0.831534\tvalid_1's auc: 0.79836\n",
      "[15]\ttraining's auc: 0.831968\tvalid_1's auc: 0.799239\n",
      "[16]\ttraining's auc: 0.832468\tvalid_1's auc: 0.799305\n",
      "[17]\ttraining's auc: 0.832935\tvalid_1's auc: 0.799907\n",
      "[18]\ttraining's auc: 0.833387\tvalid_1's auc: 0.800232\n",
      "[19]\ttraining's auc: 0.833796\tvalid_1's auc: 0.800128\n",
      "[20]\ttraining's auc: 0.834164\tvalid_1's auc: 0.800316\n",
      "[21]\ttraining's auc: 0.834521\tvalid_1's auc: 0.800822\n",
      "[22]\ttraining's auc: 0.834869\tvalid_1's auc: 0.800677\n",
      "[23]\ttraining's auc: 0.835197\tvalid_1's auc: 0.800768\n",
      "[24]\ttraining's auc: 0.83553\tvalid_1's auc: 0.800912\n",
      "[25]\ttraining's auc: 0.835835\tvalid_1's auc: 0.801109\n",
      "[26]\ttraining's auc: 0.83615\tvalid_1's auc: 0.80186\n",
      "[27]\ttraining's auc: 0.836453\tvalid_1's auc: 0.802081\n",
      "[28]\ttraining's auc: 0.836751\tvalid_1's auc: 0.802086\n",
      "[29]\ttraining's auc: 0.837039\tvalid_1's auc: 0.802381\n",
      "[30]\ttraining's auc: 0.837315\tvalid_1's auc: 0.802264\n",
      "[31]\ttraining's auc: 0.83756\tvalid_1's auc: 0.802424\n",
      "[32]\ttraining's auc: 0.837825\tvalid_1's auc: 0.802613\n",
      "[33]\ttraining's auc: 0.838051\tvalid_1's auc: 0.802902\n",
      "[34]\ttraining's auc: 0.838258\tvalid_1's auc: 0.803051\n",
      "[35]\ttraining's auc: 0.838486\tvalid_1's auc: 0.803152\n",
      "[36]\ttraining's auc: 0.838694\tvalid_1's auc: 0.803248\n",
      "[37]\ttraining's auc: 0.838899\tvalid_1's auc: 0.80338\n",
      "[38]\ttraining's auc: 0.839089\tvalid_1's auc: 0.803658\n",
      "[39]\ttraining's auc: 0.839313\tvalid_1's auc: 0.803717\n",
      "[40]\ttraining's auc: 0.839502\tvalid_1's auc: 0.803945\n",
      "[41]\ttraining's auc: 0.83968\tvalid_1's auc: 0.804098\n",
      "[42]\ttraining's auc: 0.839891\tvalid_1's auc: 0.804333\n",
      "[43]\ttraining's auc: 0.840052\tvalid_1's auc: 0.804556\n",
      "[44]\ttraining's auc: 0.840219\tvalid_1's auc: 0.804616\n",
      "[45]\ttraining's auc: 0.840396\tvalid_1's auc: 0.804901\n",
      "[46]\ttraining's auc: 0.840548\tvalid_1's auc: 0.805256\n",
      "[47]\ttraining's auc: 0.840713\tvalid_1's auc: 0.805529\n",
      "[48]\ttraining's auc: 0.840862\tvalid_1's auc: 0.80551\n",
      "[49]\ttraining's auc: 0.841015\tvalid_1's auc: 0.805547\n",
      "[50]\ttraining's auc: 0.841164\tvalid_1's auc: 0.8055\n",
      "[51]\ttraining's auc: 0.841293\tvalid_1's auc: 0.805568\n",
      "[52]\ttraining's auc: 0.841436\tvalid_1's auc: 0.805801\n",
      "[53]\ttraining's auc: 0.841577\tvalid_1's auc: 0.805744\n",
      "[54]\ttraining's auc: 0.841697\tvalid_1's auc: 0.805498\n",
      "[55]\ttraining's auc: 0.841813\tvalid_1's auc: 0.805776\n",
      "[56]\ttraining's auc: 0.841904\tvalid_1's auc: 0.805852\n",
      "[57]\ttraining's auc: 0.842022\tvalid_1's auc: 0.805829\n",
      "[58]\ttraining's auc: 0.84216\tvalid_1's auc: 0.806035\n",
      "[59]\ttraining's auc: 0.842293\tvalid_1's auc: 0.806056\n",
      "[60]\ttraining's auc: 0.842396\tvalid_1's auc: 0.806029\n",
      "[61]\ttraining's auc: 0.842521\tvalid_1's auc: 0.80619\n",
      "[62]\ttraining's auc: 0.842626\tvalid_1's auc: 0.806379\n",
      "[63]\ttraining's auc: 0.842727\tvalid_1's auc: 0.806303\n",
      "[64]\ttraining's auc: 0.84283\tvalid_1's auc: 0.806341\n",
      "[65]\ttraining's auc: 0.842938\tvalid_1's auc: 0.806394\n",
      "[66]\ttraining's auc: 0.843048\tvalid_1's auc: 0.806481\n",
      "[67]\ttraining's auc: 0.843126\tvalid_1's auc: 0.80636\n",
      "[68]\ttraining's auc: 0.843229\tvalid_1's auc: 0.80657\n",
      "[69]\ttraining's auc: 0.843317\tvalid_1's auc: 0.806897\n",
      "[70]\ttraining's auc: 0.843411\tvalid_1's auc: 0.807027\n",
      "[71]\ttraining's auc: 0.843507\tvalid_1's auc: 0.807085\n",
      "[72]\ttraining's auc: 0.843608\tvalid_1's auc: 0.807057\n",
      "[73]\ttraining's auc: 0.843711\tvalid_1's auc: 0.807065\n",
      "[74]\ttraining's auc: 0.843796\tvalid_1's auc: 0.807167\n",
      "[75]\ttraining's auc: 0.843889\tvalid_1's auc: 0.80729\n",
      "[76]\ttraining's auc: 0.843973\tvalid_1's auc: 0.807435\n",
      "[77]\ttraining's auc: 0.844064\tvalid_1's auc: 0.807541\n",
      "[78]\ttraining's auc: 0.844147\tvalid_1's auc: 0.807424\n",
      "[79]\ttraining's auc: 0.844222\tvalid_1's auc: 0.807543\n",
      "[80]\ttraining's auc: 0.844304\tvalid_1's auc: 0.807531\n",
      "[81]\ttraining's auc: 0.844373\tvalid_1's auc: 0.807497\n",
      "[82]\ttraining's auc: 0.844457\tvalid_1's auc: 0.807815\n",
      "[83]\ttraining's auc: 0.844518\tvalid_1's auc: 0.807822\n",
      "[84]\ttraining's auc: 0.844587\tvalid_1's auc: 0.807769\n",
      "[85]\ttraining's auc: 0.844654\tvalid_1's auc: 0.807681\n",
      "[86]\ttraining's auc: 0.844744\tvalid_1's auc: 0.807639\n",
      "[87]\ttraining's auc: 0.844803\tvalid_1's auc: 0.8077\n",
      "[88]\ttraining's auc: 0.844861\tvalid_1's auc: 0.807673\n",
      "[89]\ttraining's auc: 0.844922\tvalid_1's auc: 0.807745\n",
      "[90]\ttraining's auc: 0.844992\tvalid_1's auc: 0.807796\n",
      "[91]\ttraining's auc: 0.84507\tvalid_1's auc: 0.807805\n",
      "[92]\ttraining's auc: 0.845133\tvalid_1's auc: 0.807843\n",
      "[93]\ttraining's auc: 0.845189\tvalid_1's auc: 0.80786\n",
      "[94]\ttraining's auc: 0.845272\tvalid_1's auc: 0.807858\n",
      "[95]\ttraining's auc: 0.845338\tvalid_1's auc: 0.807777\n",
      "[96]\ttraining's auc: 0.845398\tvalid_1's auc: 0.807771\n",
      "[97]\ttraining's auc: 0.845465\tvalid_1's auc: 0.807834\n",
      "[98]\ttraining's auc: 0.845522\tvalid_1's auc: 0.807858\n",
      "[99]\ttraining's auc: 0.845588\tvalid_1's auc: 0.807847\n",
      "[100]\ttraining's auc: 0.845661\tvalid_1's auc: 0.807889\n",
      "[101]\ttraining's auc: 0.84571\tvalid_1's auc: 0.807855\n",
      "[102]\ttraining's auc: 0.845752\tvalid_1's auc: 0.807875\n",
      "[103]\ttraining's auc: 0.845801\tvalid_1's auc: 0.808125\n",
      "[104]\ttraining's auc: 0.845867\tvalid_1's auc: 0.808198\n",
      "[105]\ttraining's auc: 0.84593\tvalid_1's auc: 0.808164\n",
      "[106]\ttraining's auc: 0.846015\tvalid_1's auc: 0.808179\n",
      "[107]\ttraining's auc: 0.846064\tvalid_1's auc: 0.808217\n",
      "[108]\ttraining's auc: 0.846105\tvalid_1's auc: 0.808234\n",
      "[109]\ttraining's auc: 0.846162\tvalid_1's auc: 0.808179\n",
      "[110]\ttraining's auc: 0.846214\tvalid_1's auc: 0.80827\n",
      "[111]\ttraining's auc: 0.846286\tvalid_1's auc: 0.808104\n",
      "[112]\ttraining's auc: 0.846339\tvalid_1's auc: 0.808091\n",
      "[113]\ttraining's auc: 0.846389\tvalid_1's auc: 0.808145\n",
      "[114]\ttraining's auc: 0.84644\tvalid_1's auc: 0.808098\n",
      "[115]\ttraining's auc: 0.846485\tvalid_1's auc: 0.808147\n",
      "[116]\ttraining's auc: 0.846528\tvalid_1's auc: 0.808249\n",
      "[117]\ttraining's auc: 0.846575\tvalid_1's auc: 0.808259\n",
      "[118]\ttraining's auc: 0.846656\tvalid_1's auc: 0.808266\n",
      "[119]\ttraining's auc: 0.8467\tvalid_1's auc: 0.808259\n",
      "[120]\ttraining's auc: 0.846743\tvalid_1's auc: 0.80827\n",
      "[121]\ttraining's auc: 0.846805\tvalid_1's auc: 0.808293\n",
      "[122]\ttraining's auc: 0.846866\tvalid_1's auc: 0.808198\n",
      "[123]\ttraining's auc: 0.8469\tvalid_1's auc: 0.808225\n",
      "[124]\ttraining's auc: 0.846935\tvalid_1's auc: 0.808223\n",
      "[125]\ttraining's auc: 0.846972\tvalid_1's auc: 0.808263\n",
      "[126]\ttraining's auc: 0.847009\tvalid_1's auc: 0.808248\n",
      "[127]\ttraining's auc: 0.847057\tvalid_1's auc: 0.808304\n",
      "[128]\ttraining's auc: 0.847109\tvalid_1's auc: 0.808342\n",
      "[129]\ttraining's auc: 0.847143\tvalid_1's auc: 0.808306\n",
      "[130]\ttraining's auc: 0.847194\tvalid_1's auc: 0.808176\n",
      "[131]\ttraining's auc: 0.847233\tvalid_1's auc: 0.808346\n",
      "[132]\ttraining's auc: 0.847281\tvalid_1's auc: 0.808384\n",
      "[133]\ttraining's auc: 0.847309\tvalid_1's auc: 0.808459\n",
      "[134]\ttraining's auc: 0.847356\tvalid_1's auc: 0.80837\n",
      "[135]\ttraining's auc: 0.847398\tvalid_1's auc: 0.808395\n",
      "[136]\ttraining's auc: 0.847441\tvalid_1's auc: 0.808453\n",
      "[137]\ttraining's auc: 0.847472\tvalid_1's auc: 0.808453\n",
      "[138]\ttraining's auc: 0.8475\tvalid_1's auc: 0.808482\n",
      "[139]\ttraining's auc: 0.847544\tvalid_1's auc: 0.808467\n",
      "[140]\ttraining's auc: 0.847587\tvalid_1's auc: 0.808529\n",
      "[141]\ttraining's auc: 0.847645\tvalid_1's auc: 0.808521\n",
      "[142]\ttraining's auc: 0.847686\tvalid_1's auc: 0.808574\n",
      "[143]\ttraining's auc: 0.847717\tvalid_1's auc: 0.808567\n",
      "[144]\ttraining's auc: 0.847768\tvalid_1's auc: 0.808595\n",
      "[145]\ttraining's auc: 0.847789\tvalid_1's auc: 0.808552\n",
      "[146]\ttraining's auc: 0.847825\tvalid_1's auc: 0.808529\n",
      "[147]\ttraining's auc: 0.84787\tvalid_1's auc: 0.808535\n",
      "[148]\ttraining's auc: 0.847908\tvalid_1's auc: 0.808578\n",
      "[149]\ttraining's auc: 0.847976\tvalid_1's auc: 0.808608\n",
      "[150]\ttraining's auc: 0.848011\tvalid_1's auc: 0.80861\n",
      "[151]\ttraining's auc: 0.848042\tvalid_1's auc: 0.808597\n",
      "[152]\ttraining's auc: 0.84807\tvalid_1's auc: 0.808612\n",
      "[153]\ttraining's auc: 0.848122\tvalid_1's auc: 0.80862\n",
      "[154]\ttraining's auc: 0.84816\tvalid_1's auc: 0.808661\n",
      "[155]\ttraining's auc: 0.848189\tvalid_1's auc: 0.808605\n",
      "[156]\ttraining's auc: 0.84822\tvalid_1's auc: 0.808478\n",
      "[157]\ttraining's auc: 0.848249\tvalid_1's auc: 0.808465\n",
      "[158]\ttraining's auc: 0.848281\tvalid_1's auc: 0.808627\n",
      "[159]\ttraining's auc: 0.848317\tvalid_1's auc: 0.808652\n",
      "[160]\ttraining's auc: 0.848358\tvalid_1's auc: 0.808726\n",
      "[161]\ttraining's auc: 0.848408\tvalid_1's auc: 0.808862\n",
      "[162]\ttraining's auc: 0.848449\tvalid_1's auc: 0.808828\n",
      "[163]\ttraining's auc: 0.848481\tvalid_1's auc: 0.808786\n",
      "[164]\ttraining's auc: 0.848495\tvalid_1's auc: 0.808797\n",
      "[165]\ttraining's auc: 0.848534\tvalid_1's auc: 0.808767\n",
      "[166]\ttraining's auc: 0.848558\tvalid_1's auc: 0.808835\n",
      "[167]\ttraining's auc: 0.848603\tvalid_1's auc: 0.808828\n",
      "[168]\ttraining's auc: 0.848653\tvalid_1's auc: 0.808879\n",
      "[169]\ttraining's auc: 0.848697\tvalid_1's auc: 0.808748\n",
      "[170]\ttraining's auc: 0.84871\tvalid_1's auc: 0.808714\n",
      "[171]\ttraining's auc: 0.848757\tvalid_1's auc: 0.808737\n",
      "[172]\ttraining's auc: 0.84878\tvalid_1's auc: 0.808846\n",
      "[173]\ttraining's auc: 0.848803\tvalid_1's auc: 0.808769\n",
      "[174]\ttraining's auc: 0.848825\tvalid_1's auc: 0.808769\n",
      "[175]\ttraining's auc: 0.848862\tvalid_1's auc: 0.80882\n",
      "[176]\ttraining's auc: 0.848909\tvalid_1's auc: 0.808816\n",
      "[177]\ttraining's auc: 0.848942\tvalid_1's auc: 0.808724\n",
      "[178]\ttraining's auc: 0.848984\tvalid_1's auc: 0.808809\n",
      "[179]\ttraining's auc: 0.849025\tvalid_1's auc: 0.80882\n",
      "[180]\ttraining's auc: 0.849041\tvalid_1's auc: 0.808778\n",
      "[181]\ttraining's auc: 0.849066\tvalid_1's auc: 0.808811\n",
      "[182]\ttraining's auc: 0.849108\tvalid_1's auc: 0.80875\n",
      "[183]\ttraining's auc: 0.84913\tvalid_1's auc: 0.80872\n",
      "[184]\ttraining's auc: 0.849159\tvalid_1's auc: 0.808782\n",
      "[185]\ttraining's auc: 0.849186\tvalid_1's auc: 0.808682\n",
      "[186]\ttraining's auc: 0.849203\tvalid_1's auc: 0.808576\n",
      "[187]\ttraining's auc: 0.849235\tvalid_1's auc: 0.808593\n",
      "[188]\ttraining's auc: 0.849277\tvalid_1's auc: 0.808795\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's auc: 0.848653\tvalid_1's auc: 0.808879\n",
      "Fold 1 VALID AUC : 0.8088786017949929 ACC : 0.7285223367697594\n",
      "\n",
      "Fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6nhv9okt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-terrain-20</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/6nhv9okt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/6nhv9okt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_213059-6nhv9okt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6nhv9okt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240119_213147-4ylzd6mo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/4ylzd6mo' target=\"_blank\">toasty-spaceship-21</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/4ylzd6mo' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/4ylzd6mo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322856, number of negative: 697893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3602\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020749, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654636 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.816293\tvalid_1's auc: 0.782047\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.820871\tvalid_1's auc: 0.789558\n",
      "[3]\ttraining's auc: 0.823669\tvalid_1's auc: 0.793849\n",
      "[4]\ttraining's auc: 0.824753\tvalid_1's auc: 0.795022\n",
      "[5]\ttraining's auc: 0.826014\tvalid_1's auc: 0.796207\n",
      "[6]\ttraining's auc: 0.827253\tvalid_1's auc: 0.796942\n",
      "[7]\ttraining's auc: 0.827971\tvalid_1's auc: 0.797555\n",
      "[8]\ttraining's auc: 0.828619\tvalid_1's auc: 0.798408\n",
      "[9]\ttraining's auc: 0.829165\tvalid_1's auc: 0.798467\n",
      "[10]\ttraining's auc: 0.82976\tvalid_1's auc: 0.798481\n",
      "[11]\ttraining's auc: 0.830467\tvalid_1's auc: 0.798427\n",
      "[12]\ttraining's auc: 0.831111\tvalid_1's auc: 0.799288\n",
      "[13]\ttraining's auc: 0.831659\tvalid_1's auc: 0.799799\n",
      "[14]\ttraining's auc: 0.832146\tvalid_1's auc: 0.800522\n",
      "[15]\ttraining's auc: 0.832559\tvalid_1's auc: 0.800499\n",
      "[16]\ttraining's auc: 0.832931\tvalid_1's auc: 0.800749\n",
      "[17]\ttraining's auc: 0.833321\tvalid_1's auc: 0.801073\n",
      "[18]\ttraining's auc: 0.833684\tvalid_1's auc: 0.801489\n",
      "[19]\ttraining's auc: 0.834129\tvalid_1's auc: 0.801747\n",
      "[20]\ttraining's auc: 0.83451\tvalid_1's auc: 0.801721\n",
      "[21]\ttraining's auc: 0.834904\tvalid_1's auc: 0.801663\n",
      "[22]\ttraining's auc: 0.835216\tvalid_1's auc: 0.802165\n",
      "[23]\ttraining's auc: 0.835562\tvalid_1's auc: 0.80236\n",
      "[24]\ttraining's auc: 0.835875\tvalid_1's auc: 0.802425\n",
      "[25]\ttraining's auc: 0.836191\tvalid_1's auc: 0.802408\n",
      "[26]\ttraining's auc: 0.836469\tvalid_1's auc: 0.802616\n",
      "[27]\ttraining's auc: 0.836759\tvalid_1's auc: 0.802793\n",
      "[28]\ttraining's auc: 0.837082\tvalid_1's auc: 0.802755\n",
      "[29]\ttraining's auc: 0.837338\tvalid_1's auc: 0.802772\n",
      "[30]\ttraining's auc: 0.837626\tvalid_1's auc: 0.802754\n",
      "[31]\ttraining's auc: 0.837869\tvalid_1's auc: 0.802738\n",
      "[32]\ttraining's auc: 0.838107\tvalid_1's auc: 0.802821\n",
      "[33]\ttraining's auc: 0.838329\tvalid_1's auc: 0.802745\n",
      "[34]\ttraining's auc: 0.838549\tvalid_1's auc: 0.802542\n",
      "[35]\ttraining's auc: 0.838782\tvalid_1's auc: 0.802625\n",
      "[36]\ttraining's auc: 0.838996\tvalid_1's auc: 0.802679\n",
      "[37]\ttraining's auc: 0.839214\tvalid_1's auc: 0.803001\n",
      "[38]\ttraining's auc: 0.839416\tvalid_1's auc: 0.803075\n",
      "[39]\ttraining's auc: 0.839617\tvalid_1's auc: 0.803096\n",
      "[40]\ttraining's auc: 0.839809\tvalid_1's auc: 0.803082\n",
      "[41]\ttraining's auc: 0.83999\tvalid_1's auc: 0.803141\n",
      "[42]\ttraining's auc: 0.840175\tvalid_1's auc: 0.803179\n",
      "[43]\ttraining's auc: 0.840358\tvalid_1's auc: 0.803245\n",
      "[44]\ttraining's auc: 0.84053\tvalid_1's auc: 0.803368\n",
      "[45]\ttraining's auc: 0.8407\tvalid_1's auc: 0.803232\n",
      "[46]\ttraining's auc: 0.840862\tvalid_1's auc: 0.803428\n",
      "[47]\ttraining's auc: 0.841014\tvalid_1's auc: 0.80366\n",
      "[48]\ttraining's auc: 0.841167\tvalid_1's auc: 0.803813\n",
      "[49]\ttraining's auc: 0.841316\tvalid_1's auc: 0.803911\n",
      "[50]\ttraining's auc: 0.841461\tvalid_1's auc: 0.803857\n",
      "[51]\ttraining's auc: 0.841615\tvalid_1's auc: 0.803955\n",
      "[52]\ttraining's auc: 0.841756\tvalid_1's auc: 0.803907\n",
      "[53]\ttraining's auc: 0.841897\tvalid_1's auc: 0.804062\n",
      "[54]\ttraining's auc: 0.842051\tvalid_1's auc: 0.804096\n",
      "[55]\ttraining's auc: 0.84218\tvalid_1's auc: 0.804142\n",
      "[56]\ttraining's auc: 0.8423\tvalid_1's auc: 0.80418\n",
      "[57]\ttraining's auc: 0.842404\tvalid_1's auc: 0.80421\n",
      "[58]\ttraining's auc: 0.84253\tvalid_1's auc: 0.804044\n",
      "[59]\ttraining's auc: 0.842658\tvalid_1's auc: 0.804014\n",
      "[60]\ttraining's auc: 0.842786\tvalid_1's auc: 0.80405\n",
      "[61]\ttraining's auc: 0.842895\tvalid_1's auc: 0.804098\n",
      "[62]\ttraining's auc: 0.842998\tvalid_1's auc: 0.804092\n",
      "[63]\ttraining's auc: 0.84309\tvalid_1's auc: 0.804034\n",
      "[64]\ttraining's auc: 0.843184\tvalid_1's auc: 0.804149\n",
      "[65]\ttraining's auc: 0.843273\tvalid_1's auc: 0.804114\n",
      "[66]\ttraining's auc: 0.843372\tvalid_1's auc: 0.804001\n",
      "[67]\ttraining's auc: 0.84347\tvalid_1's auc: 0.804001\n",
      "[68]\ttraining's auc: 0.843557\tvalid_1's auc: 0.803977\n",
      "[69]\ttraining's auc: 0.843658\tvalid_1's auc: 0.803891\n",
      "[70]\ttraining's auc: 0.843763\tvalid_1's auc: 0.803911\n",
      "[71]\ttraining's auc: 0.843849\tvalid_1's auc: 0.803859\n",
      "[72]\ttraining's auc: 0.843948\tvalid_1's auc: 0.803873\n",
      "[73]\ttraining's auc: 0.844034\tvalid_1's auc: 0.803871\n",
      "[74]\ttraining's auc: 0.844113\tvalid_1's auc: 0.803854\n",
      "[75]\ttraining's auc: 0.844187\tvalid_1's auc: 0.803871\n",
      "[76]\ttraining's auc: 0.84427\tvalid_1's auc: 0.804021\n",
      "[77]\ttraining's auc: 0.844385\tvalid_1's auc: 0.804144\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.842404\tvalid_1's auc: 0.80421\n",
      "Fold 2 VALID AUC : 0.8042100272017171 ACC : 0.7198132088058706\n",
      "\n",
      "Fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4ylzd6mo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇███▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>76</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-spaceship-21</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/4ylzd6mo' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/4ylzd6mo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_213147-4ylzd6mo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4ylzd6mo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240119_213216-ik6emvzh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/ik6emvzh' target=\"_blank\">earnest-water-22</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/ik6emvzh' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/ik6emvzh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322858, number of negative: 697894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3598\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020752, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654636 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.815499\tvalid_1's auc: 0.77696\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.820063\tvalid_1's auc: 0.784062\n",
      "[3]\ttraining's auc: 0.823078\tvalid_1's auc: 0.787882\n",
      "[4]\ttraining's auc: 0.824626\tvalid_1's auc: 0.791972\n",
      "[5]\ttraining's auc: 0.825682\tvalid_1's auc: 0.792895\n",
      "[6]\ttraining's auc: 0.826469\tvalid_1's auc: 0.79535\n",
      "[7]\ttraining's auc: 0.827045\tvalid_1's auc: 0.795121\n",
      "[8]\ttraining's auc: 0.827699\tvalid_1's auc: 0.795758\n",
      "[9]\ttraining's auc: 0.828318\tvalid_1's auc: 0.795888\n",
      "[10]\ttraining's auc: 0.829015\tvalid_1's auc: 0.797033\n",
      "[11]\ttraining's auc: 0.82966\tvalid_1's auc: 0.797833\n",
      "[12]\ttraining's auc: 0.830216\tvalid_1's auc: 0.798823\n",
      "[13]\ttraining's auc: 0.830742\tvalid_1's auc: 0.799392\n",
      "[14]\ttraining's auc: 0.831295\tvalid_1's auc: 0.800432\n",
      "[15]\ttraining's auc: 0.831881\tvalid_1's auc: 0.800364\n",
      "[16]\ttraining's auc: 0.832236\tvalid_1's auc: 0.800834\n",
      "[17]\ttraining's auc: 0.832605\tvalid_1's auc: 0.800718\n",
      "[18]\ttraining's auc: 0.833077\tvalid_1's auc: 0.801464\n",
      "[19]\ttraining's auc: 0.833522\tvalid_1's auc: 0.801513\n",
      "[20]\ttraining's auc: 0.833878\tvalid_1's auc: 0.801434\n",
      "[21]\ttraining's auc: 0.834205\tvalid_1's auc: 0.801795\n",
      "[22]\ttraining's auc: 0.834608\tvalid_1's auc: 0.802306\n",
      "[23]\ttraining's auc: 0.834925\tvalid_1's auc: 0.802438\n",
      "[24]\ttraining's auc: 0.835265\tvalid_1's auc: 0.802445\n",
      "[25]\ttraining's auc: 0.835623\tvalid_1's auc: 0.802677\n",
      "[26]\ttraining's auc: 0.83593\tvalid_1's auc: 0.803083\n",
      "[27]\ttraining's auc: 0.836233\tvalid_1's auc: 0.803325\n",
      "[28]\ttraining's auc: 0.836521\tvalid_1's auc: 0.80348\n",
      "[29]\ttraining's auc: 0.836845\tvalid_1's auc: 0.803664\n",
      "[30]\ttraining's auc: 0.83712\tvalid_1's auc: 0.803373\n",
      "[31]\ttraining's auc: 0.837377\tvalid_1's auc: 0.803677\n",
      "[32]\ttraining's auc: 0.837603\tvalid_1's auc: 0.803853\n",
      "[33]\ttraining's auc: 0.837845\tvalid_1's auc: 0.804231\n",
      "[34]\ttraining's auc: 0.838086\tvalid_1's auc: 0.804145\n",
      "[35]\ttraining's auc: 0.838285\tvalid_1's auc: 0.803981\n",
      "[36]\ttraining's auc: 0.838489\tvalid_1's auc: 0.804191\n",
      "[37]\ttraining's auc: 0.838707\tvalid_1's auc: 0.804393\n",
      "[38]\ttraining's auc: 0.83891\tvalid_1's auc: 0.804377\n",
      "[39]\ttraining's auc: 0.839122\tvalid_1's auc: 0.804535\n",
      "[40]\ttraining's auc: 0.839296\tvalid_1's auc: 0.80489\n",
      "[41]\ttraining's auc: 0.839493\tvalid_1's auc: 0.80504\n",
      "[42]\ttraining's auc: 0.839657\tvalid_1's auc: 0.805009\n",
      "[43]\ttraining's auc: 0.839833\tvalid_1's auc: 0.804997\n",
      "[44]\ttraining's auc: 0.839981\tvalid_1's auc: 0.804793\n",
      "[45]\ttraining's auc: 0.840149\tvalid_1's auc: 0.804901\n",
      "[46]\ttraining's auc: 0.840299\tvalid_1's auc: 0.805064\n",
      "[47]\ttraining's auc: 0.84047\tvalid_1's auc: 0.805181\n",
      "[48]\ttraining's auc: 0.840638\tvalid_1's auc: 0.805299\n",
      "[49]\ttraining's auc: 0.840793\tvalid_1's auc: 0.805315\n",
      "[50]\ttraining's auc: 0.840928\tvalid_1's auc: 0.80539\n",
      "[51]\ttraining's auc: 0.841064\tvalid_1's auc: 0.805497\n",
      "[52]\ttraining's auc: 0.841219\tvalid_1's auc: 0.805535\n",
      "[53]\ttraining's auc: 0.84136\tvalid_1's auc: 0.805675\n",
      "[54]\ttraining's auc: 0.841474\tvalid_1's auc: 0.805673\n",
      "[55]\ttraining's auc: 0.841592\tvalid_1's auc: 0.805749\n",
      "[56]\ttraining's auc: 0.841722\tvalid_1's auc: 0.805688\n",
      "[57]\ttraining's auc: 0.841836\tvalid_1's auc: 0.805643\n",
      "[58]\ttraining's auc: 0.841962\tvalid_1's auc: 0.805452\n",
      "[59]\ttraining's auc: 0.842067\tvalid_1's auc: 0.80556\n",
      "[60]\ttraining's auc: 0.842183\tvalid_1's auc: 0.805434\n",
      "[61]\ttraining's auc: 0.842285\tvalid_1's auc: 0.805235\n",
      "[62]\ttraining's auc: 0.842386\tvalid_1's auc: 0.805403\n",
      "[63]\ttraining's auc: 0.842492\tvalid_1's auc: 0.805439\n",
      "[64]\ttraining's auc: 0.842603\tvalid_1's auc: 0.805628\n",
      "[65]\ttraining's auc: 0.842694\tvalid_1's auc: 0.805645\n",
      "[66]\ttraining's auc: 0.842787\tvalid_1's auc: 0.805744\n",
      "[67]\ttraining's auc: 0.842897\tvalid_1's auc: 0.805906\n",
      "[68]\ttraining's auc: 0.84299\tvalid_1's auc: 0.805964\n",
      "[69]\ttraining's auc: 0.843087\tvalid_1's auc: 0.806009\n",
      "[70]\ttraining's auc: 0.843183\tvalid_1's auc: 0.806001\n",
      "[71]\ttraining's auc: 0.843282\tvalid_1's auc: 0.805996\n",
      "[72]\ttraining's auc: 0.843386\tvalid_1's auc: 0.806099\n",
      "[73]\ttraining's auc: 0.843474\tvalid_1's auc: 0.806149\n",
      "[74]\ttraining's auc: 0.843563\tvalid_1's auc: 0.806205\n",
      "[75]\ttraining's auc: 0.843626\tvalid_1's auc: 0.806317\n",
      "[76]\ttraining's auc: 0.843715\tvalid_1's auc: 0.806348\n",
      "[77]\ttraining's auc: 0.843789\tvalid_1's auc: 0.806322\n",
      "[78]\ttraining's auc: 0.843878\tvalid_1's auc: 0.806256\n",
      "[79]\ttraining's auc: 0.843951\tvalid_1's auc: 0.80629\n",
      "[80]\ttraining's auc: 0.844029\tvalid_1's auc: 0.806241\n",
      "[81]\ttraining's auc: 0.844103\tvalid_1's auc: 0.806175\n",
      "[82]\ttraining's auc: 0.844179\tvalid_1's auc: 0.806211\n",
      "[83]\ttraining's auc: 0.844256\tvalid_1's auc: 0.806185\n",
      "[84]\ttraining's auc: 0.844318\tvalid_1's auc: 0.806202\n",
      "[85]\ttraining's auc: 0.84441\tvalid_1's auc: 0.806322\n",
      "[86]\ttraining's auc: 0.844477\tvalid_1's auc: 0.806176\n",
      "[87]\ttraining's auc: 0.844544\tvalid_1's auc: 0.806153\n",
      "[88]\ttraining's auc: 0.844625\tvalid_1's auc: 0.806117\n",
      "[89]\ttraining's auc: 0.844697\tvalid_1's auc: 0.806259\n",
      "[90]\ttraining's auc: 0.844754\tvalid_1's auc: 0.806266\n",
      "[91]\ttraining's auc: 0.84483\tvalid_1's auc: 0.806234\n",
      "[92]\ttraining's auc: 0.844888\tvalid_1's auc: 0.806202\n",
      "[93]\ttraining's auc: 0.84498\tvalid_1's auc: 0.806166\n",
      "[94]\ttraining's auc: 0.845051\tvalid_1's auc: 0.806104\n",
      "[95]\ttraining's auc: 0.845121\tvalid_1's auc: 0.806164\n",
      "[96]\ttraining's auc: 0.845196\tvalid_1's auc: 0.806302\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's auc: 0.843715\tvalid_1's auc: 0.806348\n",
      "Fold 3 VALID AUC : 0.8063475413145312 ACC : 0.7261744966442953\n",
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ik6emvzh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>valid_1_auc</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>95</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-water-22</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/ik6emvzh' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/ik6emvzh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240119_213216-ik6emvzh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ik6emvzh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240119_213250-gu2aqg67</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/gu2aqg67' target=\"_blank\">celestial-fog-23</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/LGBM/runs/gu2aqg67' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/LGBM/runs/gu2aqg67</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322866, number of negative: 697898\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3599\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654637 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.816828\tvalid_1's auc: 0.785699\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.820004\tvalid_1's auc: 0.792052\n",
      "[3]\ttraining's auc: 0.822402\tvalid_1's auc: 0.792518\n",
      "[4]\ttraining's auc: 0.824578\tvalid_1's auc: 0.795087\n",
      "[5]\ttraining's auc: 0.825708\tvalid_1's auc: 0.794851\n",
      "[6]\ttraining's auc: 0.826849\tvalid_1's auc: 0.795204\n",
      "[7]\ttraining's auc: 0.82776\tvalid_1's auc: 0.795136\n",
      "[8]\ttraining's auc: 0.828289\tvalid_1's auc: 0.795257\n",
      "[9]\ttraining's auc: 0.829018\tvalid_1's auc: 0.796147\n",
      "[10]\ttraining's auc: 0.829569\tvalid_1's auc: 0.79567\n",
      "[11]\ttraining's auc: 0.830145\tvalid_1's auc: 0.795398\n",
      "[12]\ttraining's auc: 0.83076\tvalid_1's auc: 0.79673\n",
      "[13]\ttraining's auc: 0.831331\tvalid_1's auc: 0.79664\n",
      "[14]\ttraining's auc: 0.831797\tvalid_1's auc: 0.797408\n",
      "[15]\ttraining's auc: 0.832228\tvalid_1's auc: 0.797829\n",
      "[16]\ttraining's auc: 0.832717\tvalid_1's auc: 0.798389\n",
      "[17]\ttraining's auc: 0.833229\tvalid_1's auc: 0.798987\n",
      "[18]\ttraining's auc: 0.833564\tvalid_1's auc: 0.79954\n",
      "[19]\ttraining's auc: 0.833913\tvalid_1's auc: 0.799957\n",
      "[20]\ttraining's auc: 0.834299\tvalid_1's auc: 0.800166\n",
      "[21]\ttraining's auc: 0.834652\tvalid_1's auc: 0.800812\n",
      "[22]\ttraining's auc: 0.835007\tvalid_1's auc: 0.801196\n",
      "[23]\ttraining's auc: 0.835367\tvalid_1's auc: 0.801648\n",
      "[24]\ttraining's auc: 0.835691\tvalid_1's auc: 0.802037\n",
      "[25]\ttraining's auc: 0.835997\tvalid_1's auc: 0.802155\n",
      "[26]\ttraining's auc: 0.83632\tvalid_1's auc: 0.80242\n",
      "[27]\ttraining's auc: 0.836651\tvalid_1's auc: 0.802796\n",
      "[28]\ttraining's auc: 0.83693\tvalid_1's auc: 0.80294\n",
      "[29]\ttraining's auc: 0.837188\tvalid_1's auc: 0.802891\n",
      "[30]\ttraining's auc: 0.837447\tvalid_1's auc: 0.803207\n",
      "[31]\ttraining's auc: 0.837693\tvalid_1's auc: 0.803413\n",
      "[32]\ttraining's auc: 0.83792\tvalid_1's auc: 0.803672\n",
      "[33]\ttraining's auc: 0.838139\tvalid_1's auc: 0.804213\n",
      "[34]\ttraining's auc: 0.838369\tvalid_1's auc: 0.804557\n",
      "[35]\ttraining's auc: 0.838568\tvalid_1's auc: 0.804766\n",
      "[36]\ttraining's auc: 0.838781\tvalid_1's auc: 0.804926\n",
      "[37]\ttraining's auc: 0.83902\tvalid_1's auc: 0.805063\n",
      "[38]\ttraining's auc: 0.839222\tvalid_1's auc: 0.805251\n",
      "[39]\ttraining's auc: 0.839421\tvalid_1's auc: 0.805511\n",
      "[40]\ttraining's auc: 0.839617\tvalid_1's auc: 0.805678\n",
      "[41]\ttraining's auc: 0.839803\tvalid_1's auc: 0.805821\n",
      "[42]\ttraining's auc: 0.839984\tvalid_1's auc: 0.805744\n",
      "[43]\ttraining's auc: 0.84017\tvalid_1's auc: 0.806176\n",
      "[44]\ttraining's auc: 0.840337\tvalid_1's auc: 0.806185\n",
      "[45]\ttraining's auc: 0.84049\tvalid_1's auc: 0.80626\n",
      "[46]\ttraining's auc: 0.840653\tvalid_1's auc: 0.806532\n",
      "[47]\ttraining's auc: 0.840789\tvalid_1's auc: 0.806676\n",
      "[48]\ttraining's auc: 0.840943\tvalid_1's auc: 0.806744\n",
      "[49]\ttraining's auc: 0.841096\tvalid_1's auc: 0.806984\n",
      "[50]\ttraining's auc: 0.841231\tvalid_1's auc: 0.807026\n",
      "[51]\ttraining's auc: 0.841356\tvalid_1's auc: 0.807193\n",
      "[52]\ttraining's auc: 0.841503\tvalid_1's auc: 0.807322\n",
      "[53]\ttraining's auc: 0.841642\tvalid_1's auc: 0.807551\n",
      "[54]\ttraining's auc: 0.841787\tvalid_1's auc: 0.807544\n",
      "[55]\ttraining's auc: 0.841922\tvalid_1's auc: 0.807565\n",
      "[56]\ttraining's auc: 0.842055\tvalid_1's auc: 0.807895\n",
      "[57]\ttraining's auc: 0.84217\tvalid_1's auc: 0.807843\n",
      "[58]\ttraining's auc: 0.842311\tvalid_1's auc: 0.807931\n",
      "[59]\ttraining's auc: 0.842443\tvalid_1's auc: 0.808088\n",
      "[60]\ttraining's auc: 0.842567\tvalid_1's auc: 0.808292\n",
      "[61]\ttraining's auc: 0.842663\tvalid_1's auc: 0.808199\n",
      "[62]\ttraining's auc: 0.842771\tvalid_1's auc: 0.808394\n",
      "[63]\ttraining's auc: 0.842871\tvalid_1's auc: 0.808686\n",
      "[64]\ttraining's auc: 0.842964\tvalid_1's auc: 0.808559\n",
      "[65]\ttraining's auc: 0.843064\tvalid_1's auc: 0.808677\n",
      "[66]\ttraining's auc: 0.843177\tvalid_1's auc: 0.808774\n",
      "[67]\ttraining's auc: 0.843278\tvalid_1's auc: 0.808763\n",
      "[68]\ttraining's auc: 0.843382\tvalid_1's auc: 0.808733\n",
      "[69]\ttraining's auc: 0.843461\tvalid_1's auc: 0.808838\n",
      "[70]\ttraining's auc: 0.84355\tvalid_1's auc: 0.808795\n",
      "[71]\ttraining's auc: 0.84364\tvalid_1's auc: 0.80881\n",
      "[72]\ttraining's auc: 0.843734\tvalid_1's auc: 0.808951\n",
      "[73]\ttraining's auc: 0.84384\tvalid_1's auc: 0.808926\n",
      "[74]\ttraining's auc: 0.843925\tvalid_1's auc: 0.80893\n",
      "[75]\ttraining's auc: 0.844\tvalid_1's auc: 0.808878\n",
      "[76]\ttraining's auc: 0.844088\tvalid_1's auc: 0.80889\n",
      "[77]\ttraining's auc: 0.84417\tvalid_1's auc: 0.808897\n",
      "[78]\ttraining's auc: 0.844248\tvalid_1's auc: 0.808833\n",
      "[79]\ttraining's auc: 0.844323\tvalid_1's auc: 0.808835\n",
      "[80]\ttraining's auc: 0.844394\tvalid_1's auc: 0.809032\n",
      "[81]\ttraining's auc: 0.844479\tvalid_1's auc: 0.809023\n",
      "[82]\ttraining's auc: 0.844557\tvalid_1's auc: 0.80916\n",
      "[83]\ttraining's auc: 0.844635\tvalid_1's auc: 0.809128\n",
      "[84]\ttraining's auc: 0.844713\tvalid_1's auc: 0.80932\n",
      "[85]\ttraining's auc: 0.84478\tvalid_1's auc: 0.809318\n",
      "[86]\ttraining's auc: 0.844845\tvalid_1's auc: 0.809427\n",
      "[87]\ttraining's auc: 0.844915\tvalid_1's auc: 0.809474\n",
      "[88]\ttraining's auc: 0.844972\tvalid_1's auc: 0.809463\n",
      "[89]\ttraining's auc: 0.845056\tvalid_1's auc: 0.809366\n",
      "[90]\ttraining's auc: 0.845128\tvalid_1's auc: 0.809504\n",
      "[91]\ttraining's auc: 0.845203\tvalid_1's auc: 0.809459\n",
      "[92]\ttraining's auc: 0.845263\tvalid_1's auc: 0.809576\n",
      "[93]\ttraining's auc: 0.845324\tvalid_1's auc: 0.809549\n",
      "[94]\ttraining's auc: 0.845403\tvalid_1's auc: 0.809527\n",
      "[95]\ttraining's auc: 0.84549\tvalid_1's auc: 0.809488\n",
      "[96]\ttraining's auc: 0.845545\tvalid_1's auc: 0.809604\n",
      "[97]\ttraining's auc: 0.845608\tvalid_1's auc: 0.809587\n",
      "[98]\ttraining's auc: 0.845681\tvalid_1's auc: 0.80961\n",
      "[99]\ttraining's auc: 0.845743\tvalid_1's auc: 0.809615\n",
      "[100]\ttraining's auc: 0.845806\tvalid_1's auc: 0.809707\n",
      "[101]\ttraining's auc: 0.845853\tvalid_1's auc: 0.809683\n",
      "[102]\ttraining's auc: 0.845909\tvalid_1's auc: 0.809617\n",
      "[103]\ttraining's auc: 0.845961\tvalid_1's auc: 0.809493\n",
      "[104]\ttraining's auc: 0.846014\tvalid_1's auc: 0.809495\n",
      "[105]\ttraining's auc: 0.846064\tvalid_1's auc: 0.809513\n",
      "[106]\ttraining's auc: 0.846117\tvalid_1's auc: 0.809452\n",
      "[107]\ttraining's auc: 0.846163\tvalid_1's auc: 0.809524\n",
      "[108]\ttraining's auc: 0.846225\tvalid_1's auc: 0.809596\n",
      "[109]\ttraining's auc: 0.84627\tvalid_1's auc: 0.809601\n",
      "[110]\ttraining's auc: 0.846315\tvalid_1's auc: 0.809597\n",
      "[111]\ttraining's auc: 0.84637\tvalid_1's auc: 0.809538\n",
      "[112]\ttraining's auc: 0.846426\tvalid_1's auc: 0.809644\n",
      "[113]\ttraining's auc: 0.846473\tvalid_1's auc: 0.809805\n",
      "[114]\ttraining's auc: 0.846522\tvalid_1's auc: 0.809775\n",
      "[115]\ttraining's auc: 0.846566\tvalid_1's auc: 0.809771\n",
      "[116]\ttraining's auc: 0.846612\tvalid_1's auc: 0.80976\n",
      "[117]\ttraining's auc: 0.846665\tvalid_1's auc: 0.809771\n",
      "[118]\ttraining's auc: 0.846707\tvalid_1's auc: 0.809631\n",
      "[119]\ttraining's auc: 0.846743\tvalid_1's auc: 0.809601\n",
      "[120]\ttraining's auc: 0.846793\tvalid_1's auc: 0.809619\n",
      "[121]\ttraining's auc: 0.846836\tvalid_1's auc: 0.809714\n",
      "[122]\ttraining's auc: 0.846878\tvalid_1's auc: 0.809719\n",
      "[123]\ttraining's auc: 0.846916\tvalid_1's auc: 0.809649\n",
      "[124]\ttraining's auc: 0.846951\tvalid_1's auc: 0.809608\n",
      "[125]\ttraining's auc: 0.846998\tvalid_1's auc: 0.809553\n",
      "[126]\ttraining's auc: 0.847036\tvalid_1's auc: 0.809558\n",
      "[127]\ttraining's auc: 0.84712\tvalid_1's auc: 0.809556\n",
      "[128]\ttraining's auc: 0.847162\tvalid_1's auc: 0.809665\n",
      "[129]\ttraining's auc: 0.8472\tvalid_1's auc: 0.809653\n",
      "[130]\ttraining's auc: 0.847243\tvalid_1's auc: 0.809637\n",
      "[131]\ttraining's auc: 0.847282\tvalid_1's auc: 0.809646\n",
      "[132]\ttraining's auc: 0.847319\tvalid_1's auc: 0.809569\n",
      "[133]\ttraining's auc: 0.847372\tvalid_1's auc: 0.809581\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's auc: 0.846473\tvalid_1's auc: 0.809805\n",
      "Fold 4 VALID AUC : 0.8098049676497652 ACC : 0.7311036789297659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary', \n",
    "    'metric': ['auc'],\n",
    "    'device': 'cpu'\n",
    "}\n",
    "\n",
    "# LabelEncoder 적용\n",
    "label_encoders = {}\n",
    "for column in ['DayOfWeek', 'TimeOfDay', 'categorize_ProblemAnswerRate', \n",
    "               'categorize_TagAnswerRate', 'categorize_TestAnswerRate']:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    # 테스트 데이터에 대해서는 transform만 적용\n",
    "    test[column] = le.transform(test[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "\n",
    "    \n",
    "n_fold=5\n",
    "sfcv=StratifiedGroupKFold(n_splits=n_fold)\n",
    "oof_auc = np.zeros(n_fold)\n",
    "oof_acc = np.zeros(n_fold)\n",
    "test_preds = np.zeros(len(test))\n",
    "# X = X.drop(columns=['Timestamp'])\n",
    "# test = test.drop(columns=['Timestamp'])\n",
    "for i, (train_idx, val_idx) in enumerate(sfcv.split(X, y, g)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid = X.iloc[val_idx]\n",
    "    X_valid = X_valid[X_valid['userID'] != X_valid['userID'].shift(-1)]\n",
    "    y_valid = X_valid[\"answerCode\"]\n",
    "    # print(X_valid)\n",
    "    # print(y_valid)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train[feat], y_train, categorical_feature=[\"KnowledgeTag\"])\n",
    "    lgb_valid = lgb.Dataset(X_valid[feat], y_valid, categorical_feature=[\"KnowledgeTag\"])\n",
    "    wandb.init(project=\"LGBM\", config=params)\n",
    "    wandb.run.name = f\"fold{i}lgbm\"\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=500,\n",
    "        callbacks=[wandb_callback(), lgb.log_evaluation(), lgb.early_stopping(20)],\n",
    "        categorical_feature=[\"KnowledgeTag\"]\n",
    "    )\n",
    "    preds = model.predict(X_valid[feat])\n",
    "    oof_acc[i] = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    \n",
    "    oof_auc[i] = roc_auc_score(y_valid, preds)\n",
    "    # 'Timestamp' 열이 실제로 test 데이터프레임에서 제거되었는지 확인합니다.\n",
    "    if 'Timestamp' in test.columns:\n",
    "        test = test.drop(columns=['Timestamp'])\n",
    "\n",
    "    # 모델을 사용하여 예측을 수행하기 전에 test 데이터프레임의 컬럼을 확인합니다.\n",
    "    test_features = [col for col in test.columns if col in feat]\n",
    "    # 빈 리스트를 초기화합니다. 예측할 마지막 행의 인덱스를 저장할 것입니다.\n",
    "    last_indices = []\n",
    "    # 예측을 수행합니다.\n",
    "    for uid in test['userID'].unique():\n",
    "    # userID가 uid인 행들 중 마지막 행의 인덱스를 찾습니다.\n",
    "        last_index = test[(test['userID'] == uid) & (test['answerCode'] == -1)].index[-1]\n",
    "        last_indices.append(last_index)\n",
    "\n",
    "    # 예측할 행들만 포함하는 새로운 DataFrame을 생성합니다.\n",
    "    test_last = test.loc[last_indices]\n",
    "    last_preds = model.predict(test_last[test_features])\n",
    "    # 예측을 수행합니다.\n",
    "    # 여기서는 모델이 'answerCode'를 예측하는 데 필요한 모든 피처를 사용하고 있다고 가정합니다.\n",
    "    # test_preds에 해당 userID의 마지막 행의 예측값을 업데이트합니다.\n",
    "    for idx, pred in zip(last_indices, last_preds):\n",
    "        test_preds[idx] += pred / n_fold\n",
    "    # test_preds += model.predict(test_last[test_features]) / n_fold\n",
    "    # test_preds += model.predict(test[test_features]) / n_fold\n",
    "\n",
    "    \n",
    "    print(f'Fold {i} VALID AUC : {oof_auc[i]} ACC : {oof_acc[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.805614173171351, 0.7264321254674632)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_auc), np.mean(oof_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/2024-01-20 06:42:44 lgbm submission.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, datetime.now(timezone(timedelta(hours=9))).strftime(\"%Y-%m-%d %H:%M:%S\")+\" lgbm submission.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(test_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prediction' 값이 0이 아닌 행만 필터링\n",
    "final_df = non_zero_predictions_df.assign(id=non_zero_predictions_df.index)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
