{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    },
    "id": "Uq_TJqbdhfQu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_callback 수정 \n",
    "from typing import TYPE_CHECKING, Callable\n",
    "import wandb\n",
    "from wandb.sdk.lib import telemetry as wb_telemetry\n",
    "\n",
    "MINIMIZE_METRICS = [\n",
    "    \"l1\",\n",
    "    \"l2\",\n",
    "    \"rmse\",\n",
    "    \"mape\",\n",
    "    \"huber\",\n",
    "    \"fair\",\n",
    "    \"poisson\",\n",
    "    \"gamma\",\n",
    "    \"binary_logloss\",\n",
    "]\n",
    "\n",
    "MAXIMIZE_METRICS = [\"map\", \"auc\", \"average_precision\"]\n",
    "        \n",
    "def wandb_callback(log_params=True, define_metric=True) -> Callable:\n",
    "    \"\"\"Automatically integrates LightGBM with wandb.\n",
    "\n",
    "    Arguments:\n",
    "        log_params: (boolean) if True (default) logs params passed to lightgbm.train as W&B config\n",
    "        define_metric: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`\n",
    "\n",
    "    Passing `wandb_callback` to LightGBM will:\n",
    "      - log params passed to lightgbm.train as W&B config (default).\n",
    "      - log evaluation metrics collected by LightGBM, such as rmse, accuracy etc to Weights & Biases\n",
    "      - Capture the best metric in `wandb.summary` when `define_metric=True` (default).\n",
    "\n",
    "    Use `log_summary` as an extension of this callback.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            .\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()])\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def _define_metric(data: str, metric_name: str) -> None:\n",
    "    \n",
    "        \"\"\"Capture model performance at the best step.\n",
    "        instead of the last step, of training in your `wandb.summary`\n",
    "        \"\"\"\n",
    "        if \"loss\" in str.lower(metric_name):\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MINIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MAXIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"max\")\n",
    "            \n",
    "    log_params_list: \"List[bool]\" = [log_params]\n",
    "    define_metric_list: \"List[bool]\" = [define_metric]\n",
    "\n",
    "    def _init(env: \"CallbackEnv\") -> None:\n",
    "        with wb_telemetry.context() as tel:\n",
    "            tel.feature.lightgbm_wandb_callback = True\n",
    "\n",
    "        wandb.config.update(env.params)\n",
    "        log_params_list[0] = False\n",
    "\n",
    "        if define_metric_list[0]:\n",
    "            for i in range(len(env.evaluation_result_list)):\n",
    "                data_type = env.evaluation_result_list[i][0]\n",
    "                metric_name = env.evaluation_result_list[i][1]\n",
    "                _define_metric(data_type, metric_name)\n",
    "\n",
    "    def _callback(env: \"CallbackEnv\") -> None:\n",
    "        if log_params_list[0]:\n",
    "            _init(env)\n",
    "        # eval_results: \"Dict[str, Dict[str, List[Any]]]\" = {}\n",
    "        # recorder = lightgbm.record_evaluation(eval_results)\n",
    "        # recorder(env)\n",
    "        eval_results = {x[0]:{x[1:][0]:x[1:][1:]} for x in env.evaluation_result_list}\n",
    "\n",
    "        for validation_key in eval_results.keys():\n",
    "            for key in eval_results[validation_key].keys():\n",
    "                 wandb.log(\n",
    "                     {validation_key + \"_\" + key: eval_results[validation_key][key][0]},\n",
    "                     commit=False,\n",
    "                 )\n",
    "        for item in eval_results:\n",
    "            if len(item) == 4:\n",
    "                wandb.log({f\"{item[0]}_{item[1]}\": item[2]}, commit=False)\n",
    "\n",
    "        # Previous log statements use commit=False. This commits them.\n",
    "        wandb.log({\"iteration\": env.iteration}, commit=True)\n",
    "\n",
    "    return _callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZlm5HSmhfQv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    },
    "id": "s6qgJ8MLhfQw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: my5wz8qa\n",
      "Sweep URL: https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa\n"
     ]
    }
   ],
   "source": [
    "sweep_config_path = '/data/ephemeral/level2-dkt-recsys-06/code/boost/lgbmsweepconfigv2.yaml'\n",
    "\n",
    "# 노트북의 이름 설정\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'LGBM_Train.ipynb'\n",
    "# YAML 파일 로드\n",
    "with open(sweep_config_path, 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)\n",
    "\n",
    "# W&B 스위프트 설정\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"lightgbm-sweep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525956, 23)\n",
      "(744, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>SolvingTime</th>\n",
       "      <th>CumulativeTime</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>problems_cumulative</th>\n",
       "      <th>...</th>\n",
       "      <th>CumulativeUserProblemAnswerRate</th>\n",
       "      <th>CumulativeProblemCount</th>\n",
       "      <th>ProblemAnswerRate</th>\n",
       "      <th>TagAnswerRate</th>\n",
       "      <th>CumulativeUserTagAnswerRate</th>\n",
       "      <th>TestAnswerRate</th>\n",
       "      <th>categorize_solvingTime</th>\n",
       "      <th>categorize_ProblemAnswerRate</th>\n",
       "      <th>categorize_TagAnswerRate</th>\n",
       "      <th>categorize_TestAnswerRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3</td>\n",
       "      <td>50133008</td>\n",
       "      <td>50133</td>\n",
       "      <td>5289</td>\n",
       "      <td>45</td>\n",
       "      <td>361</td>\n",
       "      <td>10</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1035</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>290</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>81</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>Difficult</td>\n",
       "      <td>Very Difficult</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>4</td>\n",
       "      <td>70146008</td>\n",
       "      <td>70146</td>\n",
       "      <td>9080</td>\n",
       "      <td>24</td>\n",
       "      <td>196</td>\n",
       "      <td>12</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Dawn</td>\n",
       "      <td>670</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>Difficult</td>\n",
       "      <td>Difficult</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>13</td>\n",
       "      <td>70111008</td>\n",
       "      <td>70111</td>\n",
       "      <td>9660</td>\n",
       "      <td>14</td>\n",
       "      <td>118</td>\n",
       "      <td>12</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Dawn</td>\n",
       "      <td>1316</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>Extremely Difficult</td>\n",
       "      <td>Extremely Difficult</td>\n",
       "      <td>Extremely Difficult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>17</td>\n",
       "      <td>90064006</td>\n",
       "      <td>90064</td>\n",
       "      <td>2611</td>\n",
       "      <td>76</td>\n",
       "      <td>456</td>\n",
       "      <td>10</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Dawn</td>\n",
       "      <td>1259</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>624</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>Extremely Difficult</td>\n",
       "      <td>Very Difficult</td>\n",
       "      <td>Difficult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>26</td>\n",
       "      <td>60135007</td>\n",
       "      <td>60135</td>\n",
       "      <td>1422</td>\n",
       "      <td>45</td>\n",
       "      <td>320</td>\n",
       "      <td>10</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>386</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>178</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>Extremely Difficult</td>\n",
       "      <td>Difficult</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  assessmentItemID  testId  KnowledgeTag  SolvingTime  \\\n",
       "1035       3          50133008   50133          5289           45   \n",
       "1706       4          70146008   70146          9080           24   \n",
       "3023      13          70111008   70111          9660           14   \n",
       "4283      17          90064006   90064          2611           76   \n",
       "4670      26          60135007   60135          1422           45   \n",
       "\n",
       "      CumulativeTime  Month DayOfWeek  TimeOfDay  problems_cumulative  ...  \\\n",
       "1035             361     10    Monday  Afternoon                 1035  ...   \n",
       "1706             196     12    Sunday       Dawn                  670  ...   \n",
       "3023             118     12    Sunday       Dawn                 1316  ...   \n",
       "4283             456     10    Friday       Dawn                 1259  ...   \n",
       "4670             320     10    Friday    Morning                  386  ...   \n",
       "\n",
       "      CumulativeUserProblemAnswerRate  CumulativeProblemCount  \\\n",
       "1035                               69                     290   \n",
       "1706                               69                      28   \n",
       "3023                               69                      34   \n",
       "4283                               81                     624   \n",
       "4670                               75                     178   \n",
       "\n",
       "      ProblemAnswerRate  TagAnswerRate  CumulativeUserTagAnswerRate  \\\n",
       "1035                 52             54                           81   \n",
       "1706                 53             56                           66   \n",
       "3023                 31             44                           33   \n",
       "4283                 37             51                          100   \n",
       "4670                 35             60                           66   \n",
       "\n",
       "      TestAnswerRate  categorize_solvingTime  categorize_ProblemAnswerRate  \\\n",
       "1035              66                       6                     Difficult   \n",
       "1706              74                       4                     Difficult   \n",
       "3023              41                       2           Extremely Difficult   \n",
       "4283              62                       7           Extremely Difficult   \n",
       "4670              67                       6           Extremely Difficult   \n",
       "\n",
       "      categorize_TagAnswerRate categorize_TestAnswerRate  \n",
       "1035            Very Difficult                    Medium  \n",
       "1706                 Difficult                      Easy  \n",
       "3023       Extremely Difficult       Extremely Difficult  \n",
       "4283            Very Difficult                 Difficult  \n",
       "4670                 Difficult                    Medium  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_v4_2.csv')\n",
    "test =  pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_Test_v4_2.csv')\n",
    "\n",
    "\n",
    "test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "test = test.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "# X.shape\n",
    "print(X.shape)\n",
    "print(test.shape)\n",
    "\n",
    "X.head()\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = X[\"answerCode\"]\n",
    "g=X[\"userID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat=[ 'userID','assessmentItemID','testId','KnowledgeTag',\n",
    "    #    'SolvingTime','CumulativeTime',\n",
    "       'Month','DayOfWeek','TimeOfDay',\n",
    "       'problems_cumulative',\n",
    "       'problems_last7days',\n",
    "       'problems_last30days',\n",
    "       'CumulativeUserProblemAnswerRate','CumulativeProblemCount',\n",
    "       'ProblemAnswerRate','TagAnswerRate','CumulativeUserTagAnswerRate','TestAnswerRate',\n",
    "       'categorize_solvingTime',\n",
    "       'categorize_ProblemAnswerRate','categorize_TagAnswerRate','categorize_TestAnswerRate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"num_leaves\": 10,  # 최소값 10\n",
    "    \"learning_rate\": 0.0001,  # 최소값 0.0001\n",
    "    \"max_depth\": -1,  # -1 (깊이 제한 없음)\n",
    "    \"min_data_in_leaf\": 20,  # 최소값 20\n",
    "    \"feature_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_freq\": 0,  # 최소값 0\n",
    "    \"lambda_l1\": 0.0,  # 최소값 0.0\n",
    "    \"lambda_l2\": 0.0,  # 최소값 0.0\n",
    "    \"cat_smooth\": 10,  # 최소값 10\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_feat = test[feat]\n",
    "\n",
    "# LabelEncoder 적용\n",
    "\n",
    "label_encoders = {}\n",
    "for column in [\n",
    "    \"DayOfWeek\",\n",
    "    \"TimeOfDay\",\n",
    "    \"categorize_ProblemAnswerRate\",\n",
    "    \"categorize_TagAnswerRate\",\n",
    "    \"categorize_TestAnswerRate\",\n",
    "]:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    # 테스트 데이터에 대해서는 transform만 적용\n",
    "    test_feat[column] = le.transform(test_feat[column])\n",
    "\n",
    "\n",
    "def train():\n",
    "    auc = 0\n",
    "    acc = 0\n",
    "    test_preds = np.zeros(len(test_feat))\n",
    "    \n",
    "    # userID별 마지막 인덱스 찾기\n",
    "    last_indices = X.groupby(\"userID\").tail(1).index\n",
    "\n",
    "    # 검증 데이터셋 생성\n",
    "    X_valid = X.loc[last_indices]\n",
    "    y_valid = X_valid[\"answerCode\"]\n",
    "\n",
    "    # 학습 데이터셋 생성\n",
    "    X_train = X.drop(last_indices)\n",
    "    y_train = X_train[\"answerCode\"]\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        X_train[feat],\n",
    "        y_train,\n",
    "        categorical_feature=[\n",
    "            \"userID\",\n",
    "            \"assessmentItemID\",\n",
    "            \"testId,KnowledgeTag\",\n",
    "            \"Month\",\n",
    "            \"categorize_solvingTime\",\n",
    "            \"categorize_ProblemAnswerRate\",\n",
    "            \"categorize_TagAnswerRate\",\n",
    "            \"categorize_TestAnswerRate\"\n",
    "        ],\n",
    "    )\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X_valid[feat],\n",
    "        y_valid,\n",
    "        categorical_feature=[\n",
    "            \"userID\",\n",
    "            \"assessmentItemID\",\n",
    "            \"testId,KnowledgeTag\",\n",
    "            \"Month\",\n",
    "            \"categorize_solvingTime\",\n",
    "            \"categorize_ProblemAnswerRate\",\n",
    "            \"categorize_TagAnswerRate\",\n",
    "            \"categorize_TestAnswerRate\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    wandb.init(project=f\"lightgbm-sweep\", config=default_config)\n",
    "    wandb.run.name = f\"nofoldlgbm\"\n",
    "    current_params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"auc\"],\n",
    "        \"device\": \"cpu\",\n",
    "        \"num_leaves\": wandb.config.num_leaves,\n",
    "        \"learning_rate\": wandb.config.learning_rate,\n",
    "        \"max_depth\": wandb.config.max_depth,\n",
    "        \"min_data_in_leaf\": wandb.config.min_data_in_leaf,\n",
    "        \"feature_fraction\": wandb.config.feature_fraction,\n",
    "        \"bagging_fraction\": wandb.config.bagging_fraction,\n",
    "        \"bagging_freq\": wandb.config.bagging_freq,\n",
    "        \"lambda_l1\": wandb.config.lambda_l1,\n",
    "        \"lambda_l2\": wandb.config.lambda_l2,\n",
    "        \"cat_smooth\": wandb.config.cat_smooth,\n",
    "    }\n",
    "    model = lgb.train(\n",
    "        current_params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=50000,\n",
    "        callbacks=[\n",
    "            wandb_callback(log_params=True, define_metric=True),\n",
    "            lgb.early_stopping(100),\n",
    "        ],\n",
    "        categorical_feature=[\"KnowledgeTag\"],\n",
    "    )\n",
    "    preds = model.predict(X_valid[feat])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    test_preds += model.predict(test_feat)\n",
    "    print(f\"VALID AUC : {auc} ACC : {acc}\\n\")\n",
    "    wandb.log({\"auc\": auc, \"accuracy\": acc})\n",
    "    output_dir = \"output/\"\n",
    "    write_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"auc:{auc} acc:{acc}\" + \"sweep\" + \" lgbm.csv\",\n",
    "    )\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "        print(\"writing prediction : {}\".format(write_path))\n",
    "        w.write(\"id,prediction\\n\")\n",
    "        for id, p in enumerate(test_preds):\n",
    "            w.write(\"{},{}\\n\".format(id, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: apeknn4s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.5847184638552186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.9862428462522672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 9.138579457840867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 6.459972728841724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0648891147077847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 39\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwooksbaby\u001b[0m (\u001b[33mboostcamp6-recsys6\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_035925-apeknn4s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/apeknn4s' target=\"_blank\">classic-sweep-1</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/apeknn4s' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/apeknn4s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649967, number of negative: 868547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655135 -> initscore=0.641689\n",
      "[LightGBM] [Info] Start training from score 0.641689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1088]\ttraining's auc: 0.841972\tvalid_1's auc: 0.805274\n",
      "VALID AUC : 0.8052744318180586 ACC : 0.7264176296694437\n",
      "\n",
      "writing prediction : output/auc:0.8052744318180586 acc:0.7264176296694437sweep lgbm.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▆▇▇▇▇▇▇▇██████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.72642</td></tr><tr><td>auc</td><td>0.80527</td></tr><tr><td>iteration</td><td>1187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-1</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/apeknn4s' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/apeknn4s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240123_035925-apeknn4s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4t874bqo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.5556133842786456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.7631000259808062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 11.477928263502047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 3.4488073585305967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.2037998587560743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_040508-4t874bqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4t874bqo' target=\"_blank\">dry-sweep-2</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4t874bqo' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4t874bqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649967, number of negative: 868547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655135 -> initscore=0.641689\n",
      "[LightGBM] [Info] Start training from score 0.641689\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's auc: 0.83943\tvalid_1's auc: 0.803505\n",
      "VALID AUC : 0.8035046080682772 ACC : 0.7268207471109916\n",
      "\n",
      "writing prediction : output/auc:0.8035046080682772 acc:0.7268207471109916sweep lgbm.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▅▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>valid_1_auc</td><td>▁▅▇▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.72682</td></tr><tr><td>auc</td><td>0.8035</td></tr><tr><td>iteration</td><td>454</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-sweep-2</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4t874bqo' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4t874bqo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240123_040508-4t874bqo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: arlk8mrx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.7499495089092738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.5076075068438028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 7.934494096928071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 10.352057417303728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.2969052876838441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 39\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_040724-arlk8mrx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/arlk8mrx' target=\"_blank\">hearty-sweep-3</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/my5wz8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/arlk8mrx' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/arlk8mrx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649967, number of negative: 868547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3086\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655135 -> initscore=0.641689\n",
      "[LightGBM] [Info] Start training from score 0.641689\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
