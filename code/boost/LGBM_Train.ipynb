{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    },
    "id": "Uq_TJqbdhfQu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytz\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_callback 수정 \n",
    "from typing import TYPE_CHECKING, Callable\n",
    "import wandb\n",
    "from wandb.sdk.lib import telemetry as wb_telemetry\n",
    "\n",
    "MINIMIZE_METRICS = [\n",
    "    \"l1\",\n",
    "    \"l2\",\n",
    "    \"rmse\",\n",
    "    \"mape\",\n",
    "    \"huber\",\n",
    "    \"fair\",\n",
    "    \"poisson\",\n",
    "    \"gamma\",\n",
    "    \"binary_logloss\",\n",
    "]\n",
    "\n",
    "MAXIMIZE_METRICS = [\"map\", \"auc\", \"average_precision\"]\n",
    "\n",
    "def set_seeds(seed: int = 42):\n",
    "    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "def wandb_callback(log_params=True, define_metric=True) -> Callable:\n",
    "    \"\"\"Automatically integrates LightGBM with wandb.\n",
    "\n",
    "    Arguments:\n",
    "        log_params: (boolean) if True (default) logs params passed to lightgbm.train as W&B config\n",
    "        define_metric: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`\n",
    "\n",
    "    Passing `wandb_callback` to LightGBM will:\n",
    "      - log params passed to lightgbm.train as W&B config (default).\n",
    "      - log evaluation metrics collected by LightGBM, such as rmse, accuracy etc to Weights & Biases\n",
    "      - Capture the best metric in `wandb.summary` when `define_metric=True` (default).\n",
    "\n",
    "    Use `log_summary` as an extension of this callback.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            .\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()])\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def _define_metric(data: str, metric_name: str) -> None:\n",
    "    \n",
    "        \"\"\"Capture model performance at the best step.\n",
    "        instead of the last step, of training in your `wandb.summary`\n",
    "        \"\"\"\n",
    "        if \"loss\" in str.lower(metric_name):\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MINIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MAXIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"max\")\n",
    "            \n",
    "    log_params_list: \"List[bool]\" = [log_params]\n",
    "    define_metric_list: \"List[bool]\" = [define_metric]\n",
    "\n",
    "    def _init(env: \"CallbackEnv\") -> None:\n",
    "        with wb_telemetry.context() as tel:\n",
    "            tel.feature.lightgbm_wandb_callback = True\n",
    "\n",
    "        wandb.config.update(env.params)\n",
    "        log_params_list[0] = False\n",
    "\n",
    "        if define_metric_list[0]:\n",
    "            for i in range(len(env.evaluation_result_list)):\n",
    "                data_type = env.evaluation_result_list[i][0]\n",
    "                metric_name = env.evaluation_result_list[i][1]\n",
    "                _define_metric(data_type, metric_name)\n",
    "\n",
    "    def _callback(env: \"CallbackEnv\") -> None:\n",
    "        if log_params_list[0]:\n",
    "            _init(env)\n",
    "        # eval_results: \"Dict[str, Dict[str, List[Any]]]\" = {}\n",
    "        # recorder = lightgbm.record_evaluation(eval_results)\n",
    "        # recorder(env)\n",
    "        eval_results = {x[0]:{x[1:][0]:x[1:][1:]} for x in env.evaluation_result_list}\n",
    "\n",
    "        for validation_key in eval_results.keys():\n",
    "            for key in eval_results[validation_key].keys():\n",
    "                 wandb.log(\n",
    "                     {validation_key + \"_\" + key: eval_results[validation_key][key][0]},\n",
    "                     commit=False,\n",
    "                 )\n",
    "        for item in eval_results:\n",
    "            if len(item) == 4:\n",
    "                wandb.log({f\"{item[0]}_{item[1]}\": item[2]}, commit=False)\n",
    "\n",
    "        # Previous log statements use commit=False. This commits them.\n",
    "        wandb.log({\"iteration\": env.iteration}, commit=True)\n",
    "\n",
    "    return _callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZlm5HSmhfQv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    },
    "id": "s6qgJ8MLhfQw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: j1rzdmbv\n",
      "Sweep URL: https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv\n"
     ]
    }
   ],
   "source": [
    "sweep_config_path = '/data/ephemeral/level2-dkt-recsys-06/code/boost/lgbmsweepconfigv2.yaml'\n",
    "\n",
    "# 노트북의 이름 설정\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'LGBM_Train.ipynb'\n",
    "# YAML 파일 로드\n",
    "with open(sweep_config_path, 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)\n",
    "\n",
    "# W&B 스위프트 설정\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"lightgbm-sweep\")\n",
    "\n",
    "# 시드 고정\n",
    "set_seeds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userIDnum 7442\n",
      "        userID  assessmentItemID  testId  answerCode            Timestamp  \\\n",
      "1035         3          50133008   50133          -1  2020-10-26 13:13:57   \n",
      "1706         4          70146008   70146          -1  2020-12-27 02:47:54   \n",
      "3023        13          70111008   70111          -1  2020-12-27 04:35:09   \n",
      "4283        17          90064006   90064          -1  2020-10-30 05:48:37   \n",
      "4670        26          60135007   60135          -1  2020-10-23 11:44:18   \n",
      "...        ...               ...     ...         ...                  ...   \n",
      "260052    7395          40122005   40122          -1  2020-09-08 02:05:20   \n",
      "260067    7404          30111005   30111          -1  2020-10-13 09:49:18   \n",
      "260082    7416          50193004   50193          -1  2020-10-04 02:44:41   \n",
      "260097    7417          50193004   50193          -1  2020-09-06 13:09:15   \n",
      "260113    7439          40130005   40130          -1  2020-10-14 23:10:03   \n",
      "\n",
      "        KnowledgeTag  Itemseq  SolvingTime  CumulativeTime  Month  ...  \\\n",
      "1035            5289        8           46             362     10  ...   \n",
      "1706            9080        8           25             197     12  ...   \n",
      "3023            9660        8            8             112     12  ...   \n",
      "4283            2611        6           75             455     10  ...   \n",
      "4670            1422        7           22             297     10  ...   \n",
      "...              ...      ...          ...             ...    ...  ...   \n",
      "260052         10615        5            2              14      9  ...   \n",
      "260067          7636        5           45             264     10  ...   \n",
      "260082         10402        4           14              61     10  ...   \n",
      "260097         10402        4           21              84      9  ...   \n",
      "260113          8832        5           26             186     10  ...   \n",
      "\n",
      "       user_tag_acc  repeat  problem_acc   tag_acc   elapsed  total_elapsed  \\\n",
      "1035       0.818182       1     0.534400  0.559569  3.850148       5.758902   \n",
      "1706       0.666667       1     0.613333  0.546588  3.178054       5.153292   \n",
      "3023       0.333333       1     0.370400  0.494467  2.197225       4.653960   \n",
      "4283       1.000000       1     0.276000  0.419529  4.330733       5.942799   \n",
      "4670       0.666667       1     0.314400  0.609600  2.890372       5.620401   \n",
      "...             ...     ...          ...       ...       ...            ...   \n",
      "260052     0.000000       1     0.448667  0.701714  1.098612       2.564949   \n",
      "260067     0.500000       1     0.885333  0.824500  4.682131       5.393628   \n",
      "260082     0.666667       1     0.856800  0.823284  3.218876       3.871201   \n",
      "260097     0.666667       1     0.856800  0.823284  3.091042       4.158883   \n",
      "260113     0.500000       1     0.605333  0.638370  3.496508       5.081404   \n",
      "\n",
      "        user_total_attempts  recent_solve_time  moving_average_solve_time  \\\n",
      "1035                   1036               46.0                       43.0   \n",
      "1706                    671               23.0                       25.6   \n",
      "3023                   1317                8.0                        7.6   \n",
      "4283                   1260               75.0                       76.0   \n",
      "4670                    387               17.0                       50.4   \n",
      "...                     ...                ...                        ...   \n",
      "260052                   24                2.0                    11669.4   \n",
      "260067                   15              107.0                    14147.6   \n",
      "260082                   15               24.0                    11996.8   \n",
      "260097                   15               21.0                     8437.4   \n",
      "260113                   16               32.0                    11163.6   \n",
      "\n",
      "        user_acc  \n",
      "1035    0.692085  \n",
      "1706    0.692996  \n",
      "3023    0.694761  \n",
      "4283    0.818254  \n",
      "4670    0.757106  \n",
      "...          ...  \n",
      "260052  0.291667  \n",
      "260067  0.466667  \n",
      "260082  0.466667  \n",
      "260097  0.133333  \n",
      "260113  0.687500  \n",
      "\n",
      "[744 rows x 54 columns]\n",
      "False\n",
      "(260114, 54)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_v7.csv')\n",
    "test =  pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_test_v7.csv')\n",
    "X = X.sort_values(by=[\"userID\", \"Timestamp\", \"assessmentItemID\"]).reset_index(drop=True)\n",
    "test = test.sort_values(by=[\"userID\", \"Timestamp\", \"assessmentItemID\"]).reset_index(drop=True)\n",
    "\n",
    "# test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "# test = test.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "# 유저 아이디 갯수 구하기\n",
    "unique_user_count = X['userID'].nunique()\n",
    "\n",
    "# 유저아이디 갯수 출력\n",
    "print(f'userIDnum {unique_user_count}')\n",
    "\n",
    "# 유저아이디 마지막 행 구하기\n",
    "last_rows = test.groupby('userID').tail(1)\n",
    "print(last_rows)\n",
    "# 마지막 행의 answerCode가 -1인지 확인\n",
    "are_last_answers_minus_one = (last_rows['answerCode'] == -1).all()\n",
    "\n",
    "print(are_last_answers_minus_one)\n",
    "\n",
    "# test 모양\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test[\"answerCode\"] == -1]\n",
    "X = X[X['answerCode']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LabelEncoder 적용\n",
    "\n",
    "label_encoders = {}\n",
    "for column in [\n",
    "    \"categorize_ItemAnswerRate\",\n",
    "    \"categorize_TagAnswerRate\",\n",
    "    \"categorize_TestAnswerRate\",\n",
    "    \"categorize_CumulativeUserItemAnswerRate\",\n",
    "    \"categorize_CumulativeUserTagAverageAnswerRate\",\n",
    "    \"categorize_CumulativeUserTagExponentialAverage\",\n",
    "    \"DayOfWeek\",\n",
    "    \"TimeOfDay\",\n",
    "    \"categorize_TagAnswerRate\",    \n",
    "    \"UserRecentTagAnswer\",\n",
    "    \"PreviousItemAnswer\",\n",
    "    \"categorize_TestAnswerRate\",\n",
    "]:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    # 테스트 데이터에 대해서는 transform만 적용\n",
    "    test[column] = le.transform(test[column])\n",
    "    label_encoders[column] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "# # 원-핫 인코딩 적용할 컬럼 선택\n",
    "# columns_to_encode = [\n",
    "#     \"UserRecentTagAnswer\",\n",
    "#     \"PreviousItemAnswer\",\n",
    "#     # 추가적으로 원-핫 인코딩을 적용할 다른 컬럼들을 여기에 추가\n",
    "# ]\n",
    "# for column in columns_to_encode:\n",
    "#     if column in X.columns:\n",
    "#         X = pd.get_dummies(X, columns=[column])\n",
    "#     if column in test.columns:\n",
    "#         test = pd.get_dummies(test, columns=[column])\n",
    "\n",
    "#         # 다른 필드들에 대해서도 동일하게 적용\n",
    "# print(X.shape)\n",
    "\n",
    "# 라벨로 이동 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525956, 54)\n",
      "(2525956, 43)\n",
      "['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp', 'KnowledgeTag', 'Itemseq', 'SolvingTime', 'CumulativeTime', 'Month', 'DayOfWeek', 'TimeOfDay', 'WeekOfYear', 'UserAvgSolvingTime', 'CumulativeItemCount', 'Item_last7days', 'Item_last30days', 'PastItemCount', 'CumulativeUserItemAnswerRate', 'ItemAnswerRate', 'AverageItemSolvingTime_Correct', 'AverageItemSolvingTime_Incorrect', 'AverageItemSolvingTime', 'Difference_SolvingTime_AvgItemSolvingTime', 'UserTagAvgSolvingTime', 'TagAnswerRate', 'CumulativeUserTagAverageAnswerRate', 'CumulativeUserTagExponentialAverage', 'UserCumulativeTagCount', 'UserRecentTagAnswer', 'PreviousItemAnswer', 'TestAnswerRate', 'categorize_solvingTime', 'categorize_ItemAnswerRate', 'categorize_TagAnswerRate', 'categorize_TestAnswerRate', 'categorize_CumulativeUserItemAnswerRate', 'categorize_CumulativeUserTagAverageAnswerRate', 'categorize_CumulativeUserTagExponentialAverage', 'user_test_correct_answer', 'user_test_total_answer', 'user_test_acc', 'user_tag_correct_answer', 'user_tag_total_answer', 'user_tag_acc', 'repeat', 'problem_acc', 'tag_acc', 'elapsed', 'total_elapsed', 'user_total_attempts', 'recent_solve_time', 'moving_average_solve_time', 'user_acc']\n"
     ]
    }
   ],
   "source": [
    "feat = X.columns.tolist()\n",
    "\n",
    "exclude_columns = [\n",
    "    \"Timestamp\",\n",
    "    \"answerCode\",\n",
    "    \"DayOfWeek\",\n",
    "    'WeekOfYear',\n",
    "    'UserAvgSolvingTime',\n",
    "    'PastItemCount',\n",
    "    \"user_tag_total_answer\",\n",
    "    \"categorize_CumulativeUserTagExponentialAverage\",\n",
    "    'categorize_CumulativeUserTagAverageAnswerRate',\n",
    "    \"categorize_TestAnswerRate\",\n",
    "    \"categorize_TagAnswerRate\"\n",
    "]\n",
    "\n",
    "filtered_feat = [column for column in feat if column not in exclude_columns]\n",
    "\n",
    "print(X[feat].shape)\n",
    "print(X[filtered_feat].shape)\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"num_leaves\": 10,  # 최소값 10\n",
    "    \"learning_rate\": 0.0001,  # 최소값 0.0001\n",
    "    \"max_depth\": -1,  # -1 (깊이 제한 없음)\n",
    "    \"min_data_in_leaf\": 20,  # 최소값 20\n",
    "    \"feature_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_freq\": 0,  # 최소값 0\n",
    "    \"lambda_l1\": 0.0,  # 최소값 0.0\n",
    "    \"lambda_l2\": 0.0,  # 최소값 0.0\n",
    "    \"cat_smooth\": 10,  # 최소값 10\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    auc = 0\n",
    "    acc = 0\n",
    "    test_preds = np.zeros(len(test))\n",
    "\n",
    "    wandb.init(project=f\"lightgbm-sweep\", config=default_config)\n",
    "\n",
    "    ratio = wandb.config.ratio\n",
    "\n",
    "    sampled_indices = X.groupby(\"userID\").sample(frac=ratio).index\n",
    "\n",
    "    # userID별 마지막 인덱스 찾기\n",
    "    # last_indices = X.groupby(\"userID\").tail(1).index\n",
    "\n",
    "    # 학습 데이터셋 생성\n",
    "    X_train = X.drop(sampled_indices)\n",
    "    y_train = X_train[\"answerCode\"]\n",
    "\n",
    "    # 검증 데이터셋 생성\n",
    "    X_valid = X.loc[sampled_indices]\n",
    "    y_valid = X_valid[\"answerCode\"]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train[filtered_feat], y_train)\n",
    "    lgb_valid = lgb.Dataset(X_valid[filtered_feat], y_valid)\n",
    "\n",
    "    # 완드비 실험 이름\n",
    "    korea = pytz.timezone(\"Asia/Seoul\")\n",
    "    current_time = datetime.now(korea).strftime(\"%m-%d %H:%M\")\n",
    "    wandb.run.name = f\"wooksbaby-{current_time},ratio-{ratio}\"\n",
    "    current_params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"auc\"],\n",
    "        \"device\": \"cpu\",\n",
    "        \"num_leaves\": wandb.config.num_leaves,\n",
    "        \"learning_rate\": wandb.config.learning_rate,\n",
    "        \"max_depth\": wandb.config.max_depth,\n",
    "        \"min_data_in_leaf\": wandb.config.min_data_in_leaf,\n",
    "        \"feature_fraction\": wandb.config.feature_fraction,\n",
    "        \"bagging_fraction\": wandb.config.bagging_fraction,\n",
    "        \"bagging_freq\": wandb.config.bagging_freq,\n",
    "        \"lambda_l1\": wandb.config.lambda_l1,\n",
    "        \"lambda_l2\": wandb.config.lambda_l2,\n",
    "        \"cat_smooth\": wandb.config.cat_smooth,\n",
    "    }\n",
    "    model = lgb.train(\n",
    "        current_params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=1500,\n",
    "        callbacks=[\n",
    "            wandb_callback(log_params=True, define_metric=True),\n",
    "            lgb.early_stopping(20),\n",
    "        ],\n",
    "        categorical_feature=[\n",
    "            \"userID\",\n",
    "            \"assessmentItemID\",\n",
    "            \"testId\",\n",
    "            \"KnowledgeTag\",\n",
    "            \"Month\",\n",
    "        ],\n",
    "    )\n",
    "    preds = model.predict(X_valid[filtered_feat])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    test_preds += model.predict(test[filtered_feat])\n",
    "    print(f\"VALID AUC : {auc} ACC : {acc}\\n\")\n",
    "\n",
    "    # output파일 생성\n",
    "    output_dir = \"output/\"\n",
    "    write_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"auc:{auc} acc:{acc}\" + \"sweep\" + \" lgbm.csv\",\n",
    "    )\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "        print(\"writing prediction : {}\".format(write_path))\n",
    "        w.write(\"id,prediction\\n\")\n",
    "        for id, p in enumerate(test_preds):\n",
    "            w.write(\"{},{}\\n\".format(id, p))\n",
    "\n",
    "    # feature_importances = model.feature_importance()\n",
    "    # feature_names = model.feature_name()\n",
    "    # importance_df = pd.DataFrame(\n",
    "    #     {\"Feature\": feature_names, \"Importance\": feature_importances}\n",
    "    # ).sort_values(by=\"Importance\", ascending=False)\n",
    "    # print(importance_df)\n",
    "\n",
    "    wandb.log({\"auc\": auc, \"accuracy\": acc})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4nagb56u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.7100504474382494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.6880100231147456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 2.9408358264506456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 9.61425685345089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.4472517690379719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tratio: 0.050189620831581586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwooksbaby\u001b[0m (\u001b[33mboostcamp6-recsys6\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240125_011812-4nagb56u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4nagb56u' target=\"_blank\">hearty-sweep-1</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4nagb56u' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4nagb56u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 1570686, number of negative: 828425\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22936\n",
      "[LightGBM] [Info] Number of data points in the train set: 2399111, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654695 -> initscore=0.639741\n",
      "[LightGBM] [Info] Start training from score 0.639741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.823968\tvalid_1's auc: 0.823895\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.834339\tvalid_1's auc: 0.834243\n",
      "[3]\ttraining's auc: 0.839193\tvalid_1's auc: 0.839058\n",
      "[4]\ttraining's auc: 0.842217\tvalid_1's auc: 0.841779\n",
      "[5]\ttraining's auc: 0.844997\tvalid_1's auc: 0.844208\n",
      "[6]\ttraining's auc: 0.847135\tvalid_1's auc: 0.845797\n",
      "[7]\ttraining's auc: 0.848908\tvalid_1's auc: 0.847225\n",
      "[8]\ttraining's auc: 0.850447\tvalid_1's auc: 0.848354\n",
      "[9]\ttraining's auc: 0.851801\tvalid_1's auc: 0.849308\n",
      "[10]\ttraining's auc: 0.85317\tvalid_1's auc: 0.850215\n",
      "[11]\ttraining's auc: 0.85435\tvalid_1's auc: 0.850992\n",
      "[12]\ttraining's auc: 0.855328\tvalid_1's auc: 0.851585\n",
      "[13]\ttraining's auc: 0.856237\tvalid_1's auc: 0.851986\n",
      "[14]\ttraining's auc: 0.856816\tvalid_1's auc: 0.852298\n",
      "[15]\ttraining's auc: 0.85761\tvalid_1's auc: 0.85268\n",
      "[16]\ttraining's auc: 0.858432\tvalid_1's auc: 0.853173\n",
      "[17]\ttraining's auc: 0.859195\tvalid_1's auc: 0.853542\n",
      "[18]\ttraining's auc: 0.85975\tvalid_1's auc: 0.853928\n",
      "[19]\ttraining's auc: 0.86027\tvalid_1's auc: 0.854065\n",
      "[20]\ttraining's auc: 0.861042\tvalid_1's auc: 0.854438\n",
      "[21]\ttraining's auc: 0.861511\tvalid_1's auc: 0.854608\n",
      "[22]\ttraining's auc: 0.862016\tvalid_1's auc: 0.854778\n",
      "[23]\ttraining's auc: 0.862304\tvalid_1's auc: 0.85476\n",
      "[24]\ttraining's auc: 0.862775\tvalid_1's auc: 0.854922\n",
      "[25]\ttraining's auc: 0.863176\tvalid_1's auc: 0.855122\n",
      "[26]\ttraining's auc: 0.863425\tvalid_1's auc: 0.855191\n",
      "[27]\ttraining's auc: 0.863719\tvalid_1's auc: 0.855251\n",
      "[28]\ttraining's auc: 0.864019\tvalid_1's auc: 0.855237\n",
      "[29]\ttraining's auc: 0.864599\tvalid_1's auc: 0.855627\n",
      "[30]\ttraining's auc: 0.864898\tvalid_1's auc: 0.855552\n",
      "[31]\ttraining's auc: 0.86521\tvalid_1's auc: 0.855698\n",
      "[32]\ttraining's auc: 0.865418\tvalid_1's auc: 0.855734\n",
      "[33]\ttraining's auc: 0.865752\tvalid_1's auc: 0.855668\n",
      "[34]\ttraining's auc: 0.865989\tvalid_1's auc: 0.855764\n",
      "[35]\ttraining's auc: 0.866124\tvalid_1's auc: 0.855705\n",
      "[36]\ttraining's auc: 0.86629\tvalid_1's auc: 0.855614\n",
      "[37]\ttraining's auc: 0.866479\tvalid_1's auc: 0.85565\n",
      "[38]\ttraining's auc: 0.866611\tvalid_1's auc: 0.855572\n",
      "[39]\ttraining's auc: 0.866887\tvalid_1's auc: 0.855393\n",
      "[40]\ttraining's auc: 0.867303\tvalid_1's auc: 0.855366\n",
      "[41]\ttraining's auc: 0.867544\tvalid_1's auc: 0.855384\n",
      "[42]\ttraining's auc: 0.868008\tvalid_1's auc: 0.855658\n",
      "[43]\ttraining's auc: 0.86814\tvalid_1's auc: 0.855707\n",
      "[44]\ttraining's auc: 0.86831\tvalid_1's auc: 0.855687\n",
      "[45]\ttraining's auc: 0.868638\tvalid_1's auc: 0.855778\n",
      "[46]\ttraining's auc: 0.868803\tvalid_1's auc: 0.855832\n",
      "[47]\ttraining's auc: 0.869051\tvalid_1's auc: 0.855982\n",
      "[48]\ttraining's auc: 0.869338\tvalid_1's auc: 0.855981\n",
      "[49]\ttraining's auc: 0.869484\tvalid_1's auc: 0.856008\n",
      "[50]\ttraining's auc: 0.869708\tvalid_1's auc: 0.855975\n",
      "[51]\ttraining's auc: 0.869882\tvalid_1's auc: 0.855963\n",
      "[52]\ttraining's auc: 0.870287\tvalid_1's auc: 0.856061\n",
      "[53]\ttraining's auc: 0.870517\tvalid_1's auc: 0.85603\n",
      "[54]\ttraining's auc: 0.870701\tvalid_1's auc: 0.856068\n",
      "[55]\ttraining's auc: 0.870805\tvalid_1's auc: 0.855962\n",
      "[56]\ttraining's auc: 0.870944\tvalid_1's auc: 0.855951\n",
      "[57]\ttraining's auc: 0.871032\tvalid_1's auc: 0.855927\n",
      "[58]\ttraining's auc: 0.87125\tvalid_1's auc: 0.855951\n",
      "[59]\ttraining's auc: 0.871519\tvalid_1's auc: 0.855879\n",
      "[60]\ttraining's auc: 0.87162\tvalid_1's auc: 0.85591\n",
      "[61]\ttraining's auc: 0.871772\tvalid_1's auc: 0.85595\n",
      "[62]\ttraining's auc: 0.871923\tvalid_1's auc: 0.855874\n",
      "[63]\ttraining's auc: 0.872066\tvalid_1's auc: 0.855882\n",
      "[64]\ttraining's auc: 0.872498\tvalid_1's auc: 0.855937\n",
      "[65]\ttraining's auc: 0.872845\tvalid_1's auc: 0.856039\n",
      "[66]\ttraining's auc: 0.873016\tvalid_1's auc: 0.856193\n",
      "[67]\ttraining's auc: 0.873209\tvalid_1's auc: 0.856159\n",
      "[68]\ttraining's auc: 0.873264\tvalid_1's auc: 0.856204\n",
      "[69]\ttraining's auc: 0.873525\tvalid_1's auc: 0.856143\n",
      "[70]\ttraining's auc: 0.873709\tvalid_1's auc: 0.856107\n",
      "[71]\ttraining's auc: 0.873825\tvalid_1's auc: 0.856114\n",
      "[72]\ttraining's auc: 0.874064\tvalid_1's auc: 0.856236\n",
      "[73]\ttraining's auc: 0.874153\tvalid_1's auc: 0.856194\n",
      "[74]\ttraining's auc: 0.874243\tvalid_1's auc: 0.856175\n",
      "[75]\ttraining's auc: 0.874423\tvalid_1's auc: 0.856227\n",
      "[76]\ttraining's auc: 0.874608\tvalid_1's auc: 0.856231\n",
      "[77]\ttraining's auc: 0.874693\tvalid_1's auc: 0.856203\n",
      "[78]\ttraining's auc: 0.87477\tvalid_1's auc: 0.856226\n",
      "[79]\ttraining's auc: 0.875095\tvalid_1's auc: 0.856238\n",
      "[80]\ttraining's auc: 0.875288\tvalid_1's auc: 0.856271\n",
      "[81]\ttraining's auc: 0.875427\tvalid_1's auc: 0.856317\n",
      "[82]\ttraining's auc: 0.875679\tvalid_1's auc: 0.856423\n",
      "[83]\ttraining's auc: 0.875702\tvalid_1's auc: 0.856415\n",
      "[84]\ttraining's auc: 0.875868\tvalid_1's auc: 0.856359\n",
      "[85]\ttraining's auc: 0.876179\tvalid_1's auc: 0.856427\n",
      "[86]\ttraining's auc: 0.876212\tvalid_1's auc: 0.856472\n",
      "[87]\ttraining's auc: 0.876491\tvalid_1's auc: 0.856663\n",
      "[88]\ttraining's auc: 0.876597\tvalid_1's auc: 0.856667\n",
      "[89]\ttraining's auc: 0.876682\tvalid_1's auc: 0.856696\n",
      "[90]\ttraining's auc: 0.876896\tvalid_1's auc: 0.856604\n",
      "[91]\ttraining's auc: 0.876935\tvalid_1's auc: 0.856598\n",
      "[92]\ttraining's auc: 0.87702\tvalid_1's auc: 0.856602\n",
      "[93]\ttraining's auc: 0.877241\tvalid_1's auc: 0.85649\n",
      "[94]\ttraining's auc: 0.877329\tvalid_1's auc: 0.856421\n",
      "[95]\ttraining's auc: 0.877409\tvalid_1's auc: 0.85639\n",
      "[96]\ttraining's auc: 0.877604\tvalid_1's auc: 0.856333\n",
      "[97]\ttraining's auc: 0.87768\tvalid_1's auc: 0.856348\n",
      "[98]\ttraining's auc: 0.877748\tvalid_1's auc: 0.856317\n",
      "[99]\ttraining's auc: 0.87785\tvalid_1's auc: 0.856271\n",
      "[100]\ttraining's auc: 0.878084\tvalid_1's auc: 0.856266\n",
      "[101]\ttraining's auc: 0.87812\tvalid_1's auc: 0.856333\n",
      "[102]\ttraining's auc: 0.878219\tvalid_1's auc: 0.856353\n",
      "[103]\ttraining's auc: 0.878496\tvalid_1's auc: 0.85651\n",
      "[104]\ttraining's auc: 0.878634\tvalid_1's auc: 0.856484\n",
      "[105]\ttraining's auc: 0.879037\tvalid_1's auc: 0.856532\n",
      "[106]\ttraining's auc: 0.879054\tvalid_1's auc: 0.85659\n",
      "[107]\ttraining's auc: 0.879174\tvalid_1's auc: 0.856606\n",
      "[108]\ttraining's auc: 0.879321\tvalid_1's auc: 0.856609\n",
      "[109]\ttraining's auc: 0.87939\tvalid_1's auc: 0.856652\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's auc: 0.876682\tvalid_1's auc: 0.856696\n",
      "VALID AUC : 0.8566955804030867 ACC : 0.8020182112026489\n",
      "\n",
      "writing prediction : output/auc:0.8566955804030867 acc:0.8020182112026489sweep lgbm.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4fb64327c84fa68b024349ce721fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>valid_1_auc</td><td>▁▄▆▆▇▇▇█████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.80202</td></tr><tr><td>auc</td><td>0.8567</td></tr><tr><td>iteration</td><td>108</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-1</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4nagb56u' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/4nagb56u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_011812-4nagb56u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lrpej6rd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.5712523457191416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.7694977001003088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 2.4574444727082696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 0.4906413940801369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.3692315632600192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 44\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tratio: 0.029726521648650563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240125_012238-lrpej6rd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/lrpej6rd' target=\"_blank\">denim-sweep-2</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/j1rzdmbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/lrpej6rd' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/lrpej6rd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 1604161, number of negative: 846605\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22923\n",
      "[LightGBM] [Info] Number of data points in the train set: 2450766, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654555 -> initscore=0.639122\n",
      "[LightGBM] [Info] Start training from score 0.639122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.82657\tvalid_1's auc: 0.823056\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.83618\tvalid_1's auc: 0.832964\n",
      "[3]\ttraining's auc: 0.84038\tvalid_1's auc: 0.836633\n",
      "[4]\ttraining's auc: 0.843045\tvalid_1's auc: 0.839307\n",
      "[5]\ttraining's auc: 0.84562\tvalid_1's auc: 0.841678\n",
      "[6]\ttraining's auc: 0.847873\tvalid_1's auc: 0.843442\n",
      "[7]\ttraining's auc: 0.849672\tvalid_1's auc: 0.844765\n",
      "[8]\ttraining's auc: 0.851073\tvalid_1's auc: 0.845999\n",
      "[9]\ttraining's auc: 0.852519\tvalid_1's auc: 0.84712\n",
      "[10]\ttraining's auc: 0.85395\tvalid_1's auc: 0.848153\n",
      "[11]\ttraining's auc: 0.855266\tvalid_1's auc: 0.849002\n",
      "[12]\ttraining's auc: 0.856536\tvalid_1's auc: 0.849858\n",
      "[13]\ttraining's auc: 0.857483\tvalid_1's auc: 0.850311\n",
      "[14]\ttraining's auc: 0.858264\tvalid_1's auc: 0.850809\n",
      "[15]\ttraining's auc: 0.858992\tvalid_1's auc: 0.851105\n",
      "[16]\ttraining's auc: 0.85994\tvalid_1's auc: 0.85163\n",
      "[17]\ttraining's auc: 0.860446\tvalid_1's auc: 0.851764\n",
      "[18]\ttraining's auc: 0.860959\tvalid_1's auc: 0.851956\n",
      "[19]\ttraining's auc: 0.861495\tvalid_1's auc: 0.85211\n",
      "[20]\ttraining's auc: 0.861994\tvalid_1's auc: 0.852236\n",
      "[21]\ttraining's auc: 0.862517\tvalid_1's auc: 0.852484\n",
      "[22]\ttraining's auc: 0.863141\tvalid_1's auc: 0.852802\n",
      "[23]\ttraining's auc: 0.863535\tvalid_1's auc: 0.853004\n",
      "[24]\ttraining's auc: 0.863925\tvalid_1's auc: 0.853161\n",
      "[25]\ttraining's auc: 0.864144\tvalid_1's auc: 0.853231\n",
      "[26]\ttraining's auc: 0.864523\tvalid_1's auc: 0.853432\n",
      "[27]\ttraining's auc: 0.864867\tvalid_1's auc: 0.853586\n",
      "[28]\ttraining's auc: 0.865146\tvalid_1's auc: 0.853549\n",
      "[29]\ttraining's auc: 0.865576\tvalid_1's auc: 0.853769\n",
      "[30]\ttraining's auc: 0.865726\tvalid_1's auc: 0.853642\n",
      "[31]\ttraining's auc: 0.866053\tvalid_1's auc: 0.853814\n",
      "[32]\ttraining's auc: 0.866478\tvalid_1's auc: 0.853803\n",
      "[33]\ttraining's auc: 0.866921\tvalid_1's auc: 0.854094\n",
      "[34]\ttraining's auc: 0.867177\tvalid_1's auc: 0.854114\n",
      "[35]\ttraining's auc: 0.867425\tvalid_1's auc: 0.854109\n",
      "[36]\ttraining's auc: 0.867588\tvalid_1's auc: 0.853981\n",
      "[37]\ttraining's auc: 0.867964\tvalid_1's auc: 0.854113\n",
      "[38]\ttraining's auc: 0.86824\tvalid_1's auc: 0.854242\n",
      "[39]\ttraining's auc: 0.868469\tvalid_1's auc: 0.854189\n",
      "[40]\ttraining's auc: 0.868898\tvalid_1's auc: 0.854232\n",
      "[41]\ttraining's auc: 0.869081\tvalid_1's auc: 0.854243\n",
      "[42]\ttraining's auc: 0.869408\tvalid_1's auc: 0.854132\n",
      "[43]\ttraining's auc: 0.869601\tvalid_1's auc: 0.854209\n",
      "[44]\ttraining's auc: 0.869801\tvalid_1's auc: 0.854244\n",
      "[45]\ttraining's auc: 0.870037\tvalid_1's auc: 0.854299\n",
      "[46]\ttraining's auc: 0.870135\tvalid_1's auc: 0.854284\n",
      "[47]\ttraining's auc: 0.870252\tvalid_1's auc: 0.854257\n",
      "[48]\ttraining's auc: 0.870338\tvalid_1's auc: 0.854238\n",
      "[49]\ttraining's auc: 0.870454\tvalid_1's auc: 0.854183\n",
      "[50]\ttraining's auc: 0.870749\tvalid_1's auc: 0.854179\n",
      "[51]\ttraining's auc: 0.870841\tvalid_1's auc: 0.854175\n",
      "[52]\ttraining's auc: 0.870984\tvalid_1's auc: 0.854174\n",
      "[53]\ttraining's auc: 0.87135\tvalid_1's auc: 0.854363\n",
      "[54]\ttraining's auc: 0.871702\tvalid_1's auc: 0.854433\n",
      "[55]\ttraining's auc: 0.871959\tvalid_1's auc: 0.854391\n",
      "[56]\ttraining's auc: 0.872261\tvalid_1's auc: 0.854421\n",
      "[57]\ttraining's auc: 0.872466\tvalid_1's auc: 0.854479\n",
      "[58]\ttraining's auc: 0.87272\tvalid_1's auc: 0.854374\n",
      "[59]\ttraining's auc: 0.873\tvalid_1's auc: 0.854512\n",
      "[60]\ttraining's auc: 0.873369\tvalid_1's auc: 0.854521\n",
      "[61]\ttraining's auc: 0.873606\tvalid_1's auc: 0.85454\n",
      "[62]\ttraining's auc: 0.873878\tvalid_1's auc: 0.854597\n",
      "[63]\ttraining's auc: 0.874114\tvalid_1's auc: 0.85449\n",
      "[64]\ttraining's auc: 0.874381\tvalid_1's auc: 0.854584\n",
      "[65]\ttraining's auc: 0.874532\tvalid_1's auc: 0.854604\n",
      "[66]\ttraining's auc: 0.87464\tvalid_1's auc: 0.854598\n",
      "[67]\ttraining's auc: 0.874834\tvalid_1's auc: 0.854489\n",
      "[68]\ttraining's auc: 0.87491\tvalid_1's auc: 0.85449\n",
      "[69]\ttraining's auc: 0.875005\tvalid_1's auc: 0.854472\n",
      "[70]\ttraining's auc: 0.875233\tvalid_1's auc: 0.854533\n",
      "[71]\ttraining's auc: 0.875318\tvalid_1's auc: 0.854509\n",
      "[72]\ttraining's auc: 0.875628\tvalid_1's auc: 0.854459\n",
      "[73]\ttraining's auc: 0.875866\tvalid_1's auc: 0.854429\n",
      "[74]\ttraining's auc: 0.876006\tvalid_1's auc: 0.854388\n",
      "[75]\ttraining's auc: 0.87614\tvalid_1's auc: 0.85439\n",
      "[76]\ttraining's auc: 0.876215\tvalid_1's auc: 0.854331\n",
      "[77]\ttraining's auc: 0.876394\tvalid_1's auc: 0.854335\n",
      "[78]\ttraining's auc: 0.876578\tvalid_1's auc: 0.854268\n",
      "[79]\ttraining's auc: 0.876789\tvalid_1's auc: 0.854236\n",
      "[80]\ttraining's auc: 0.877053\tvalid_1's auc: 0.854336\n",
      "[81]\ttraining's auc: 0.877243\tvalid_1's auc: 0.854289\n",
      "[82]\ttraining's auc: 0.87735\tvalid_1's auc: 0.854286\n",
      "[83]\ttraining's auc: 0.877453\tvalid_1's auc: 0.854256\n",
      "[84]\ttraining's auc: 0.877692\tvalid_1's auc: 0.854227\n",
      "[85]\ttraining's auc: 0.877842\tvalid_1's auc: 0.854387\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.874532\tvalid_1's auc: 0.854604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
