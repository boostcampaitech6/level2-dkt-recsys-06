{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    },
    "id": "Uq_TJqbdhfQu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_callback 수정 \n",
    "from typing import TYPE_CHECKING, Callable\n",
    "import wandb\n",
    "from wandb.sdk.lib import telemetry as wb_telemetry\n",
    "\n",
    "MINIMIZE_METRICS = [\n",
    "    \"l1\",\n",
    "    \"l2\",\n",
    "    \"rmse\",\n",
    "    \"mape\",\n",
    "    \"huber\",\n",
    "    \"fair\",\n",
    "    \"poisson\",\n",
    "    \"gamma\",\n",
    "    \"binary_logloss\",\n",
    "]\n",
    "\n",
    "MAXIMIZE_METRICS = [\"map\", \"auc\", \"average_precision\"]\n",
    "        \n",
    "def wandb_callback(log_params=True, define_metric=True) -> Callable:\n",
    "    \"\"\"Automatically integrates LightGBM with wandb.\n",
    "\n",
    "    Arguments:\n",
    "        log_params: (boolean) if True (default) logs params passed to lightgbm.train as W&B config\n",
    "        define_metric: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`\n",
    "\n",
    "    Passing `wandb_callback` to LightGBM will:\n",
    "      - log params passed to lightgbm.train as W&B config (default).\n",
    "      - log evaluation metrics collected by LightGBM, such as rmse, accuracy etc to Weights & Biases\n",
    "      - Capture the best metric in `wandb.summary` when `define_metric=True` (default).\n",
    "\n",
    "    Use `log_summary` as an extension of this callback.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            .\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()])\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def _define_metric(data: str, metric_name: str) -> None:\n",
    "    \n",
    "        \"\"\"Capture model performance at the best step.\n",
    "        instead of the last step, of training in your `wandb.summary`\n",
    "        \"\"\"\n",
    "        if \"loss\" in str.lower(metric_name):\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MINIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "        elif str.lower(metric_name) in MAXIMIZE_METRICS:\n",
    "            wandb.define_metric(f\"{data}_{metric_name}\", summary=\"max\")\n",
    "            \n",
    "    log_params_list: \"List[bool]\" = [log_params]\n",
    "    define_metric_list: \"List[bool]\" = [define_metric]\n",
    "\n",
    "    def _init(env: \"CallbackEnv\") -> None:\n",
    "        with wb_telemetry.context() as tel:\n",
    "            tel.feature.lightgbm_wandb_callback = True\n",
    "\n",
    "        wandb.config.update(env.params)\n",
    "        log_params_list[0] = False\n",
    "\n",
    "        if define_metric_list[0]:\n",
    "            for i in range(len(env.evaluation_result_list)):\n",
    "                data_type = env.evaluation_result_list[i][0]\n",
    "                metric_name = env.evaluation_result_list[i][1]\n",
    "                _define_metric(data_type, metric_name)\n",
    "\n",
    "    def _callback(env: \"CallbackEnv\") -> None:\n",
    "        if log_params_list[0]:\n",
    "            _init(env)\n",
    "        # eval_results: \"Dict[str, Dict[str, List[Any]]]\" = {}\n",
    "        # recorder = lightgbm.record_evaluation(eval_results)\n",
    "        # recorder(env)\n",
    "        eval_results = {x[0]:{x[1:][0]:x[1:][1:]} for x in env.evaluation_result_list}\n",
    "\n",
    "        for validation_key in eval_results.keys():\n",
    "            for key in eval_results[validation_key].keys():\n",
    "                 wandb.log(\n",
    "                     {validation_key + \"_\" + key: eval_results[validation_key][key][0]},\n",
    "                     commit=False,\n",
    "                 )\n",
    "        for item in eval_results:\n",
    "            if len(item) == 4:\n",
    "                wandb.log({f\"{item[0]}_{item[1]}\": item[2]}, commit=False)\n",
    "\n",
    "        # Previous log statements use commit=False. This commits them.\n",
    "        wandb.log({\"iteration\": env.iteration}, commit=True)\n",
    "\n",
    "    return _callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZlm5HSmhfQv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    },
    "id": "s6qgJ8MLhfQw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: dp3c9fep\n",
      "Sweep URL: https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep\n"
     ]
    }
   ],
   "source": [
    "sweep_config_path = '/data/ephemeral/level2-dkt-recsys-06/code/boost/lgbmsweepconfigv2.yaml'\n",
    "\n",
    "# 노트북의 이름 설정\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'LGBM_Train.ipynb'\n",
    "# YAML 파일 로드\n",
    "with open(sweep_config_path, 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)\n",
    "\n",
    "# W&B 스위프트 설정\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"lightgbm-sweep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userIDnum 7442\n",
      "        userID  assessmentItemID  testId  answerCode            Timestamp  \\\n",
      "1035         3          50133008   50133          -1  2020-10-26 13:13:57   \n",
      "1706         4          70146008   70146          -1  2020-12-27 02:47:54   \n",
      "3023        13          70111008   70111          -1  2020-12-27 04:35:09   \n",
      "4283        17          90064006   90064          -1  2020-10-30 05:48:37   \n",
      "4670        26          60135007   60135          -1  2020-10-23 11:44:18   \n",
      "...        ...               ...     ...         ...                  ...   \n",
      "260052    7395          40122005   40122          -1  2020-09-08 02:05:20   \n",
      "260067    7404          30111005   30111          -1  2020-10-13 09:49:18   \n",
      "260082    7416          50193004   50193          -1  2020-10-04 02:44:41   \n",
      "260097    7417          50193004   50193          -1  2020-09-06 13:09:15   \n",
      "260113    7439          40130005   40130          -1  2020-10-14 23:10:03   \n",
      "\n",
      "        KnowledgeTag  Itemseq  SolvingTime  CumulativeTime  Month  ...  \\\n",
      "1035            5289        8           46             362     10  ...   \n",
      "1706            9080        8           25             197     12  ...   \n",
      "3023            9660        8            8             112     12  ...   \n",
      "4283            2611        6           75             455     10  ...   \n",
      "4670            1422        7           22             297     10  ...   \n",
      "...              ...      ...          ...             ...    ...  ...   \n",
      "260052         10615        5            2              14      9  ...   \n",
      "260067          7636        5           45             264     10  ...   \n",
      "260082         10402        4           14              61     10  ...   \n",
      "260097         10402        4           21              84      9  ...   \n",
      "260113          8832        5           26             186     10  ...   \n",
      "\n",
      "       user_tag_acc  repeat  problem_acc   tag_acc   elapsed  total_elapsed  \\\n",
      "1035       0.818182       1     0.534400  0.559569  3.850148       5.758902   \n",
      "1706       0.666667       1     0.613333  0.546588  3.178054       5.153292   \n",
      "3023       0.333333       1     0.370400  0.494467  2.197225       4.653960   \n",
      "4283       1.000000       1     0.276000  0.419529  4.330733       5.942799   \n",
      "4670       0.666667       1     0.314400  0.609600  2.890372       5.620401   \n",
      "...             ...     ...          ...       ...       ...            ...   \n",
      "260052     0.000000       1     0.448667  0.701714  1.098612       2.564949   \n",
      "260067     0.500000       1     0.885333  0.824500  4.682131       5.393628   \n",
      "260082     0.666667       1     0.856800  0.823284  3.218876       3.871201   \n",
      "260097     0.666667       1     0.856800  0.823284  3.091042       4.158883   \n",
      "260113     0.500000       1     0.605333  0.638370  3.496508       5.081404   \n",
      "\n",
      "        user_total_attempts  recent_solve_time  moving_average_solve_time  \\\n",
      "1035                   1036               46.0                       43.0   \n",
      "1706                    671               23.0                       25.6   \n",
      "3023                   1317                8.0                        7.6   \n",
      "4283                   1260               75.0                       76.0   \n",
      "4670                    387               17.0                       50.4   \n",
      "...                     ...                ...                        ...   \n",
      "260052                   24                2.0                    11669.4   \n",
      "260067                   15              107.0                    14147.6   \n",
      "260082                   15               24.0                    11996.8   \n",
      "260097                   15               21.0                     8437.4   \n",
      "260113                   16               32.0                    11163.6   \n",
      "\n",
      "        user_acc  \n",
      "1035    0.692085  \n",
      "1706    0.692996  \n",
      "3023    0.694761  \n",
      "4283    0.818254  \n",
      "4670    0.757106  \n",
      "...          ...  \n",
      "260052  0.291667  \n",
      "260067  0.466667  \n",
      "260082  0.466667  \n",
      "260097  0.133333  \n",
      "260113  0.687500  \n",
      "\n",
      "[744 rows x 54 columns]\n",
      "False\n",
      "(260114, 54)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_v7.csv')\n",
    "test =  pd.read_csv('/data/ephemeral/level2-dkt-recsys-06/data/FE_test_v7.csv')\n",
    "X = X.sort_values(by=[\"userID\", \"Timestamp\", \"assessmentItemID\"]).reset_index(drop=True)\n",
    "test = test.sort_values(by=[\"userID\", \"Timestamp\", \"assessmentItemID\"]).reset_index(drop=True)\n",
    "\n",
    "# test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "# test = test.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "# 유저 아이디 갯수 구하기\n",
    "unique_user_count = X['userID'].nunique()\n",
    "\n",
    "# 유저아이디 갯수 출력\n",
    "print(f'userIDnum {unique_user_count}')\n",
    "\n",
    "# 유저아이디 마지막 행 구하기\n",
    "last_rows = test.groupby('userID').tail(1)\n",
    "print(last_rows)\n",
    "# 마지막 행의 answerCode가 -1인지 확인\n",
    "are_last_answers_minus_one = (last_rows['answerCode'] == -1).all()\n",
    "\n",
    "print(are_last_answers_minus_one)\n",
    "\n",
    "# test 모양\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test[\"answerCode\"] == -1]\n",
    "X = X[X['answerCode']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LabelEncoder 적용\n",
    "\n",
    "label_encoders = {}\n",
    "for column in [\n",
    "    \"categorize_ItemAnswerRate\",\n",
    "    \"categorize_TagAnswerRate\",\n",
    "    \"categorize_TestAnswerRate\",\n",
    "    \"categorize_CumulativeUserItemAnswerRate\",\n",
    "    \"categorize_CumulativeUserTagAverageAnswerRate\",\n",
    "    \"categorize_CumulativeUserTagExponentialAverage\",\n",
    "    \"DayOfWeek\",\n",
    "    \"TimeOfDay\",\n",
    "    \"categorize_TagAnswerRate\",    \n",
    "    \"UserRecentTagAnswer\",\n",
    "    \"PreviousItemAnswer\",\n",
    "    \"categorize_TestAnswerRate\",\n",
    "]:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    # 테스트 데이터에 대해서는 transform만 적용\n",
    "    test[column] = le.transform(test[column])\n",
    "    label_encoders[column] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "# # 원-핫 인코딩 적용할 컬럼 선택\n",
    "# columns_to_encode = [\n",
    "#     \"UserRecentTagAnswer\",\n",
    "#     \"PreviousItemAnswer\",\n",
    "#     # 추가적으로 원-핫 인코딩을 적용할 다른 컬럼들을 여기에 추가\n",
    "# ]\n",
    "# for column in columns_to_encode:\n",
    "#     if column in X.columns:\n",
    "#         X = pd.get_dummies(X, columns=[column])\n",
    "#     if column in test.columns:\n",
    "#         test = pd.get_dummies(test, columns=[column])\n",
    "\n",
    "#         # 다른 필드들에 대해서도 동일하게 적용\n",
    "# print(X.shape)\n",
    "\n",
    "# 라벨로 이동 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525956, 54)\n",
      "(2525956, 52)\n",
      "['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp', 'KnowledgeTag', 'Itemseq', 'SolvingTime', 'CumulativeTime', 'Month', 'DayOfWeek', 'TimeOfDay', 'WeekOfYear', 'UserAvgSolvingTime', 'CumulativeItemCount', 'Item_last7days', 'Item_last30days', 'PastItemCount', 'CumulativeUserItemAnswerRate', 'ItemAnswerRate', 'AverageItemSolvingTime_Correct', 'AverageItemSolvingTime_Incorrect', 'AverageItemSolvingTime', 'Difference_SolvingTime_AvgItemSolvingTime', 'UserTagAvgSolvingTime', 'TagAnswerRate', 'CumulativeUserTagAverageAnswerRate', 'CumulativeUserTagExponentialAverage', 'UserCumulativeTagCount', 'UserRecentTagAnswer', 'PreviousItemAnswer', 'TestAnswerRate', 'categorize_solvingTime', 'categorize_ItemAnswerRate', 'categorize_TagAnswerRate', 'categorize_TestAnswerRate', 'categorize_CumulativeUserItemAnswerRate', 'categorize_CumulativeUserTagAverageAnswerRate', 'categorize_CumulativeUserTagExponentialAverage', 'user_test_correct_answer', 'user_test_total_answer', 'user_test_acc', 'user_tag_correct_answer', 'user_tag_total_answer', 'user_tag_acc', 'repeat', 'problem_acc', 'tag_acc', 'elapsed', 'total_elapsed', 'user_total_attempts', 'recent_solve_time', 'moving_average_solve_time', 'user_acc']\n"
     ]
    }
   ],
   "source": [
    "feat = X.columns.tolist()\n",
    "\n",
    "exclude_columns = [\"Timestamp\",\"answerCode\"]\n",
    "\n",
    "filtered_feat = [column for column in feat if column not in exclude_columns]\n",
    "\n",
    "print(X[feat].shape)\n",
    "print(X[filtered_feat].shape)\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"num_leaves\": 10,  # 최소값 10\n",
    "    \"learning_rate\": 0.0001,  # 최소값 0.0001\n",
    "    \"max_depth\": -1,  # -1 (깊이 제한 없음)\n",
    "    \"min_data_in_leaf\": 20,  # 최소값 20\n",
    "    \"feature_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_fraction\": 0.6,  # 최소값 0.6\n",
    "    \"bagging_freq\": 0,  # 최소값 0\n",
    "    \"lambda_l1\": 0.0,  # 최소값 0.0\n",
    "    \"lambda_l2\": 0.0,  # 최소값 0.0\n",
    "    \"cat_smooth\": 10,  # 최소값 10\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    auc = 0\n",
    "    acc = 0\n",
    "    test_preds = np.zeros(len(test))\n",
    "\n",
    "    # userID별 마지막 인덱스 찾기\n",
    "    last_indices = X.groupby(\"userID\").tail(1).index\n",
    "\n",
    "    # 학습 데이터셋 생성\n",
    "    X_train = X.drop(last_indices)\n",
    "    y_train = X_train[\"answerCode\"]\n",
    "\n",
    "    # 검증 데이터셋 생성\n",
    "    X_valid = X.loc[last_indices]\n",
    "    y_valid = X_valid[\"answerCode\"]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train[filtered_feat], y_train)\n",
    "    lgb_valid = lgb.Dataset(X_valid[filtered_feat], y_valid)\n",
    "\n",
    "    wandb.init(project=f\"lightgbm-sweep\", config=default_config)\n",
    "    wandb.run.name = f\"nofoldlgbm\"\n",
    "    current_params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"auc\"],\n",
    "        \"device\": \"cpu\",\n",
    "        \"num_leaves\": wandb.config.num_leaves,\n",
    "        \"learning_rate\": wandb.config.learning_rate,\n",
    "        \"max_depth\": wandb.config.max_depth,\n",
    "        \"min_data_in_leaf\": wandb.config.min_data_in_leaf,\n",
    "        \"feature_fraction\": wandb.config.feature_fraction,\n",
    "        \"bagging_fraction\": wandb.config.bagging_fraction,\n",
    "        \"bagging_freq\": wandb.config.bagging_freq,\n",
    "        \"lambda_l1\": wandb.config.lambda_l1,\n",
    "        \"lambda_l2\": wandb.config.lambda_l2,\n",
    "        \"cat_smooth\": wandb.config.cat_smooth,\n",
    "    }\n",
    "    model = lgb.train(\n",
    "        current_params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        num_boost_round=50000,\n",
    "        callbacks=[\n",
    "            wandb_callback(log_params=True, define_metric=True),\n",
    "            lgb.early_stopping(100),\n",
    "        ],\n",
    "        categorical_feature=[\n",
    "            \"userID\",\n",
    "            \"assessmentItemID\",\n",
    "            \"testId\",\n",
    "            \"KnowledgeTag\",\n",
    "            \"Month\"\n",
    "        ],\n",
    "    )\n",
    "    preds = model.predict(X_valid[filtered_feat])\n",
    "    acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_valid, preds)\n",
    "    test_preds += model.predict(test[filtered_feat])\n",
    "    print(f\"VALID AUC : {auc} ACC : {acc}\\n\")\n",
    "    wandb.log({\"auc\": auc, \"accuracy\": acc})\n",
    "    output_dir = \"output/\"\n",
    "    write_path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"auc:{auc} acc:{acc}\" + \"sweep\" + \" lgbm.csv\",\n",
    "    )\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "        print(\"writing prediction : {}\".format(write_path))\n",
    "        w.write(\"id,prediction\\n\")\n",
    "        for id, p in enumerate(test_preds):\n",
    "            w.write(\"{},{}\\n\".format(id, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m3j9xhki with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.6993547946794672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.6015347619200078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 11.066245303897327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 13.99826126670338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.4322292661158103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_185922-m3j9xhki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/m3j9xhki' target=\"_blank\">proud-sweep-1</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/m3j9xhki' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/m3j9xhki</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649973, number of negative: 868541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.372395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23235\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655138 -> initscore=0.641699\n",
      "[LightGBM] [Info] Start training from score 0.641699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[591]\ttraining's auc: 0.858957\tvalid_1's auc: 0.824354\n",
      "VALID AUC : 0.8243542912862347 ACC : 0.7484547164740661\n",
      "\n",
      "writing prediction : output/auc:0.8243542912862347 acc:0.7484547164740661sweep lgbm.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>valid_1_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█████▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.74845</td></tr><tr><td>auc</td><td>0.82435</td></tr><tr><td>iteration</td><td>690</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-1</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/m3j9xhki' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/m3j9xhki</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240123_185922-m3j9xhki/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3zo97vt9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.8304998973036604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.7816867238428115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 13.982075644335843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 6.688827655004626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.25462976143808735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_190336-3zo97vt9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/3zo97vt9' target=\"_blank\">bright-sweep-2</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/3zo97vt9' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/3zo97vt9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649973, number of negative: 868541\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23235\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655138 -> initscore=0.641699\n",
      "[LightGBM] [Info] Start training from score 0.641699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's auc: 0.875989\tvalid_1's auc: 0.832224\n",
      "VALID AUC : 0.8322236160699926 ACC : 0.7545014780972856\n",
      "\n",
      "writing prediction : output/auc:0.8322236160699926 acc:0.7545014780972856sweep lgbm.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>valid_1_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.7545</td></tr><tr><td>auc</td><td>0.83222</td></tr><tr><td>iteration</td><td>348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-sweep-2</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/3zo97vt9' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/3zo97vt9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240123_190336-3zo97vt9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k2tyg5sk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_fraction: 0.8816154229860389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbagging_freq: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature_fraction: 0.921439215996356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l1: 10.06932210585647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlambda_l2: 10.609820076613154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.16146209458676392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 38\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_leaves: 52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240123_190809-k2tyg5sk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/k2tyg5sk' target=\"_blank\">good-sweep-3</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/sweeps/dp3c9fep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/k2tyg5sk' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/lightgbm-sweep/runs/k2tyg5sk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1649973, number of negative: 868541\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23235\n",
      "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655138 -> initscore=0.641699\n",
      "[LightGBM] [Info] Start training from score 0.641699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_leaves' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_depth' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'min_data_in_leaf' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'feature_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_fraction' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bagging_freq' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lambda_l2' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's auc: 0.883112\tvalid_1's auc: 0.836112\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
