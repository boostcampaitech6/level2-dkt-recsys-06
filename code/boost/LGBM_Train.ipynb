{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    },
    "id": "Uq_TJqbdhfQu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_callback 수정 \n",
    "from typing import TYPE_CHECKING, Callable\n",
    "import wandb\n",
    "from wandb.sdk.lib import telemetry as wb_telemetry\n",
    "\n",
    "MINIMIZE_METRICS = [\n",
    "    \"l1\",\n",
    "    \"l2\",\n",
    "    \"rmse\",\n",
    "    \"mape\",\n",
    "    \"huber\",\n",
    "    \"fair\",\n",
    "    \"poisson\",\n",
    "    \"gamma\",\n",
    "    \"binary_logloss\",\n",
    "]\n",
    "\n",
    "MAXIMIZE_METRICS = [\"map\", \"auc\", \"average_precision\"]\n",
    "\n",
    "def _define_metric(data: str, metric_name: str) -> None:\n",
    "    \n",
    "    \"\"\"Capture model performance at the best step.\n",
    "\n",
    "    instead of the last step, of training in your `wandb.summary`\n",
    "    \"\"\"\n",
    "    if \"loss\" in str.lower(metric_name):\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "    elif str.lower(metric_name) in MINIMIZE_METRICS:\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"min\")\n",
    "    elif str.lower(metric_name) in MAXIMIZE_METRICS:\n",
    "        wandb.define_metric(f\"{data}_{metric_name}\", summary=\"max\")\n",
    "        \n",
    "def wandb_callback(log_params: bool = True, define_metric: bool = True) -> Callable:\n",
    "    \"\"\"Automatically integrates LightGBM with wandb.\n",
    "\n",
    "    Arguments:\n",
    "        log_params: (boolean) if True (default) logs params passed to lightgbm.train as W&B config\n",
    "        define_metric: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`\n",
    "\n",
    "    Passing `wandb_callback` to LightGBM will:\n",
    "      - log params passed to lightgbm.train as W&B config (default).\n",
    "      - log evaluation metrics collected by LightGBM, such as rmse, accuracy etc to Weights & Biases\n",
    "      - Capture the best metric in `wandb.summary` when `define_metric=True` (default).\n",
    "\n",
    "    Use `log_summary` as an extension of this callback.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            .\n",
    "        }\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()])\n",
    "        ```\n",
    "    \"\"\"\n",
    "    log_params_list: \"List[bool]\" = [log_params]\n",
    "    define_metric_list: \"List[bool]\" = [define_metric]\n",
    "\n",
    "    def _init(env: \"CallbackEnv\") -> None:\n",
    "        with wb_telemetry.context() as tel:\n",
    "            tel.feature.lightgbm_wandb_callback = True\n",
    "\n",
    "        wandb.config.update(env.params)\n",
    "        log_params_list[0] = False\n",
    "\n",
    "        if define_metric_list[0]:\n",
    "            for i in range(len(env.evaluation_result_list)):\n",
    "                data_type = env.evaluation_result_list[i][0]\n",
    "                metric_name = env.evaluation_result_list[i][1]\n",
    "                _define_metric(data_type, metric_name)\n",
    "\n",
    "    def _callback(env: \"CallbackEnv\") -> None:\n",
    "        if log_params_list[0]:\n",
    "            _init(env)\n",
    "        # eval_results: \"Dict[str, Dict[str, List[Any]]]\" = {}\n",
    "        # recorder = lightgbm.record_evaluation(eval_results)\n",
    "        # recorder(env)\n",
    "        eval_results = {x[0]:{x[1:][0]:x[1:][1:]} for x in env.evaluation_result_list}\n",
    "\n",
    "        for validation_key in eval_results.keys():\n",
    "            for key in eval_results[validation_key].keys():\n",
    "                 wandb.log(\n",
    "                     {validation_key + \"_\" + key: eval_results[validation_key][key][0]},\n",
    "                     commit=False,\n",
    "                 )\n",
    "        for item in eval_results:\n",
    "            if len(item) == 4:\n",
    "                wandb.log({f\"{item[0]}_{item[1]}\": item[2]}, commit=False)\n",
    "\n",
    "        # Previous log statements use commit=False. This commits them.\n",
    "        wandb.log({\"iteration\": env.iteration}, commit=True)\n",
    "\n",
    "    return _callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZlm5HSmhfQv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    },
    "id": "s6qgJ8MLhfQw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#경로에 맞게 수정\n",
    "X=pd.read_parquet('/data/ephemeral/level2-dkt-recsys-06/data/train_ppd_final_sfcv.parquet')\n",
    "test=pd.read_parquet('/data/ephemeral/level2-dkt-recsys-06/data/test_ppd_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y=X[\"answerCode\"]\n",
    "g=X[\"userID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat=[ 'KnowledgeTag', \n",
    "       'user_test_correct_answer', \n",
    "       'user_test_total_answer',\n",
    "       'user_test_acc', \n",
    "       'user_tag_correct_answer', \n",
    "       'user_tag_total_answer',\n",
    "       'user_tag_acc', \n",
    "       'testid_first', \n",
    "       'testid_rest', \n",
    "       'itemseq', \n",
    "       'item_mean',\n",
    "       'test_mean', \n",
    "       'tag_mean', \n",
    "       'item_std', \n",
    "       'test_std', \n",
    "       'tag_std', \n",
    "       'month',\n",
    "       'hour', \n",
    "       'repeat', \n",
    "       'elapse', \n",
    "       'total_elapse', \n",
    "       'encoded_time',\n",
    "       'user_tag_incorrect', \n",
    "       'user_tag_inacc' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /opt/ml/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240118_141150-e5tollwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/e5tollwh' target=\"_blank\">lucky-wind-1</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/e5tollwh' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/e5tollwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322873, number of negative: 697897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3897\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020770, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654638 -> initscore=0.639490\n",
      "[LightGBM] [Info] Start training from score 0.639490\n",
      "[1]\ttraining's auc: 0.810993\tvalid_1's auc: 0.794067\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.814312\tvalid_1's auc: 0.798142\n",
      "[3]\ttraining's auc: 0.818308\tvalid_1's auc: 0.802148\n",
      "[4]\ttraining's auc: 0.819049\tvalid_1's auc: 0.802638\n",
      "[5]\ttraining's auc: 0.820715\tvalid_1's auc: 0.805464\n",
      "[6]\ttraining's auc: 0.821511\tvalid_1's auc: 0.806752\n",
      "[7]\ttraining's auc: 0.822557\tvalid_1's auc: 0.808137\n",
      "[8]\ttraining's auc: 0.823103\tvalid_1's auc: 0.80836\n",
      "[9]\ttraining's auc: 0.823801\tvalid_1's auc: 0.808911\n",
      "[10]\ttraining's auc: 0.824298\tvalid_1's auc: 0.809455\n",
      "[11]\ttraining's auc: 0.824745\tvalid_1's auc: 0.809698\n",
      "[12]\ttraining's auc: 0.825475\tvalid_1's auc: 0.810258\n",
      "[13]\ttraining's auc: 0.826052\tvalid_1's auc: 0.810773\n",
      "[14]\ttraining's auc: 0.82656\tvalid_1's auc: 0.810853\n",
      "[15]\ttraining's auc: 0.827272\tvalid_1's auc: 0.811415\n",
      "[16]\ttraining's auc: 0.827834\tvalid_1's auc: 0.811893\n",
      "[17]\ttraining's auc: 0.828169\tvalid_1's auc: 0.812302\n",
      "[18]\ttraining's auc: 0.828712\tvalid_1's auc: 0.812767\n",
      "[19]\ttraining's auc: 0.829048\tvalid_1's auc: 0.813026\n",
      "[20]\ttraining's auc: 0.829489\tvalid_1's auc: 0.81336\n",
      "[21]\ttraining's auc: 0.829875\tvalid_1's auc: 0.813408\n",
      "[22]\ttraining's auc: 0.830225\tvalid_1's auc: 0.814008\n",
      "[23]\ttraining's auc: 0.830545\tvalid_1's auc: 0.814141\n",
      "[24]\ttraining's auc: 0.830958\tvalid_1's auc: 0.814686\n",
      "[25]\ttraining's auc: 0.831315\tvalid_1's auc: 0.815057\n",
      "[26]\ttraining's auc: 0.831589\tvalid_1's auc: 0.815322\n",
      "[27]\ttraining's auc: 0.831882\tvalid_1's auc: 0.815195\n",
      "[28]\ttraining's auc: 0.832167\tvalid_1's auc: 0.815432\n",
      "[29]\ttraining's auc: 0.832513\tvalid_1's auc: 0.815445\n",
      "[30]\ttraining's auc: 0.83279\tvalid_1's auc: 0.815663\n",
      "[31]\ttraining's auc: 0.833111\tvalid_1's auc: 0.8162\n",
      "[32]\ttraining's auc: 0.833366\tvalid_1's auc: 0.816338\n",
      "[33]\ttraining's auc: 0.833575\tvalid_1's auc: 0.816637\n",
      "[34]\ttraining's auc: 0.83388\tvalid_1's auc: 0.816607\n",
      "[35]\ttraining's auc: 0.834127\tvalid_1's auc: 0.816913\n",
      "[36]\ttraining's auc: 0.834333\tvalid_1's auc: 0.817016\n",
      "[37]\ttraining's auc: 0.834555\tvalid_1's auc: 0.81706\n",
      "[38]\ttraining's auc: 0.834817\tvalid_1's auc: 0.817231\n",
      "[39]\ttraining's auc: 0.835036\tvalid_1's auc: 0.817474\n",
      "[40]\ttraining's auc: 0.835242\tvalid_1's auc: 0.817638\n",
      "[41]\ttraining's auc: 0.835433\tvalid_1's auc: 0.818122\n",
      "[42]\ttraining's auc: 0.835655\tvalid_1's auc: 0.81822\n",
      "[43]\ttraining's auc: 0.835912\tvalid_1's auc: 0.818368\n",
      "[44]\ttraining's auc: 0.836084\tvalid_1's auc: 0.818384\n",
      "[45]\ttraining's auc: 0.836254\tvalid_1's auc: 0.818459\n",
      "[46]\ttraining's auc: 0.836417\tvalid_1's auc: 0.818363\n",
      "[47]\ttraining's auc: 0.836578\tvalid_1's auc: 0.818384\n",
      "[48]\ttraining's auc: 0.836744\tvalid_1's auc: 0.818785\n",
      "[49]\ttraining's auc: 0.836923\tvalid_1's auc: 0.818845\n",
      "[50]\ttraining's auc: 0.837067\tvalid_1's auc: 0.819014\n",
      "[51]\ttraining's auc: 0.837273\tvalid_1's auc: 0.819133\n",
      "[52]\ttraining's auc: 0.8374\tvalid_1's auc: 0.819263\n",
      "[53]\ttraining's auc: 0.837574\tvalid_1's auc: 0.819419\n",
      "[54]\ttraining's auc: 0.837705\tvalid_1's auc: 0.819415\n",
      "[55]\ttraining's auc: 0.837874\tvalid_1's auc: 0.819669\n",
      "[56]\ttraining's auc: 0.838003\tvalid_1's auc: 0.81987\n",
      "[57]\ttraining's auc: 0.838169\tvalid_1's auc: 0.819845\n",
      "[58]\ttraining's auc: 0.8383\tvalid_1's auc: 0.819911\n",
      "[59]\ttraining's auc: 0.838414\tvalid_1's auc: 0.819886\n",
      "[60]\ttraining's auc: 0.83852\tvalid_1's auc: 0.819872\n",
      "[61]\ttraining's auc: 0.838681\tvalid_1's auc: 0.820181\n",
      "[62]\ttraining's auc: 0.838836\tvalid_1's auc: 0.820312\n",
      "[63]\ttraining's auc: 0.838966\tvalid_1's auc: 0.820673\n",
      "[64]\ttraining's auc: 0.839068\tvalid_1's auc: 0.820898\n",
      "[65]\ttraining's auc: 0.839185\tvalid_1's auc: 0.820779\n",
      "[66]\ttraining's auc: 0.839313\tvalid_1's auc: 0.820795\n",
      "[67]\ttraining's auc: 0.839409\tvalid_1's auc: 0.820819\n",
      "[68]\ttraining's auc: 0.839499\tvalid_1's auc: 0.821004\n",
      "[69]\ttraining's auc: 0.839611\tvalid_1's auc: 0.821017\n",
      "[70]\ttraining's auc: 0.839698\tvalid_1's auc: 0.821093\n",
      "[71]\ttraining's auc: 0.839831\tvalid_1's auc: 0.821059\n",
      "[72]\ttraining's auc: 0.839946\tvalid_1's auc: 0.821232\n",
      "[73]\ttraining's auc: 0.840048\tvalid_1's auc: 0.821533\n",
      "[74]\ttraining's auc: 0.840142\tvalid_1's auc: 0.821514\n",
      "[75]\ttraining's auc: 0.84023\tvalid_1's auc: 0.821448\n",
      "[76]\ttraining's auc: 0.840332\tvalid_1's auc: 0.82164\n",
      "[77]\ttraining's auc: 0.840415\tvalid_1's auc: 0.821615\n",
      "[78]\ttraining's auc: 0.84051\tvalid_1's auc: 0.82169\n",
      "[79]\ttraining's auc: 0.840635\tvalid_1's auc: 0.821753\n",
      "[80]\ttraining's auc: 0.840712\tvalid_1's auc: 0.821738\n",
      "[81]\ttraining's auc: 0.84081\tvalid_1's auc: 0.821603\n",
      "[82]\ttraining's auc: 0.840887\tvalid_1's auc: 0.821574\n",
      "[83]\ttraining's auc: 0.840963\tvalid_1's auc: 0.821576\n",
      "[84]\ttraining's auc: 0.841024\tvalid_1's auc: 0.821576\n",
      "[85]\ttraining's auc: 0.841108\tvalid_1's auc: 0.821626\n",
      "[86]\ttraining's auc: 0.841179\tvalid_1's auc: 0.821674\n",
      "[87]\ttraining's auc: 0.841268\tvalid_1's auc: 0.821534\n",
      "[88]\ttraining's auc: 0.841334\tvalid_1's auc: 0.821566\n",
      "[89]\ttraining's auc: 0.841403\tvalid_1's auc: 0.821618\n",
      "[90]\ttraining's auc: 0.841479\tvalid_1's auc: 0.821632\n",
      "[91]\ttraining's auc: 0.841533\tvalid_1's auc: 0.821566\n",
      "[92]\ttraining's auc: 0.84163\tvalid_1's auc: 0.821641\n",
      "[93]\ttraining's auc: 0.841728\tvalid_1's auc: 0.821676\n",
      "[94]\ttraining's auc: 0.841801\tvalid_1's auc: 0.821664\n",
      "[95]\ttraining's auc: 0.841898\tvalid_1's auc: 0.821671\n",
      "[96]\ttraining's auc: 0.841965\tvalid_1's auc: 0.821945\n",
      "[97]\ttraining's auc: 0.842046\tvalid_1's auc: 0.822136\n",
      "[98]\ttraining's auc: 0.842147\tvalid_1's auc: 0.822144\n",
      "[99]\ttraining's auc: 0.842216\tvalid_1's auc: 0.822097\n",
      "[100]\ttraining's auc: 0.84229\tvalid_1's auc: 0.822154\n",
      "[101]\ttraining's auc: 0.842342\tvalid_1's auc: 0.822271\n",
      "[102]\ttraining's auc: 0.842417\tvalid_1's auc: 0.822289\n",
      "[103]\ttraining's auc: 0.842467\tvalid_1's auc: 0.822348\n",
      "[104]\ttraining's auc: 0.84255\tvalid_1's auc: 0.822215\n",
      "[105]\ttraining's auc: 0.842639\tvalid_1's auc: 0.822303\n",
      "[106]\ttraining's auc: 0.842702\tvalid_1's auc: 0.82246\n",
      "[107]\ttraining's auc: 0.842751\tvalid_1's auc: 0.822525\n",
      "[108]\ttraining's auc: 0.842804\tvalid_1's auc: 0.822533\n",
      "[109]\ttraining's auc: 0.84287\tvalid_1's auc: 0.822618\n",
      "[110]\ttraining's auc: 0.842964\tvalid_1's auc: 0.822819\n",
      "[111]\ttraining's auc: 0.84306\tvalid_1's auc: 0.822768\n",
      "[112]\ttraining's auc: 0.843118\tvalid_1's auc: 0.822779\n",
      "[113]\ttraining's auc: 0.843164\tvalid_1's auc: 0.822896\n",
      "[114]\ttraining's auc: 0.843215\tvalid_1's auc: 0.823089\n",
      "[115]\ttraining's auc: 0.84327\tvalid_1's auc: 0.822956\n",
      "[116]\ttraining's auc: 0.84334\tvalid_1's auc: 0.822901\n",
      "[117]\ttraining's auc: 0.843417\tvalid_1's auc: 0.822953\n",
      "[118]\ttraining's auc: 0.84349\tvalid_1's auc: 0.82316\n",
      "[119]\ttraining's auc: 0.843559\tvalid_1's auc: 0.823338\n",
      "[120]\ttraining's auc: 0.843627\tvalid_1's auc: 0.823263\n",
      "[121]\ttraining's auc: 0.84369\tvalid_1's auc: 0.823409\n",
      "[122]\ttraining's auc: 0.843753\tvalid_1's auc: 0.823368\n",
      "[123]\ttraining's auc: 0.843817\tvalid_1's auc: 0.823334\n",
      "[124]\ttraining's auc: 0.843885\tvalid_1's auc: 0.823299\n",
      "[125]\ttraining's auc: 0.843937\tvalid_1's auc: 0.823214\n",
      "[126]\ttraining's auc: 0.843988\tvalid_1's auc: 0.823274\n",
      "[127]\ttraining's auc: 0.844035\tvalid_1's auc: 0.823226\n",
      "[128]\ttraining's auc: 0.844086\tvalid_1's auc: 0.823221\n",
      "[129]\ttraining's auc: 0.844122\tvalid_1's auc: 0.823173\n",
      "[130]\ttraining's auc: 0.844144\tvalid_1's auc: 0.823182\n",
      "[131]\ttraining's auc: 0.844193\tvalid_1's auc: 0.823199\n",
      "[132]\ttraining's auc: 0.844244\tvalid_1's auc: 0.823095\n",
      "[133]\ttraining's auc: 0.844295\tvalid_1's auc: 0.823123\n",
      "[134]\ttraining's auc: 0.84434\tvalid_1's auc: 0.823301\n",
      "[135]\ttraining's auc: 0.844409\tvalid_1's auc: 0.823379\n",
      "[136]\ttraining's auc: 0.844451\tvalid_1's auc: 0.82345\n",
      "[137]\ttraining's auc: 0.844492\tvalid_1's auc: 0.823391\n",
      "[138]\ttraining's auc: 0.844544\tvalid_1's auc: 0.823421\n",
      "[139]\ttraining's auc: 0.84459\tvalid_1's auc: 0.823395\n",
      "[140]\ttraining's auc: 0.844631\tvalid_1's auc: 0.823338\n",
      "[141]\ttraining's auc: 0.844669\tvalid_1's auc: 0.823551\n",
      "[142]\ttraining's auc: 0.844704\tvalid_1's auc: 0.823544\n",
      "[143]\ttraining's auc: 0.844745\tvalid_1's auc: 0.823553\n",
      "[144]\ttraining's auc: 0.844796\tvalid_1's auc: 0.823624\n",
      "[145]\ttraining's auc: 0.844835\tvalid_1's auc: 0.823596\n",
      "[146]\ttraining's auc: 0.84488\tvalid_1's auc: 0.823626\n",
      "[147]\ttraining's auc: 0.844937\tvalid_1's auc: 0.823628\n",
      "[148]\ttraining's auc: 0.844996\tvalid_1's auc: 0.823633\n",
      "[149]\ttraining's auc: 0.84504\tvalid_1's auc: 0.823631\n",
      "[150]\ttraining's auc: 0.84508\tvalid_1's auc: 0.823707\n",
      "[151]\ttraining's auc: 0.845112\tvalid_1's auc: 0.82364\n",
      "[152]\ttraining's auc: 0.84516\tvalid_1's auc: 0.823727\n",
      "[153]\ttraining's auc: 0.845261\tvalid_1's auc: 0.823674\n",
      "[154]\ttraining's auc: 0.845298\tvalid_1's auc: 0.823642\n",
      "[155]\ttraining's auc: 0.845339\tvalid_1's auc: 0.823745\n",
      "[156]\ttraining's auc: 0.84538\tvalid_1's auc: 0.823741\n",
      "[157]\ttraining's auc: 0.845427\tvalid_1's auc: 0.82377\n",
      "[158]\ttraining's auc: 0.845461\tvalid_1's auc: 0.823819\n",
      "[159]\ttraining's auc: 0.845522\tvalid_1's auc: 0.823606\n",
      "[160]\ttraining's auc: 0.845548\tvalid_1's auc: 0.823606\n",
      "[161]\ttraining's auc: 0.845565\tvalid_1's auc: 0.823578\n",
      "[162]\ttraining's auc: 0.845597\tvalid_1's auc: 0.823789\n",
      "[163]\ttraining's auc: 0.845636\tvalid_1's auc: 0.823798\n",
      "[164]\ttraining's auc: 0.845669\tvalid_1's auc: 0.82378\n",
      "[165]\ttraining's auc: 0.845718\tvalid_1's auc: 0.823787\n",
      "[166]\ttraining's auc: 0.845757\tvalid_1's auc: 0.823777\n",
      "[167]\ttraining's auc: 0.845821\tvalid_1's auc: 0.823842\n",
      "[168]\ttraining's auc: 0.845855\tvalid_1's auc: 0.823881\n",
      "[169]\ttraining's auc: 0.845901\tvalid_1's auc: 0.824036\n",
      "[170]\ttraining's auc: 0.845946\tvalid_1's auc: 0.824105\n",
      "[171]\ttraining's auc: 0.845988\tvalid_1's auc: 0.824048\n",
      "[172]\ttraining's auc: 0.846035\tvalid_1's auc: 0.824088\n",
      "[173]\ttraining's auc: 0.846068\tvalid_1's auc: 0.824066\n",
      "[174]\ttraining's auc: 0.846101\tvalid_1's auc: 0.824167\n",
      "[175]\ttraining's auc: 0.846182\tvalid_1's auc: 0.824157\n",
      "[176]\ttraining's auc: 0.8462\tvalid_1's auc: 0.824153\n",
      "[177]\ttraining's auc: 0.846234\tvalid_1's auc: 0.824068\n",
      "[178]\ttraining's auc: 0.846257\tvalid_1's auc: 0.824002\n",
      "[179]\ttraining's auc: 0.846275\tvalid_1's auc: 0.824031\n",
      "[180]\ttraining's auc: 0.846342\tvalid_1's auc: 0.824063\n",
      "[181]\ttraining's auc: 0.846384\tvalid_1's auc: 0.824132\n",
      "[182]\ttraining's auc: 0.846416\tvalid_1's auc: 0.824116\n",
      "[183]\ttraining's auc: 0.846437\tvalid_1's auc: 0.824089\n",
      "[184]\ttraining's auc: 0.846486\tvalid_1's auc: 0.824214\n",
      "[185]\ttraining's auc: 0.846508\tvalid_1's auc: 0.824143\n",
      "[186]\ttraining's auc: 0.846521\tvalid_1's auc: 0.824112\n",
      "[187]\ttraining's auc: 0.846544\tvalid_1's auc: 0.824134\n",
      "[188]\ttraining's auc: 0.846573\tvalid_1's auc: 0.824192\n",
      "[189]\ttraining's auc: 0.846629\tvalid_1's auc: 0.824311\n",
      "[190]\ttraining's auc: 0.846664\tvalid_1's auc: 0.824301\n",
      "[191]\ttraining's auc: 0.846695\tvalid_1's auc: 0.824301\n",
      "[192]\ttraining's auc: 0.846721\tvalid_1's auc: 0.824379\n",
      "[193]\ttraining's auc: 0.846761\tvalid_1's auc: 0.824414\n",
      "[194]\ttraining's auc: 0.846809\tvalid_1's auc: 0.824375\n",
      "[195]\ttraining's auc: 0.846835\tvalid_1's auc: 0.824254\n",
      "[196]\ttraining's auc: 0.846881\tvalid_1's auc: 0.824265\n",
      "[197]\ttraining's auc: 0.846907\tvalid_1's auc: 0.824258\n",
      "[198]\ttraining's auc: 0.846977\tvalid_1's auc: 0.824203\n",
      "[199]\ttraining's auc: 0.846997\tvalid_1's auc: 0.824207\n",
      "[200]\ttraining's auc: 0.847032\tvalid_1's auc: 0.824226\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[193]\ttraining's auc: 0.846761\tvalid_1's auc: 0.824414\n",
      "Fold 0 VALID AUC : 0.8244143296094347 ACC : 0.7471723220226214\n",
      "\n",
      "Fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e5tollwh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-wind-1</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/e5tollwh' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/e5tollwh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240118_141150-e5tollwh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e5tollwh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240118_141233-6wiucq1b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/6wiucq1b' target=\"_blank\">royal-thunder-2</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/6wiucq1b' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/6wiucq1b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322899, number of negative: 697890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3905\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020789, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654645 -> initscore=0.639519\n",
      "[LightGBM] [Info] Start training from score 0.639519\n",
      "[1]\ttraining's auc: 0.811555\tvalid_1's auc: 0.802111\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.817806\tvalid_1's auc: 0.811653\n",
      "[3]\ttraining's auc: 0.81914\tvalid_1's auc: 0.81396\n",
      "[4]\ttraining's auc: 0.820421\tvalid_1's auc: 0.815666\n",
      "[5]\ttraining's auc: 0.8215\tvalid_1's auc: 0.816851\n",
      "[6]\ttraining's auc: 0.822385\tvalid_1's auc: 0.817616\n",
      "[7]\ttraining's auc: 0.823356\tvalid_1's auc: 0.818637\n",
      "[8]\ttraining's auc: 0.824081\tvalid_1's auc: 0.818888\n",
      "[9]\ttraining's auc: 0.824913\tvalid_1's auc: 0.819783\n",
      "[10]\ttraining's auc: 0.825374\tvalid_1's auc: 0.820992\n",
      "[11]\ttraining's auc: 0.825889\tvalid_1's auc: 0.821461\n",
      "[12]\ttraining's auc: 0.826301\tvalid_1's auc: 0.821602\n",
      "[13]\ttraining's auc: 0.827034\tvalid_1's auc: 0.82205\n",
      "[14]\ttraining's auc: 0.827437\tvalid_1's auc: 0.822307\n",
      "[15]\ttraining's auc: 0.827798\tvalid_1's auc: 0.822504\n",
      "[16]\ttraining's auc: 0.828359\tvalid_1's auc: 0.823136\n",
      "[17]\ttraining's auc: 0.828984\tvalid_1's auc: 0.823525\n",
      "[18]\ttraining's auc: 0.829429\tvalid_1's auc: 0.824113\n",
      "[19]\ttraining's auc: 0.829796\tvalid_1's auc: 0.824398\n",
      "[20]\ttraining's auc: 0.830116\tvalid_1's auc: 0.824619\n",
      "[21]\ttraining's auc: 0.830431\tvalid_1's auc: 0.82497\n",
      "[22]\ttraining's auc: 0.830753\tvalid_1's auc: 0.825219\n",
      "[23]\ttraining's auc: 0.831245\tvalid_1's auc: 0.826074\n",
      "[24]\ttraining's auc: 0.831555\tvalid_1's auc: 0.826271\n",
      "[25]\ttraining's auc: 0.831868\tvalid_1's auc: 0.826686\n",
      "[26]\ttraining's auc: 0.832186\tvalid_1's auc: 0.826887\n",
      "[27]\ttraining's auc: 0.832559\tvalid_1's auc: 0.827557\n",
      "[28]\ttraining's auc: 0.832895\tvalid_1's auc: 0.827791\n",
      "[29]\ttraining's auc: 0.833154\tvalid_1's auc: 0.827999\n",
      "[30]\ttraining's auc: 0.833414\tvalid_1's auc: 0.828264\n",
      "[31]\ttraining's auc: 0.833726\tvalid_1's auc: 0.828449\n",
      "[32]\ttraining's auc: 0.834075\tvalid_1's auc: 0.828976\n",
      "[33]\ttraining's auc: 0.834345\tvalid_1's auc: 0.829344\n",
      "[34]\ttraining's auc: 0.834568\tvalid_1's auc: 0.829638\n",
      "[35]\ttraining's auc: 0.834816\tvalid_1's auc: 0.830234\n",
      "[36]\ttraining's auc: 0.835031\tvalid_1's auc: 0.830621\n",
      "[37]\ttraining's auc: 0.835229\tvalid_1's auc: 0.830677\n",
      "[38]\ttraining's auc: 0.835456\tvalid_1's auc: 0.830765\n",
      "[39]\ttraining's auc: 0.835682\tvalid_1's auc: 0.830863\n",
      "[40]\ttraining's auc: 0.835884\tvalid_1's auc: 0.831118\n",
      "[41]\ttraining's auc: 0.836077\tvalid_1's auc: 0.831335\n",
      "[42]\ttraining's auc: 0.83625\tvalid_1's auc: 0.831578\n",
      "[43]\ttraining's auc: 0.836435\tvalid_1's auc: 0.831724\n",
      "[44]\ttraining's auc: 0.836597\tvalid_1's auc: 0.832038\n",
      "[45]\ttraining's auc: 0.836782\tvalid_1's auc: 0.832073\n",
      "[46]\ttraining's auc: 0.837\tvalid_1's auc: 0.832173\n",
      "[47]\ttraining's auc: 0.837186\tvalid_1's auc: 0.832544\n",
      "[48]\ttraining's auc: 0.837335\tvalid_1's auc: 0.832673\n",
      "[49]\ttraining's auc: 0.837471\tvalid_1's auc: 0.832969\n",
      "[50]\ttraining's auc: 0.837609\tvalid_1's auc: 0.833236\n",
      "[51]\ttraining's auc: 0.837801\tvalid_1's auc: 0.833295\n",
      "[52]\ttraining's auc: 0.837943\tvalid_1's auc: 0.833418\n",
      "[53]\ttraining's auc: 0.838087\tvalid_1's auc: 0.833692\n",
      "[54]\ttraining's auc: 0.838229\tvalid_1's auc: 0.833726\n",
      "[55]\ttraining's auc: 0.838397\tvalid_1's auc: 0.834103\n",
      "[56]\ttraining's auc: 0.838529\tvalid_1's auc: 0.834075\n",
      "[57]\ttraining's auc: 0.838712\tvalid_1's auc: 0.834131\n",
      "[58]\ttraining's auc: 0.838855\tvalid_1's auc: 0.834211\n",
      "[59]\ttraining's auc: 0.838985\tvalid_1's auc: 0.834288\n",
      "[60]\ttraining's auc: 0.839094\tvalid_1's auc: 0.834613\n",
      "[61]\ttraining's auc: 0.839201\tvalid_1's auc: 0.834756\n",
      "[62]\ttraining's auc: 0.839312\tvalid_1's auc: 0.834746\n",
      "[63]\ttraining's auc: 0.839421\tvalid_1's auc: 0.834701\n",
      "[64]\ttraining's auc: 0.839517\tvalid_1's auc: 0.834693\n",
      "[65]\ttraining's auc: 0.839643\tvalid_1's auc: 0.834818\n",
      "[66]\ttraining's auc: 0.839794\tvalid_1's auc: 0.835096\n",
      "[67]\ttraining's auc: 0.839913\tvalid_1's auc: 0.834984\n",
      "[68]\ttraining's auc: 0.840001\tvalid_1's auc: 0.835056\n",
      "[69]\ttraining's auc: 0.840105\tvalid_1's auc: 0.834932\n",
      "[70]\ttraining's auc: 0.840184\tvalid_1's auc: 0.83505\n",
      "[71]\ttraining's auc: 0.840284\tvalid_1's auc: 0.835189\n",
      "[72]\ttraining's auc: 0.840404\tvalid_1's auc: 0.835287\n",
      "[73]\ttraining's auc: 0.840516\tvalid_1's auc: 0.835459\n",
      "[74]\ttraining's auc: 0.840622\tvalid_1's auc: 0.835462\n",
      "[75]\ttraining's auc: 0.840711\tvalid_1's auc: 0.835585\n",
      "[76]\ttraining's auc: 0.840801\tvalid_1's auc: 0.835616\n",
      "[77]\ttraining's auc: 0.84093\tvalid_1's auc: 0.835803\n",
      "[78]\ttraining's auc: 0.841041\tvalid_1's auc: 0.83572\n",
      "[79]\ttraining's auc: 0.841158\tvalid_1's auc: 0.835802\n",
      "[80]\ttraining's auc: 0.841227\tvalid_1's auc: 0.835977\n",
      "[81]\ttraining's auc: 0.841318\tvalid_1's auc: 0.83607\n",
      "[82]\ttraining's auc: 0.84141\tvalid_1's auc: 0.836133\n",
      "[83]\ttraining's auc: 0.84148\tvalid_1's auc: 0.836129\n",
      "[84]\ttraining's auc: 0.841572\tvalid_1's auc: 0.836177\n",
      "[85]\ttraining's auc: 0.841693\tvalid_1's auc: 0.836332\n",
      "[86]\ttraining's auc: 0.841785\tvalid_1's auc: 0.836352\n",
      "[87]\ttraining's auc: 0.841866\tvalid_1's auc: 0.836354\n",
      "[88]\ttraining's auc: 0.841937\tvalid_1's auc: 0.836432\n",
      "[89]\ttraining's auc: 0.842027\tvalid_1's auc: 0.836559\n",
      "[90]\ttraining's auc: 0.842094\tvalid_1's auc: 0.836563\n",
      "[91]\ttraining's auc: 0.842162\tvalid_1's auc: 0.836529\n",
      "[92]\ttraining's auc: 0.842238\tvalid_1's auc: 0.836437\n",
      "[93]\ttraining's auc: 0.842335\tvalid_1's auc: 0.836491\n",
      "[94]\ttraining's auc: 0.842411\tvalid_1's auc: 0.836571\n",
      "[95]\ttraining's auc: 0.842466\tvalid_1's auc: 0.836588\n",
      "[96]\ttraining's auc: 0.842547\tvalid_1's auc: 0.83665\n",
      "[97]\ttraining's auc: 0.842628\tvalid_1's auc: 0.83668\n",
      "[98]\ttraining's auc: 0.842679\tvalid_1's auc: 0.836737\n",
      "[99]\ttraining's auc: 0.842739\tvalid_1's auc: 0.83675\n",
      "[100]\ttraining's auc: 0.842836\tvalid_1's auc: 0.836828\n",
      "[101]\ttraining's auc: 0.842891\tvalid_1's auc: 0.836879\n",
      "[102]\ttraining's auc: 0.842952\tvalid_1's auc: 0.836867\n",
      "[103]\ttraining's auc: 0.843039\tvalid_1's auc: 0.83692\n",
      "[104]\ttraining's auc: 0.8431\tvalid_1's auc: 0.836967\n",
      "[105]\ttraining's auc: 0.843163\tvalid_1's auc: 0.837052\n",
      "[106]\ttraining's auc: 0.843219\tvalid_1's auc: 0.837164\n",
      "[107]\ttraining's auc: 0.843285\tvalid_1's auc: 0.837226\n",
      "[108]\ttraining's auc: 0.843344\tvalid_1's auc: 0.837194\n",
      "[109]\ttraining's auc: 0.843404\tvalid_1's auc: 0.837209\n",
      "[110]\ttraining's auc: 0.84346\tvalid_1's auc: 0.837207\n",
      "[111]\ttraining's auc: 0.843524\tvalid_1's auc: 0.837241\n",
      "[112]\ttraining's auc: 0.843586\tvalid_1's auc: 0.837377\n",
      "[113]\ttraining's auc: 0.843638\tvalid_1's auc: 0.837442\n",
      "[114]\ttraining's auc: 0.843698\tvalid_1's auc: 0.837502\n",
      "[115]\ttraining's auc: 0.843757\tvalid_1's auc: 0.837519\n",
      "[116]\ttraining's auc: 0.843816\tvalid_1's auc: 0.837489\n",
      "[117]\ttraining's auc: 0.843911\tvalid_1's auc: 0.83754\n",
      "[118]\ttraining's auc: 0.843966\tvalid_1's auc: 0.837523\n",
      "[119]\ttraining's auc: 0.844014\tvalid_1's auc: 0.837472\n",
      "[120]\ttraining's auc: 0.844082\tvalid_1's auc: 0.837546\n",
      "[121]\ttraining's auc: 0.844125\tvalid_1's auc: 0.837638\n",
      "[122]\ttraining's auc: 0.844173\tvalid_1's auc: 0.837646\n",
      "[123]\ttraining's auc: 0.844241\tvalid_1's auc: 0.837731\n",
      "[124]\ttraining's auc: 0.844307\tvalid_1's auc: 0.837827\n",
      "[125]\ttraining's auc: 0.844364\tvalid_1's auc: 0.83781\n",
      "[126]\ttraining's auc: 0.844402\tvalid_1's auc: 0.837882\n",
      "[127]\ttraining's auc: 0.844447\tvalid_1's auc: 0.837924\n",
      "[128]\ttraining's auc: 0.844487\tvalid_1's auc: 0.838041\n",
      "[129]\ttraining's auc: 0.84453\tvalid_1's auc: 0.838012\n",
      "[130]\ttraining's auc: 0.844585\tvalid_1's auc: 0.838003\n",
      "[131]\ttraining's auc: 0.844662\tvalid_1's auc: 0.838005\n",
      "[132]\ttraining's auc: 0.844713\tvalid_1's auc: 0.837988\n",
      "[133]\ttraining's auc: 0.844757\tvalid_1's auc: 0.837935\n",
      "[134]\ttraining's auc: 0.844817\tvalid_1's auc: 0.837988\n",
      "[135]\ttraining's auc: 0.844866\tvalid_1's auc: 0.838039\n",
      "[136]\ttraining's auc: 0.844923\tvalid_1's auc: 0.838046\n",
      "[137]\ttraining's auc: 0.844968\tvalid_1's auc: 0.838131\n",
      "[138]\ttraining's auc: 0.845006\tvalid_1's auc: 0.838058\n",
      "[139]\ttraining's auc: 0.845038\tvalid_1's auc: 0.838163\n",
      "[140]\ttraining's auc: 0.845082\tvalid_1's auc: 0.838335\n",
      "[141]\ttraining's auc: 0.845123\tvalid_1's auc: 0.838318\n",
      "[142]\ttraining's auc: 0.845206\tvalid_1's auc: 0.838456\n",
      "[143]\ttraining's auc: 0.845254\tvalid_1's auc: 0.838368\n",
      "[144]\ttraining's auc: 0.845311\tvalid_1's auc: 0.838385\n",
      "[145]\ttraining's auc: 0.845358\tvalid_1's auc: 0.838449\n",
      "[146]\ttraining's auc: 0.845393\tvalid_1's auc: 0.838409\n",
      "[147]\ttraining's auc: 0.845457\tvalid_1's auc: 0.83842\n",
      "[148]\ttraining's auc: 0.845491\tvalid_1's auc: 0.838436\n",
      "[149]\ttraining's auc: 0.845526\tvalid_1's auc: 0.838479\n",
      "[150]\ttraining's auc: 0.845557\tvalid_1's auc: 0.838439\n",
      "[151]\ttraining's auc: 0.845627\tvalid_1's auc: 0.838543\n",
      "[152]\ttraining's auc: 0.845665\tvalid_1's auc: 0.838485\n",
      "[153]\ttraining's auc: 0.845711\tvalid_1's auc: 0.838526\n",
      "[154]\ttraining's auc: 0.845754\tvalid_1's auc: 0.838625\n",
      "[155]\ttraining's auc: 0.845787\tvalid_1's auc: 0.838659\n",
      "[156]\ttraining's auc: 0.845825\tvalid_1's auc: 0.838587\n",
      "[157]\ttraining's auc: 0.845873\tvalid_1's auc: 0.838638\n",
      "[158]\ttraining's auc: 0.845902\tvalid_1's auc: 0.838715\n",
      "[159]\ttraining's auc: 0.845929\tvalid_1's auc: 0.838744\n",
      "[160]\ttraining's auc: 0.845962\tvalid_1's auc: 0.838753\n",
      "[161]\ttraining's auc: 0.846012\tvalid_1's auc: 0.838753\n",
      "[162]\ttraining's auc: 0.846031\tvalid_1's auc: 0.838738\n",
      "[163]\ttraining's auc: 0.846101\tvalid_1's auc: 0.838855\n",
      "[164]\ttraining's auc: 0.846153\tvalid_1's auc: 0.838855\n",
      "[165]\ttraining's auc: 0.846208\tvalid_1's auc: 0.838982\n",
      "[166]\ttraining's auc: 0.846234\tvalid_1's auc: 0.839008\n",
      "[167]\ttraining's auc: 0.846274\tvalid_1's auc: 0.839016\n",
      "[168]\ttraining's auc: 0.846334\tvalid_1's auc: 0.839044\n",
      "[169]\ttraining's auc: 0.846372\tvalid_1's auc: 0.839065\n",
      "[170]\ttraining's auc: 0.846395\tvalid_1's auc: 0.83901\n",
      "[171]\ttraining's auc: 0.846428\tvalid_1's auc: 0.838929\n",
      "[172]\ttraining's auc: 0.846472\tvalid_1's auc: 0.83894\n",
      "[173]\ttraining's auc: 0.846512\tvalid_1's auc: 0.838957\n",
      "[174]\ttraining's auc: 0.846563\tvalid_1's auc: 0.839059\n",
      "[175]\ttraining's auc: 0.846638\tvalid_1's auc: 0.839014\n",
      "[176]\ttraining's auc: 0.846663\tvalid_1's auc: 0.839191\n",
      "[177]\ttraining's auc: 0.846705\tvalid_1's auc: 0.839333\n",
      "[178]\ttraining's auc: 0.84677\tvalid_1's auc: 0.839356\n",
      "[179]\ttraining's auc: 0.846823\tvalid_1's auc: 0.839214\n",
      "[180]\ttraining's auc: 0.846871\tvalid_1's auc: 0.839263\n",
      "[181]\ttraining's auc: 0.846922\tvalid_1's auc: 0.839377\n",
      "[182]\ttraining's auc: 0.846958\tvalid_1's auc: 0.839394\n",
      "[183]\ttraining's auc: 0.84698\tvalid_1's auc: 0.839428\n",
      "[184]\ttraining's auc: 0.84701\tvalid_1's auc: 0.839435\n",
      "[185]\ttraining's auc: 0.847047\tvalid_1's auc: 0.83939\n",
      "[186]\ttraining's auc: 0.847082\tvalid_1's auc: 0.839428\n",
      "[187]\ttraining's auc: 0.847113\tvalid_1's auc: 0.839516\n",
      "[188]\ttraining's auc: 0.847134\tvalid_1's auc: 0.839539\n",
      "[189]\ttraining's auc: 0.847175\tvalid_1's auc: 0.839505\n",
      "[190]\ttraining's auc: 0.847207\tvalid_1's auc: 0.839471\n",
      "[191]\ttraining's auc: 0.847239\tvalid_1's auc: 0.839352\n",
      "[192]\ttraining's auc: 0.847264\tvalid_1's auc: 0.839327\n",
      "[193]\ttraining's auc: 0.847303\tvalid_1's auc: 0.839309\n",
      "[194]\ttraining's auc: 0.847335\tvalid_1's auc: 0.839318\n",
      "[195]\ttraining's auc: 0.847397\tvalid_1's auc: 0.839388\n",
      "[196]\ttraining's auc: 0.847415\tvalid_1's auc: 0.839443\n",
      "[197]\ttraining's auc: 0.847441\tvalid_1's auc: 0.839414\n",
      "[198]\ttraining's auc: 0.84747\tvalid_1's auc: 0.839418\n",
      "[199]\ttraining's auc: 0.847485\tvalid_1's auc: 0.839428\n",
      "[200]\ttraining's auc: 0.847499\tvalid_1's auc: 0.839437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[188]\ttraining's auc: 0.847134\tvalid_1's auc: 0.839539\n",
      "Fold 1 VALID AUC : 0.8395390405937526 ACC : 0.7628865979381443\n",
      "\n",
      "Fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6wiucq1b) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>valid_1_auc</td><td>▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-thunder-2</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/6wiucq1b' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/6wiucq1b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240118_141233-6wiucq1b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6wiucq1b). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240118_141324-2lezy7xa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/2lezy7xa' target=\"_blank\">decent-donkey-3</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/2lezy7xa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/2lezy7xa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322856, number of negative: 697893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3914\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020749, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654636 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.812179\tvalid_1's auc: 0.795545\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.816572\tvalid_1's auc: 0.801616\n",
      "[3]\ttraining's auc: 0.818327\tvalid_1's auc: 0.804236\n",
      "[4]\ttraining's auc: 0.820526\tvalid_1's auc: 0.80763\n",
      "[5]\ttraining's auc: 0.820864\tvalid_1's auc: 0.807312\n",
      "[6]\ttraining's auc: 0.822469\tvalid_1's auc: 0.80865\n",
      "[7]\ttraining's auc: 0.823345\tvalid_1's auc: 0.808655\n",
      "[8]\ttraining's auc: 0.824138\tvalid_1's auc: 0.810409\n",
      "[9]\ttraining's auc: 0.82477\tvalid_1's auc: 0.811155\n",
      "[10]\ttraining's auc: 0.82521\tvalid_1's auc: 0.811263\n",
      "[11]\ttraining's auc: 0.825991\tvalid_1's auc: 0.812256\n",
      "[12]\ttraining's auc: 0.826517\tvalid_1's auc: 0.813094\n",
      "[13]\ttraining's auc: 0.827041\tvalid_1's auc: 0.81422\n",
      "[14]\ttraining's auc: 0.827539\tvalid_1's auc: 0.814978\n",
      "[15]\ttraining's auc: 0.828245\tvalid_1's auc: 0.815497\n",
      "[16]\ttraining's auc: 0.828597\tvalid_1's auc: 0.815788\n",
      "[17]\ttraining's auc: 0.829152\tvalid_1's auc: 0.815929\n",
      "[18]\ttraining's auc: 0.829639\tvalid_1's auc: 0.816621\n",
      "[19]\ttraining's auc: 0.830081\tvalid_1's auc: 0.816594\n",
      "[20]\ttraining's auc: 0.830483\tvalid_1's auc: 0.816757\n",
      "[21]\ttraining's auc: 0.830894\tvalid_1's auc: 0.81723\n",
      "[22]\ttraining's auc: 0.831226\tvalid_1's auc: 0.817719\n",
      "[23]\ttraining's auc: 0.831597\tvalid_1's auc: 0.818163\n",
      "[24]\ttraining's auc: 0.831922\tvalid_1's auc: 0.818846\n",
      "[25]\ttraining's auc: 0.832234\tvalid_1's auc: 0.819172\n",
      "[26]\ttraining's auc: 0.832552\tvalid_1's auc: 0.819614\n",
      "[27]\ttraining's auc: 0.832831\tvalid_1's auc: 0.820045\n",
      "[28]\ttraining's auc: 0.833095\tvalid_1's auc: 0.820443\n",
      "[29]\ttraining's auc: 0.83336\tvalid_1's auc: 0.820694\n",
      "[30]\ttraining's auc: 0.833655\tvalid_1's auc: 0.820952\n",
      "[31]\ttraining's auc: 0.833952\tvalid_1's auc: 0.821216\n",
      "[32]\ttraining's auc: 0.834233\tvalid_1's auc: 0.821763\n",
      "[33]\ttraining's auc: 0.834601\tvalid_1's auc: 0.822136\n",
      "[34]\ttraining's auc: 0.83486\tvalid_1's auc: 0.822338\n",
      "[35]\ttraining's auc: 0.835048\tvalid_1's auc: 0.822801\n",
      "[36]\ttraining's auc: 0.835262\tvalid_1's auc: 0.823073\n",
      "[37]\ttraining's auc: 0.835478\tvalid_1's auc: 0.823279\n",
      "[38]\ttraining's auc: 0.83568\tvalid_1's auc: 0.823655\n",
      "[39]\ttraining's auc: 0.835897\tvalid_1's auc: 0.823746\n",
      "[40]\ttraining's auc: 0.836112\tvalid_1's auc: 0.824056\n",
      "[41]\ttraining's auc: 0.836261\tvalid_1's auc: 0.824307\n",
      "[42]\ttraining's auc: 0.836466\tvalid_1's auc: 0.824196\n",
      "[43]\ttraining's auc: 0.836636\tvalid_1's auc: 0.824245\n",
      "[44]\ttraining's auc: 0.836889\tvalid_1's auc: 0.824488\n",
      "[45]\ttraining's auc: 0.837052\tvalid_1's auc: 0.824559\n",
      "[46]\ttraining's auc: 0.837207\tvalid_1's auc: 0.82475\n",
      "[47]\ttraining's auc: 0.837402\tvalid_1's auc: 0.824888\n",
      "[48]\ttraining's auc: 0.83761\tvalid_1's auc: 0.825178\n",
      "[49]\ttraining's auc: 0.83776\tvalid_1's auc: 0.825235\n",
      "[50]\ttraining's auc: 0.837943\tvalid_1's auc: 0.825311\n",
      "[51]\ttraining's auc: 0.838104\tvalid_1's auc: 0.825407\n",
      "[52]\ttraining's auc: 0.838237\tvalid_1's auc: 0.825411\n",
      "[53]\ttraining's auc: 0.83838\tvalid_1's auc: 0.825708\n",
      "[54]\ttraining's auc: 0.838503\tvalid_1's auc: 0.825683\n",
      "[55]\ttraining's auc: 0.838681\tvalid_1's auc: 0.825982\n",
      "[56]\ttraining's auc: 0.838816\tvalid_1's auc: 0.82603\n",
      "[57]\ttraining's auc: 0.838925\tvalid_1's auc: 0.826011\n",
      "[58]\ttraining's auc: 0.839047\tvalid_1's auc: 0.825968\n",
      "[59]\ttraining's auc: 0.83921\tvalid_1's auc: 0.826162\n",
      "[60]\ttraining's auc: 0.839339\tvalid_1's auc: 0.826138\n",
      "[61]\ttraining's auc: 0.839494\tvalid_1's auc: 0.826288\n",
      "[62]\ttraining's auc: 0.839595\tvalid_1's auc: 0.826393\n",
      "[63]\ttraining's auc: 0.839712\tvalid_1's auc: 0.826331\n",
      "[64]\ttraining's auc: 0.839825\tvalid_1's auc: 0.82636\n",
      "[65]\ttraining's auc: 0.83994\tvalid_1's auc: 0.826503\n",
      "[66]\ttraining's auc: 0.84009\tvalid_1's auc: 0.826518\n",
      "[67]\ttraining's auc: 0.840188\tvalid_1's auc: 0.826581\n",
      "[68]\ttraining's auc: 0.840289\tvalid_1's auc: 0.826821\n",
      "[69]\ttraining's auc: 0.840393\tvalid_1's auc: 0.826747\n",
      "[70]\ttraining's auc: 0.840477\tvalid_1's auc: 0.826818\n",
      "[71]\ttraining's auc: 0.840599\tvalid_1's auc: 0.8268\n",
      "[72]\ttraining's auc: 0.840727\tvalid_1's auc: 0.826889\n",
      "[73]\ttraining's auc: 0.840817\tvalid_1's auc: 0.827026\n",
      "[74]\ttraining's auc: 0.840944\tvalid_1's auc: 0.827089\n",
      "[75]\ttraining's auc: 0.841032\tvalid_1's auc: 0.827162\n",
      "[76]\ttraining's auc: 0.841125\tvalid_1's auc: 0.827119\n",
      "[77]\ttraining's auc: 0.841228\tvalid_1's auc: 0.827057\n",
      "[78]\ttraining's auc: 0.841315\tvalid_1's auc: 0.827053\n",
      "[79]\ttraining's auc: 0.841424\tvalid_1's auc: 0.827232\n",
      "[80]\ttraining's auc: 0.841505\tvalid_1's auc: 0.827198\n",
      "[81]\ttraining's auc: 0.841584\tvalid_1's auc: 0.827141\n",
      "[82]\ttraining's auc: 0.841673\tvalid_1's auc: 0.8271\n",
      "[83]\ttraining's auc: 0.841775\tvalid_1's auc: 0.827241\n",
      "[84]\ttraining's auc: 0.841857\tvalid_1's auc: 0.827273\n",
      "[85]\ttraining's auc: 0.841944\tvalid_1's auc: 0.827277\n",
      "[86]\ttraining's auc: 0.84202\tvalid_1's auc: 0.827444\n",
      "[87]\ttraining's auc: 0.84208\tvalid_1's auc: 0.827393\n",
      "[88]\ttraining's auc: 0.842141\tvalid_1's auc: 0.827423\n",
      "[89]\ttraining's auc: 0.842241\tvalid_1's auc: 0.827316\n",
      "[90]\ttraining's auc: 0.842319\tvalid_1's auc: 0.827316\n",
      "[91]\ttraining's auc: 0.84239\tvalid_1's auc: 0.827361\n",
      "[92]\ttraining's auc: 0.842472\tvalid_1's auc: 0.8274\n",
      "[93]\ttraining's auc: 0.842553\tvalid_1's auc: 0.827316\n",
      "[94]\ttraining's auc: 0.842617\tvalid_1's auc: 0.827263\n",
      "[95]\ttraining's auc: 0.842706\tvalid_1's auc: 0.827291\n",
      "[96]\ttraining's auc: 0.842778\tvalid_1's auc: 0.827295\n",
      "[97]\ttraining's auc: 0.842841\tvalid_1's auc: 0.82722\n",
      "[98]\ttraining's auc: 0.84291\tvalid_1's auc: 0.82717\n",
      "[99]\ttraining's auc: 0.842978\tvalid_1's auc: 0.827263\n",
      "[100]\ttraining's auc: 0.843026\tvalid_1's auc: 0.827336\n",
      "[101]\ttraining's auc: 0.843101\tvalid_1's auc: 0.827512\n",
      "[102]\ttraining's auc: 0.843192\tvalid_1's auc: 0.827541\n",
      "[103]\ttraining's auc: 0.84324\tvalid_1's auc: 0.827565\n",
      "[104]\ttraining's auc: 0.843327\tvalid_1's auc: 0.827592\n",
      "[105]\ttraining's auc: 0.843384\tvalid_1's auc: 0.827621\n",
      "[106]\ttraining's auc: 0.84344\tvalid_1's auc: 0.827594\n",
      "[107]\ttraining's auc: 0.843501\tvalid_1's auc: 0.827471\n",
      "[108]\ttraining's auc: 0.843556\tvalid_1's auc: 0.827587\n",
      "[109]\ttraining's auc: 0.84363\tvalid_1's auc: 0.82763\n",
      "[110]\ttraining's auc: 0.843733\tvalid_1's auc: 0.827678\n",
      "[111]\ttraining's auc: 0.843816\tvalid_1's auc: 0.827753\n",
      "[112]\ttraining's auc: 0.843876\tvalid_1's auc: 0.827756\n",
      "[113]\ttraining's auc: 0.843932\tvalid_1's auc: 0.827806\n",
      "[114]\ttraining's auc: 0.844015\tvalid_1's auc: 0.828\n",
      "[115]\ttraining's auc: 0.844082\tvalid_1's auc: 0.827876\n",
      "[116]\ttraining's auc: 0.844165\tvalid_1's auc: 0.828031\n",
      "[117]\ttraining's auc: 0.844229\tvalid_1's auc: 0.828106\n",
      "[118]\ttraining's auc: 0.844298\tvalid_1's auc: 0.828024\n",
      "[119]\ttraining's auc: 0.844337\tvalid_1's auc: 0.828006\n",
      "[120]\ttraining's auc: 0.844383\tvalid_1's auc: 0.828077\n",
      "[121]\ttraining's auc: 0.844426\tvalid_1's auc: 0.828031\n",
      "[122]\ttraining's auc: 0.844501\tvalid_1's auc: 0.828196\n",
      "[123]\ttraining's auc: 0.844548\tvalid_1's auc: 0.828214\n",
      "[124]\ttraining's auc: 0.844588\tvalid_1's auc: 0.828193\n",
      "[125]\ttraining's auc: 0.844653\tvalid_1's auc: 0.828182\n",
      "[126]\ttraining's auc: 0.844711\tvalid_1's auc: 0.828081\n",
      "[127]\ttraining's auc: 0.844756\tvalid_1's auc: 0.828073\n",
      "[128]\ttraining's auc: 0.844833\tvalid_1's auc: 0.828081\n",
      "[129]\ttraining's auc: 0.844886\tvalid_1's auc: 0.82812\n",
      "[130]\ttraining's auc: 0.84494\tvalid_1's auc: 0.828063\n",
      "[131]\ttraining's auc: 0.844993\tvalid_1's auc: 0.828191\n",
      "[132]\ttraining's auc: 0.845058\tvalid_1's auc: 0.828191\n",
      "[133]\ttraining's auc: 0.845102\tvalid_1's auc: 0.828287\n",
      "[134]\ttraining's auc: 0.845149\tvalid_1's auc: 0.828184\n",
      "[135]\ttraining's auc: 0.845199\tvalid_1's auc: 0.828195\n",
      "[136]\ttraining's auc: 0.845233\tvalid_1's auc: 0.828284\n",
      "[137]\ttraining's auc: 0.845273\tvalid_1's auc: 0.828353\n",
      "[138]\ttraining's auc: 0.845321\tvalid_1's auc: 0.828241\n",
      "[139]\ttraining's auc: 0.845357\tvalid_1's auc: 0.828257\n",
      "[140]\ttraining's auc: 0.845405\tvalid_1's auc: 0.828214\n",
      "[141]\ttraining's auc: 0.845459\tvalid_1's auc: 0.828111\n",
      "[142]\ttraining's auc: 0.845502\tvalid_1's auc: 0.828107\n",
      "[143]\ttraining's auc: 0.845526\tvalid_1's auc: 0.82804\n",
      "[144]\ttraining's auc: 0.845562\tvalid_1's auc: 0.8281\n",
      "[145]\ttraining's auc: 0.845608\tvalid_1's auc: 0.828065\n",
      "[146]\ttraining's auc: 0.845669\tvalid_1's auc: 0.828228\n",
      "[147]\ttraining's auc: 0.845722\tvalid_1's auc: 0.828262\n",
      "[148]\ttraining's auc: 0.845764\tvalid_1's auc: 0.828287\n",
      "[149]\ttraining's auc: 0.845806\tvalid_1's auc: 0.828366\n",
      "[150]\ttraining's auc: 0.845843\tvalid_1's auc: 0.828232\n",
      "[151]\ttraining's auc: 0.845877\tvalid_1's auc: 0.828294\n",
      "[152]\ttraining's auc: 0.845906\tvalid_1's auc: 0.828293\n",
      "[153]\ttraining's auc: 0.845956\tvalid_1's auc: 0.828412\n",
      "[154]\ttraining's auc: 0.845996\tvalid_1's auc: 0.82835\n",
      "[155]\ttraining's auc: 0.846031\tvalid_1's auc: 0.828359\n",
      "[156]\ttraining's auc: 0.846072\tvalid_1's auc: 0.828364\n",
      "[157]\ttraining's auc: 0.846097\tvalid_1's auc: 0.828364\n",
      "[158]\ttraining's auc: 0.846168\tvalid_1's auc: 0.828455\n",
      "[159]\ttraining's auc: 0.846234\tvalid_1's auc: 0.828654\n",
      "[160]\ttraining's auc: 0.846264\tvalid_1's auc: 0.828672\n",
      "[161]\ttraining's auc: 0.846344\tvalid_1's auc: 0.828631\n",
      "[162]\ttraining's auc: 0.846375\tvalid_1's auc: 0.828699\n",
      "[163]\ttraining's auc: 0.846414\tvalid_1's auc: 0.828765\n",
      "[164]\ttraining's auc: 0.846493\tvalid_1's auc: 0.828749\n",
      "[165]\ttraining's auc: 0.846521\tvalid_1's auc: 0.828768\n",
      "[166]\ttraining's auc: 0.846561\tvalid_1's auc: 0.828777\n",
      "[167]\ttraining's auc: 0.846604\tvalid_1's auc: 0.828619\n",
      "[168]\ttraining's auc: 0.846632\tvalid_1's auc: 0.828654\n",
      "[169]\ttraining's auc: 0.846656\tvalid_1's auc: 0.828665\n",
      "[170]\ttraining's auc: 0.846689\tvalid_1's auc: 0.828772\n",
      "[171]\ttraining's auc: 0.846745\tvalid_1's auc: 0.828735\n",
      "[172]\ttraining's auc: 0.846775\tvalid_1's auc: 0.82879\n",
      "[173]\ttraining's auc: 0.846807\tvalid_1's auc: 0.828815\n",
      "[174]\ttraining's auc: 0.846848\tvalid_1's auc: 0.82885\n",
      "[175]\ttraining's auc: 0.846872\tvalid_1's auc: 0.82884\n",
      "[176]\ttraining's auc: 0.846929\tvalid_1's auc: 0.828802\n",
      "[177]\ttraining's auc: 0.846959\tvalid_1's auc: 0.828818\n",
      "[178]\ttraining's auc: 0.846983\tvalid_1's auc: 0.82887\n",
      "[179]\ttraining's auc: 0.847041\tvalid_1's auc: 0.828836\n",
      "[180]\ttraining's auc: 0.847069\tvalid_1's auc: 0.828765\n",
      "[181]\ttraining's auc: 0.847106\tvalid_1's auc: 0.82877\n",
      "[182]\ttraining's auc: 0.847142\tvalid_1's auc: 0.828788\n",
      "[183]\ttraining's auc: 0.847168\tvalid_1's auc: 0.828786\n",
      "[184]\ttraining's auc: 0.847195\tvalid_1's auc: 0.828854\n",
      "[185]\ttraining's auc: 0.847211\tvalid_1's auc: 0.828843\n",
      "[186]\ttraining's auc: 0.847245\tvalid_1's auc: 0.828793\n",
      "[187]\ttraining's auc: 0.847277\tvalid_1's auc: 0.828849\n",
      "[188]\ttraining's auc: 0.847306\tvalid_1's auc: 0.828916\n",
      "[189]\ttraining's auc: 0.847339\tvalid_1's auc: 0.828941\n",
      "[190]\ttraining's auc: 0.84738\tvalid_1's auc: 0.828941\n",
      "[191]\ttraining's auc: 0.847396\tvalid_1's auc: 0.828963\n",
      "[192]\ttraining's auc: 0.847421\tvalid_1's auc: 0.828968\n",
      "[193]\ttraining's auc: 0.847448\tvalid_1's auc: 0.828959\n",
      "[194]\ttraining's auc: 0.847483\tvalid_1's auc: 0.829011\n",
      "[195]\ttraining's auc: 0.847521\tvalid_1's auc: 0.829029\n",
      "[196]\ttraining's auc: 0.84755\tvalid_1's auc: 0.829006\n",
      "[197]\ttraining's auc: 0.847573\tvalid_1's auc: 0.828965\n",
      "[198]\ttraining's auc: 0.847602\tvalid_1's auc: 0.828936\n",
      "[199]\ttraining's auc: 0.84762\tvalid_1's auc: 0.829007\n",
      "[200]\ttraining's auc: 0.847651\tvalid_1's auc: 0.829045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.847651\tvalid_1's auc: 0.829045\n",
      "Fold 2 VALID AUC : 0.8290447335590805 ACC : 0.7505003335557038\n",
      "\n",
      "Fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2lezy7xa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>valid_1_auc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-donkey-3</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/2lezy7xa' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/2lezy7xa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240118_141324-2lezy7xa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2lezy7xa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240118_141413-eix9dlnv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/eix9dlnv' target=\"_blank\">valiant-snowflake-4</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/eix9dlnv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/eix9dlnv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322858, number of negative: 697894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3901\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020752, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654636 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.811147\tvalid_1's auc: 0.796528\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.814935\tvalid_1's auc: 0.800836\n",
      "[3]\ttraining's auc: 0.818605\tvalid_1's auc: 0.80488\n",
      "[4]\ttraining's auc: 0.818953\tvalid_1's auc: 0.804336\n",
      "[5]\ttraining's auc: 0.819755\tvalid_1's auc: 0.806053\n",
      "[6]\ttraining's auc: 0.821487\tvalid_1's auc: 0.807439\n",
      "[7]\ttraining's auc: 0.822659\tvalid_1's auc: 0.810132\n",
      "[8]\ttraining's auc: 0.823272\tvalid_1's auc: 0.811766\n",
      "[9]\ttraining's auc: 0.823904\tvalid_1's auc: 0.812823\n",
      "[10]\ttraining's auc: 0.824543\tvalid_1's auc: 0.813516\n",
      "[11]\ttraining's auc: 0.825295\tvalid_1's auc: 0.814001\n",
      "[12]\ttraining's auc: 0.825715\tvalid_1's auc: 0.81497\n",
      "[13]\ttraining's auc: 0.826319\tvalid_1's auc: 0.81525\n",
      "[14]\ttraining's auc: 0.826813\tvalid_1's auc: 0.816215\n",
      "[15]\ttraining's auc: 0.827523\tvalid_1's auc: 0.817276\n",
      "[16]\ttraining's auc: 0.828098\tvalid_1's auc: 0.818139\n",
      "[17]\ttraining's auc: 0.828647\tvalid_1's auc: 0.818988\n",
      "[18]\ttraining's auc: 0.828981\tvalid_1's auc: 0.819466\n",
      "[19]\ttraining's auc: 0.829382\tvalid_1's auc: 0.819806\n",
      "[20]\ttraining's auc: 0.829791\tvalid_1's auc: 0.82001\n",
      "[21]\ttraining's auc: 0.830254\tvalid_1's auc: 0.820612\n",
      "[22]\ttraining's auc: 0.830572\tvalid_1's auc: 0.820761\n",
      "[23]\ttraining's auc: 0.830919\tvalid_1's auc: 0.821139\n",
      "[24]\ttraining's auc: 0.831254\tvalid_1's auc: 0.822072\n",
      "[25]\ttraining's auc: 0.831646\tvalid_1's auc: 0.822785\n",
      "[26]\ttraining's auc: 0.831945\tvalid_1's auc: 0.823032\n",
      "[27]\ttraining's auc: 0.832219\tvalid_1's auc: 0.823354\n",
      "[28]\ttraining's auc: 0.832505\tvalid_1's auc: 0.823835\n",
      "[29]\ttraining's auc: 0.832847\tvalid_1's auc: 0.82418\n",
      "[30]\ttraining's auc: 0.833091\tvalid_1's auc: 0.82524\n",
      "[31]\ttraining's auc: 0.833413\tvalid_1's auc: 0.825885\n",
      "[32]\ttraining's auc: 0.833776\tvalid_1's auc: 0.826329\n",
      "[33]\ttraining's auc: 0.834054\tvalid_1's auc: 0.826494\n",
      "[34]\ttraining's auc: 0.834271\tvalid_1's auc: 0.826952\n",
      "[35]\ttraining's auc: 0.8345\tvalid_1's auc: 0.827543\n",
      "[36]\ttraining's auc: 0.834736\tvalid_1's auc: 0.828145\n",
      "[37]\ttraining's auc: 0.834975\tvalid_1's auc: 0.828542\n",
      "[38]\ttraining's auc: 0.835207\tvalid_1's auc: 0.828542\n",
      "[39]\ttraining's auc: 0.835452\tvalid_1's auc: 0.82858\n",
      "[40]\ttraining's auc: 0.835626\tvalid_1's auc: 0.828882\n",
      "[41]\ttraining's auc: 0.835819\tvalid_1's auc: 0.829019\n",
      "[42]\ttraining's auc: 0.836008\tvalid_1's auc: 0.82934\n",
      "[43]\ttraining's auc: 0.836241\tvalid_1's auc: 0.829578\n",
      "[44]\ttraining's auc: 0.8364\tvalid_1's auc: 0.829764\n",
      "[45]\ttraining's auc: 0.836592\tvalid_1's auc: 0.829898\n",
      "[46]\ttraining's auc: 0.836763\tvalid_1's auc: 0.830073\n",
      "[47]\ttraining's auc: 0.83694\tvalid_1's auc: 0.83021\n",
      "[48]\ttraining's auc: 0.837102\tvalid_1's auc: 0.830609\n",
      "[49]\ttraining's auc: 0.837248\tvalid_1's auc: 0.830791\n",
      "[50]\ttraining's auc: 0.837399\tvalid_1's auc: 0.830762\n",
      "[51]\ttraining's auc: 0.83754\tvalid_1's auc: 0.830767\n",
      "[52]\ttraining's auc: 0.837752\tvalid_1's auc: 0.831068\n",
      "[53]\ttraining's auc: 0.837875\tvalid_1's auc: 0.831214\n",
      "[54]\ttraining's auc: 0.838014\tvalid_1's auc: 0.831274\n",
      "[55]\ttraining's auc: 0.838127\tvalid_1's auc: 0.831333\n",
      "[56]\ttraining's auc: 0.838252\tvalid_1's auc: 0.831436\n",
      "[57]\ttraining's auc: 0.838459\tvalid_1's auc: 0.831732\n",
      "[58]\ttraining's auc: 0.838578\tvalid_1's auc: 0.83173\n",
      "[59]\ttraining's auc: 0.83869\tvalid_1's auc: 0.831833\n",
      "[60]\ttraining's auc: 0.83882\tvalid_1's auc: 0.831975\n",
      "[61]\ttraining's auc: 0.83896\tvalid_1's auc: 0.832309\n",
      "[62]\ttraining's auc: 0.839116\tvalid_1's auc: 0.832608\n",
      "[63]\ttraining's auc: 0.839222\tvalid_1's auc: 0.832605\n",
      "[64]\ttraining's auc: 0.839326\tvalid_1's auc: 0.832664\n",
      "[65]\ttraining's auc: 0.839437\tvalid_1's auc: 0.832675\n",
      "[66]\ttraining's auc: 0.839562\tvalid_1's auc: 0.832842\n",
      "[67]\ttraining's auc: 0.839651\tvalid_1's auc: 0.832829\n",
      "[68]\ttraining's auc: 0.839775\tvalid_1's auc: 0.832995\n",
      "[69]\ttraining's auc: 0.839881\tvalid_1's auc: 0.832923\n",
      "[70]\ttraining's auc: 0.839952\tvalid_1's auc: 0.83304\n",
      "[71]\ttraining's auc: 0.840039\tvalid_1's auc: 0.833064\n",
      "[72]\ttraining's auc: 0.840139\tvalid_1's auc: 0.833039\n",
      "[73]\ttraining's auc: 0.840245\tvalid_1's auc: 0.833174\n",
      "[74]\ttraining's auc: 0.840358\tvalid_1's auc: 0.833291\n",
      "[75]\ttraining's auc: 0.840435\tvalid_1's auc: 0.833355\n",
      "[76]\ttraining's auc: 0.840551\tvalid_1's auc: 0.833409\n",
      "[77]\ttraining's auc: 0.840633\tvalid_1's auc: 0.833396\n",
      "[78]\ttraining's auc: 0.840754\tvalid_1's auc: 0.833519\n",
      "[79]\ttraining's auc: 0.840848\tvalid_1's auc: 0.83362\n",
      "[80]\ttraining's auc: 0.840934\tvalid_1's auc: 0.833488\n",
      "[81]\ttraining's auc: 0.841017\tvalid_1's auc: 0.833733\n",
      "[82]\ttraining's auc: 0.841095\tvalid_1's auc: 0.833777\n",
      "[83]\ttraining's auc: 0.841177\tvalid_1's auc: 0.833683\n",
      "[84]\ttraining's auc: 0.841255\tvalid_1's auc: 0.833634\n",
      "[85]\ttraining's auc: 0.841344\tvalid_1's auc: 0.833737\n",
      "[86]\ttraining's auc: 0.841427\tvalid_1's auc: 0.833764\n",
      "[87]\ttraining's auc: 0.841503\tvalid_1's auc: 0.833829\n",
      "[88]\ttraining's auc: 0.841603\tvalid_1's auc: 0.833888\n",
      "[89]\ttraining's auc: 0.841665\tvalid_1's auc: 0.833941\n",
      "[90]\ttraining's auc: 0.841751\tvalid_1's auc: 0.833926\n",
      "[91]\ttraining's auc: 0.841812\tvalid_1's auc: 0.833975\n",
      "[92]\ttraining's auc: 0.841889\tvalid_1's auc: 0.834007\n",
      "[93]\ttraining's auc: 0.841966\tvalid_1's auc: 0.834097\n",
      "[94]\ttraining's auc: 0.842032\tvalid_1's auc: 0.83402\n",
      "[95]\ttraining's auc: 0.842088\tvalid_1's auc: 0.83406\n",
      "[96]\ttraining's auc: 0.842152\tvalid_1's auc: 0.834055\n",
      "[97]\ttraining's auc: 0.842234\tvalid_1's auc: 0.83408\n",
      "[98]\ttraining's auc: 0.842316\tvalid_1's auc: 0.834041\n",
      "[99]\ttraining's auc: 0.842393\tvalid_1's auc: 0.834046\n",
      "[100]\ttraining's auc: 0.842452\tvalid_1's auc: 0.834048\n",
      "[101]\ttraining's auc: 0.842523\tvalid_1's auc: 0.83408\n",
      "[102]\ttraining's auc: 0.842611\tvalid_1's auc: 0.83428\n",
      "[103]\ttraining's auc: 0.842663\tvalid_1's auc: 0.834285\n",
      "[104]\ttraining's auc: 0.84272\tvalid_1's auc: 0.834346\n",
      "[105]\ttraining's auc: 0.842786\tvalid_1's auc: 0.834272\n",
      "[106]\ttraining's auc: 0.842844\tvalid_1's auc: 0.834283\n",
      "[107]\ttraining's auc: 0.84293\tvalid_1's auc: 0.834312\n",
      "[108]\ttraining's auc: 0.842968\tvalid_1's auc: 0.834452\n",
      "[109]\ttraining's auc: 0.843025\tvalid_1's auc: 0.834523\n",
      "[110]\ttraining's auc: 0.843089\tvalid_1's auc: 0.834548\n",
      "[111]\ttraining's auc: 0.843147\tvalid_1's auc: 0.834467\n",
      "[112]\ttraining's auc: 0.843211\tvalid_1's auc: 0.834571\n",
      "[113]\ttraining's auc: 0.843282\tvalid_1's auc: 0.834562\n",
      "[114]\ttraining's auc: 0.843344\tvalid_1's auc: 0.834629\n",
      "[115]\ttraining's auc: 0.84343\tvalid_1's auc: 0.834804\n",
      "[116]\ttraining's auc: 0.843476\tvalid_1's auc: 0.834825\n",
      "[117]\ttraining's auc: 0.843547\tvalid_1's auc: 0.835051\n",
      "[118]\ttraining's auc: 0.843598\tvalid_1's auc: 0.835125\n",
      "[119]\ttraining's auc: 0.843685\tvalid_1's auc: 0.835209\n",
      "[120]\ttraining's auc: 0.843749\tvalid_1's auc: 0.835422\n",
      "[121]\ttraining's auc: 0.843804\tvalid_1's auc: 0.835505\n",
      "[122]\ttraining's auc: 0.84386\tvalid_1's auc: 0.835537\n",
      "[123]\ttraining's auc: 0.843916\tvalid_1's auc: 0.835516\n",
      "[124]\ttraining's auc: 0.843959\tvalid_1's auc: 0.835525\n",
      "[125]\ttraining's auc: 0.844027\tvalid_1's auc: 0.835672\n",
      "[126]\ttraining's auc: 0.84408\tvalid_1's auc: 0.835672\n",
      "[127]\ttraining's auc: 0.844122\tvalid_1's auc: 0.835582\n",
      "[128]\ttraining's auc: 0.844192\tvalid_1's auc: 0.835584\n",
      "[129]\ttraining's auc: 0.844252\tvalid_1's auc: 0.835545\n",
      "[130]\ttraining's auc: 0.844291\tvalid_1's auc: 0.835559\n",
      "[131]\ttraining's auc: 0.844332\tvalid_1's auc: 0.835678\n",
      "[132]\ttraining's auc: 0.844412\tvalid_1's auc: 0.83571\n",
      "[133]\ttraining's auc: 0.844457\tvalid_1's auc: 0.835701\n",
      "[134]\ttraining's auc: 0.844508\tvalid_1's auc: 0.835709\n",
      "[135]\ttraining's auc: 0.844551\tvalid_1's auc: 0.835719\n",
      "[136]\ttraining's auc: 0.844606\tvalid_1's auc: 0.83568\n",
      "[137]\ttraining's auc: 0.844646\tvalid_1's auc: 0.83568\n",
      "[138]\ttraining's auc: 0.844685\tvalid_1's auc: 0.835599\n",
      "[139]\ttraining's auc: 0.844747\tvalid_1's auc: 0.83544\n",
      "[140]\ttraining's auc: 0.844788\tvalid_1's auc: 0.835618\n",
      "[141]\ttraining's auc: 0.84484\tvalid_1's auc: 0.835618\n",
      "[142]\ttraining's auc: 0.844914\tvalid_1's auc: 0.83557\n",
      "[143]\ttraining's auc: 0.844952\tvalid_1's auc: 0.835559\n",
      "[144]\ttraining's auc: 0.844996\tvalid_1's auc: 0.835678\n",
      "[145]\ttraining's auc: 0.845029\tvalid_1's auc: 0.835681\n",
      "[146]\ttraining's auc: 0.845084\tvalid_1's auc: 0.835739\n",
      "[147]\ttraining's auc: 0.845135\tvalid_1's auc: 0.835543\n",
      "[148]\ttraining's auc: 0.845177\tvalid_1's auc: 0.835662\n",
      "[149]\ttraining's auc: 0.845215\tvalid_1's auc: 0.835656\n",
      "[150]\ttraining's auc: 0.84525\tvalid_1's auc: 0.835752\n",
      "[151]\ttraining's auc: 0.845312\tvalid_1's auc: 0.835813\n",
      "[152]\ttraining's auc: 0.845356\tvalid_1's auc: 0.835849\n",
      "[153]\ttraining's auc: 0.845389\tvalid_1's auc: 0.835856\n",
      "[154]\ttraining's auc: 0.845416\tvalid_1's auc: 0.835845\n",
      "[155]\ttraining's auc: 0.845461\tvalid_1's auc: 0.835775\n",
      "[156]\ttraining's auc: 0.845502\tvalid_1's auc: 0.835891\n",
      "[157]\ttraining's auc: 0.845543\tvalid_1's auc: 0.835883\n",
      "[158]\ttraining's auc: 0.845576\tvalid_1's auc: 0.83586\n",
      "[159]\ttraining's auc: 0.845631\tvalid_1's auc: 0.835885\n",
      "[160]\ttraining's auc: 0.845696\tvalid_1's auc: 0.835907\n",
      "[161]\ttraining's auc: 0.845734\tvalid_1's auc: 0.835874\n",
      "[162]\ttraining's auc: 0.845763\tvalid_1's auc: 0.835961\n",
      "[163]\ttraining's auc: 0.845862\tvalid_1's auc: 0.836127\n",
      "[164]\ttraining's auc: 0.845894\tvalid_1's auc: 0.836121\n",
      "[165]\ttraining's auc: 0.845925\tvalid_1's auc: 0.836145\n",
      "[166]\ttraining's auc: 0.845949\tvalid_1's auc: 0.836114\n",
      "[167]\ttraining's auc: 0.845989\tvalid_1's auc: 0.836139\n",
      "[168]\ttraining's auc: 0.846006\tvalid_1's auc: 0.836141\n",
      "[169]\ttraining's auc: 0.846038\tvalid_1's auc: 0.836089\n",
      "[170]\ttraining's auc: 0.84607\tvalid_1's auc: 0.836044\n",
      "[171]\ttraining's auc: 0.846103\tvalid_1's auc: 0.836002\n",
      "[172]\ttraining's auc: 0.846142\tvalid_1's auc: 0.835986\n",
      "[173]\ttraining's auc: 0.846172\tvalid_1's auc: 0.835946\n",
      "[174]\ttraining's auc: 0.846211\tvalid_1's auc: 0.835952\n",
      "[175]\ttraining's auc: 0.846238\tvalid_1's auc: 0.835964\n",
      "[176]\ttraining's auc: 0.846261\tvalid_1's auc: 0.836101\n",
      "[177]\ttraining's auc: 0.846278\tvalid_1's auc: 0.8361\n",
      "[178]\ttraining's auc: 0.846361\tvalid_1's auc: 0.836348\n",
      "[179]\ttraining's auc: 0.846401\tvalid_1's auc: 0.836348\n",
      "[180]\ttraining's auc: 0.846421\tvalid_1's auc: 0.836283\n",
      "[181]\ttraining's auc: 0.846454\tvalid_1's auc: 0.83628\n",
      "[182]\ttraining's auc: 0.846498\tvalid_1's auc: 0.83639\n",
      "[183]\ttraining's auc: 0.846546\tvalid_1's auc: 0.836364\n",
      "[184]\ttraining's auc: 0.846576\tvalid_1's auc: 0.83642\n",
      "[185]\ttraining's auc: 0.846603\tvalid_1's auc: 0.836433\n",
      "[186]\ttraining's auc: 0.846665\tvalid_1's auc: 0.836554\n",
      "[187]\ttraining's auc: 0.846688\tvalid_1's auc: 0.836512\n",
      "[188]\ttraining's auc: 0.84672\tvalid_1's auc: 0.836519\n",
      "[189]\ttraining's auc: 0.84676\tvalid_1's auc: 0.836556\n",
      "[190]\ttraining's auc: 0.846807\tvalid_1's auc: 0.836583\n",
      "[191]\ttraining's auc: 0.846829\tvalid_1's auc: 0.836588\n",
      "[192]\ttraining's auc: 0.846849\tvalid_1's auc: 0.836545\n",
      "[193]\ttraining's auc: 0.8469\tvalid_1's auc: 0.83662\n",
      "[194]\ttraining's auc: 0.846941\tvalid_1's auc: 0.836565\n",
      "[195]\ttraining's auc: 0.846986\tvalid_1's auc: 0.836537\n",
      "[196]\ttraining's auc: 0.847\tvalid_1's auc: 0.836559\n",
      "[197]\ttraining's auc: 0.84704\tvalid_1's auc: 0.836561\n",
      "[198]\ttraining's auc: 0.847069\tvalid_1's auc: 0.836583\n",
      "[199]\ttraining's auc: 0.847111\tvalid_1's auc: 0.836566\n",
      "[200]\ttraining's auc: 0.847146\tvalid_1's auc: 0.836631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.847146\tvalid_1's auc: 0.836631\n",
      "Fold 3 VALID AUC : 0.8366312010726178 ACC : 0.7624161073825504\n",
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:eix9dlnv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_auc</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>valid_1_auc</td><td>▁▂▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-snowflake-4</strong> at: <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/eix9dlnv' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/eix9dlnv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240118_141413-eix9dlnv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eix9dlnv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-dkt-recsys-06/code/boost/wandb/run-20240118_141503-peo6dt6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/peo6dt6x' target=\"_blank\">polished-water-5</a></strong> to <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boostcamp6-recsys6/dkt' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boostcamp6-recsys6/dkt/runs/peo6dt6x' target=\"_blank\">https://wandb.ai/boostcamp6-recsys6/dkt/runs/peo6dt6x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1322866, number of negative: 697898\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3921\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654637 -> initscore=0.639483\n",
      "[LightGBM] [Info] Start training from score 0.639483\n",
      "[1]\ttraining's auc: 0.811178\tvalid_1's auc: 0.797588\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.814838\tvalid_1's auc: 0.800416\n",
      "[3]\ttraining's auc: 0.817051\tvalid_1's auc: 0.803121\n",
      "[4]\ttraining's auc: 0.819953\tvalid_1's auc: 0.80575\n",
      "[5]\ttraining's auc: 0.821681\tvalid_1's auc: 0.806864\n",
      "[6]\ttraining's auc: 0.822248\tvalid_1's auc: 0.808454\n",
      "[7]\ttraining's auc: 0.823369\tvalid_1's auc: 0.810356\n",
      "[8]\ttraining's auc: 0.82409\tvalid_1's auc: 0.811528\n",
      "[9]\ttraining's auc: 0.82465\tvalid_1's auc: 0.81288\n",
      "[10]\ttraining's auc: 0.825288\tvalid_1's auc: 0.814161\n",
      "[11]\ttraining's auc: 0.825692\tvalid_1's auc: 0.81453\n",
      "[12]\ttraining's auc: 0.826317\tvalid_1's auc: 0.815591\n",
      "[13]\ttraining's auc: 0.826734\tvalid_1's auc: 0.816441\n",
      "[14]\ttraining's auc: 0.827169\tvalid_1's auc: 0.817303\n",
      "[15]\ttraining's auc: 0.827629\tvalid_1's auc: 0.817934\n",
      "[16]\ttraining's auc: 0.828313\tvalid_1's auc: 0.818174\n",
      "[17]\ttraining's auc: 0.828824\tvalid_1's auc: 0.818985\n",
      "[18]\ttraining's auc: 0.829265\tvalid_1's auc: 0.819251\n",
      "[19]\ttraining's auc: 0.829732\tvalid_1's auc: 0.819594\n",
      "[20]\ttraining's auc: 0.83016\tvalid_1's auc: 0.820207\n",
      "[21]\ttraining's auc: 0.830468\tvalid_1's auc: 0.820769\n",
      "[22]\ttraining's auc: 0.830847\tvalid_1's auc: 0.821542\n",
      "[23]\ttraining's auc: 0.83117\tvalid_1's auc: 0.822235\n",
      "[24]\ttraining's auc: 0.831467\tvalid_1's auc: 0.822744\n",
      "[25]\ttraining's auc: 0.831758\tvalid_1's auc: 0.823095\n",
      "[26]\ttraining's auc: 0.832128\tvalid_1's auc: 0.823711\n",
      "[27]\ttraining's auc: 0.832425\tvalid_1's auc: 0.823849\n",
      "[28]\ttraining's auc: 0.832744\tvalid_1's auc: 0.824181\n",
      "[29]\ttraining's auc: 0.833033\tvalid_1's auc: 0.824706\n",
      "[30]\ttraining's auc: 0.833322\tvalid_1's auc: 0.825093\n",
      "[31]\ttraining's auc: 0.833601\tvalid_1's auc: 0.825296\n",
      "[32]\ttraining's auc: 0.8339\tvalid_1's auc: 0.825449\n",
      "[33]\ttraining's auc: 0.834139\tvalid_1's auc: 0.825902\n",
      "[34]\ttraining's auc: 0.834417\tvalid_1's auc: 0.826546\n",
      "[35]\ttraining's auc: 0.83463\tvalid_1's auc: 0.826541\n",
      "[36]\ttraining's auc: 0.834863\tvalid_1's auc: 0.82695\n",
      "[37]\ttraining's auc: 0.835057\tvalid_1's auc: 0.827458\n",
      "[38]\ttraining's auc: 0.835333\tvalid_1's auc: 0.827846\n",
      "[39]\ttraining's auc: 0.835521\tvalid_1's auc: 0.828098\n",
      "[40]\ttraining's auc: 0.835726\tvalid_1's auc: 0.828454\n",
      "[41]\ttraining's auc: 0.835922\tvalid_1's auc: 0.828578\n",
      "[42]\ttraining's auc: 0.836132\tvalid_1's auc: 0.828685\n",
      "[43]\ttraining's auc: 0.836326\tvalid_1's auc: 0.829036\n",
      "[44]\ttraining's auc: 0.836481\tvalid_1's auc: 0.82916\n",
      "[45]\ttraining's auc: 0.836648\tvalid_1's auc: 0.829417\n",
      "[46]\ttraining's auc: 0.836797\tvalid_1's auc: 0.829687\n",
      "[47]\ttraining's auc: 0.836956\tvalid_1's auc: 0.829812\n",
      "[48]\ttraining's auc: 0.837091\tvalid_1's auc: 0.829962\n",
      "[49]\ttraining's auc: 0.837241\tvalid_1's auc: 0.829944\n",
      "[50]\ttraining's auc: 0.837384\tvalid_1's auc: 0.830106\n",
      "[51]\ttraining's auc: 0.837528\tvalid_1's auc: 0.830454\n",
      "[52]\ttraining's auc: 0.837724\tvalid_1's auc: 0.830828\n",
      "[53]\ttraining's auc: 0.837893\tvalid_1's auc: 0.831068\n",
      "[54]\ttraining's auc: 0.838024\tvalid_1's auc: 0.830911\n",
      "[55]\ttraining's auc: 0.838202\tvalid_1's auc: 0.83099\n",
      "[56]\ttraining's auc: 0.838333\tvalid_1's auc: 0.831052\n",
      "[57]\ttraining's auc: 0.838448\tvalid_1's auc: 0.831121\n",
      "[58]\ttraining's auc: 0.838577\tvalid_1's auc: 0.831209\n",
      "[59]\ttraining's auc: 0.838683\tvalid_1's auc: 0.831205\n",
      "[60]\ttraining's auc: 0.838806\tvalid_1's auc: 0.831279\n",
      "[61]\ttraining's auc: 0.838968\tvalid_1's auc: 0.831759\n",
      "[62]\ttraining's auc: 0.839122\tvalid_1's auc: 0.831945\n",
      "[63]\ttraining's auc: 0.839264\tvalid_1's auc: 0.8322\n",
      "[64]\ttraining's auc: 0.839368\tvalid_1's auc: 0.832354\n",
      "[65]\ttraining's auc: 0.839466\tvalid_1's auc: 0.832464\n",
      "[66]\ttraining's auc: 0.839628\tvalid_1's auc: 0.832772\n",
      "[67]\ttraining's auc: 0.839759\tvalid_1's auc: 0.832928\n",
      "[68]\ttraining's auc: 0.839871\tvalid_1's auc: 0.832967\n",
      "[69]\ttraining's auc: 0.839981\tvalid_1's auc: 0.832955\n",
      "[70]\ttraining's auc: 0.840065\tvalid_1's auc: 0.832991\n",
      "[71]\ttraining's auc: 0.840153\tvalid_1's auc: 0.83316\n",
      "[72]\ttraining's auc: 0.840272\tvalid_1's auc: 0.833328\n",
      "[73]\ttraining's auc: 0.840385\tvalid_1's auc: 0.833401\n",
      "[74]\ttraining's auc: 0.840494\tvalid_1's auc: 0.833426\n",
      "[75]\ttraining's auc: 0.840595\tvalid_1's auc: 0.833432\n",
      "[76]\ttraining's auc: 0.840679\tvalid_1's auc: 0.833466\n",
      "[77]\ttraining's auc: 0.840774\tvalid_1's auc: 0.833561\n",
      "[78]\ttraining's auc: 0.840855\tvalid_1's auc: 0.833792\n",
      "[79]\ttraining's auc: 0.840938\tvalid_1's auc: 0.833781\n",
      "[80]\ttraining's auc: 0.841067\tvalid_1's auc: 0.834003\n",
      "[81]\ttraining's auc: 0.841181\tvalid_1's auc: 0.834069\n",
      "[82]\ttraining's auc: 0.841268\tvalid_1's auc: 0.834041\n",
      "[83]\ttraining's auc: 0.841355\tvalid_1's auc: 0.834157\n",
      "[84]\ttraining's auc: 0.84143\tvalid_1's auc: 0.834261\n",
      "[85]\ttraining's auc: 0.841528\tvalid_1's auc: 0.834282\n",
      "[86]\ttraining's auc: 0.841611\tvalid_1's auc: 0.834435\n",
      "[87]\ttraining's auc: 0.841688\tvalid_1's auc: 0.834369\n",
      "[88]\ttraining's auc: 0.841784\tvalid_1's auc: 0.8344\n",
      "[89]\ttraining's auc: 0.84186\tvalid_1's auc: 0.83445\n",
      "[90]\ttraining's auc: 0.841957\tvalid_1's auc: 0.834645\n",
      "[91]\ttraining's auc: 0.842038\tvalid_1's auc: 0.834722\n",
      "[92]\ttraining's auc: 0.842104\tvalid_1's auc: 0.834765\n",
      "[93]\ttraining's auc: 0.842172\tvalid_1's auc: 0.834865\n",
      "[94]\ttraining's auc: 0.842243\tvalid_1's auc: 0.834856\n",
      "[95]\ttraining's auc: 0.842301\tvalid_1's auc: 0.834854\n",
      "[96]\ttraining's auc: 0.842414\tvalid_1's auc: 0.834969\n",
      "[97]\ttraining's auc: 0.842504\tvalid_1's auc: 0.834931\n",
      "[98]\ttraining's auc: 0.842572\tvalid_1's auc: 0.835001\n",
      "[99]\ttraining's auc: 0.842637\tvalid_1's auc: 0.834985\n",
      "[100]\ttraining's auc: 0.842713\tvalid_1's auc: 0.835118\n",
      "[101]\ttraining's auc: 0.842768\tvalid_1's auc: 0.835214\n",
      "[102]\ttraining's auc: 0.842823\tvalid_1's auc: 0.835196\n",
      "[103]\ttraining's auc: 0.842882\tvalid_1's auc: 0.835193\n",
      "[104]\ttraining's auc: 0.842936\tvalid_1's auc: 0.835347\n",
      "[105]\ttraining's auc: 0.843026\tvalid_1's auc: 0.835511\n",
      "[106]\ttraining's auc: 0.843077\tvalid_1's auc: 0.835578\n",
      "[107]\ttraining's auc: 0.843136\tvalid_1's auc: 0.835707\n",
      "[108]\ttraining's auc: 0.843193\tvalid_1's auc: 0.835732\n",
      "[109]\ttraining's auc: 0.84325\tvalid_1's auc: 0.835993\n",
      "[110]\ttraining's auc: 0.843326\tvalid_1's auc: 0.835993\n",
      "[111]\ttraining's auc: 0.843409\tvalid_1's auc: 0.836075\n",
      "[112]\ttraining's auc: 0.843474\tvalid_1's auc: 0.836039\n",
      "[113]\ttraining's auc: 0.84353\tvalid_1's auc: 0.836066\n",
      "[114]\ttraining's auc: 0.843589\tvalid_1's auc: 0.836032\n",
      "[115]\ttraining's auc: 0.84369\tvalid_1's auc: 0.836182\n",
      "[116]\ttraining's auc: 0.843742\tvalid_1's auc: 0.83623\n",
      "[117]\ttraining's auc: 0.843798\tvalid_1's auc: 0.836329\n",
      "[118]\ttraining's auc: 0.843839\tvalid_1's auc: 0.836424\n",
      "[119]\ttraining's auc: 0.843882\tvalid_1's auc: 0.836458\n",
      "[120]\ttraining's auc: 0.843961\tvalid_1's auc: 0.836646\n",
      "[121]\ttraining's auc: 0.844012\tvalid_1's auc: 0.836673\n",
      "[122]\ttraining's auc: 0.844068\tvalid_1's auc: 0.836669\n",
      "[123]\ttraining's auc: 0.844119\tvalid_1's auc: 0.836801\n",
      "[124]\ttraining's auc: 0.844176\tvalid_1's auc: 0.836911\n",
      "[125]\ttraining's auc: 0.844244\tvalid_1's auc: 0.836961\n",
      "[126]\ttraining's auc: 0.844323\tvalid_1's auc: 0.837002\n",
      "[127]\ttraining's auc: 0.844376\tvalid_1's auc: 0.836993\n",
      "[128]\ttraining's auc: 0.844423\tvalid_1's auc: 0.837022\n",
      "[129]\ttraining's auc: 0.844539\tvalid_1's auc: 0.837251\n",
      "[130]\ttraining's auc: 0.844585\tvalid_1's auc: 0.837382\n",
      "[131]\ttraining's auc: 0.844612\tvalid_1's auc: 0.837249\n",
      "[132]\ttraining's auc: 0.844654\tvalid_1's auc: 0.837394\n",
      "[133]\ttraining's auc: 0.8447\tvalid_1's auc: 0.837555\n",
      "[134]\ttraining's auc: 0.844746\tvalid_1's auc: 0.837639\n",
      "[135]\ttraining's auc: 0.844807\tvalid_1's auc: 0.837672\n",
      "[136]\ttraining's auc: 0.844857\tvalid_1's auc: 0.837605\n",
      "[137]\ttraining's auc: 0.844906\tvalid_1's auc: 0.837539\n",
      "[138]\ttraining's auc: 0.844948\tvalid_1's auc: 0.8376\n",
      "[139]\ttraining's auc: 0.845021\tvalid_1's auc: 0.837792\n",
      "[140]\ttraining's auc: 0.845062\tvalid_1's auc: 0.83779\n",
      "[141]\ttraining's auc: 0.845106\tvalid_1's auc: 0.837858\n",
      "[142]\ttraining's auc: 0.845138\tvalid_1's auc: 0.837962\n",
      "[143]\ttraining's auc: 0.845165\tvalid_1's auc: 0.837989\n",
      "[144]\ttraining's auc: 0.845268\tvalid_1's auc: 0.838014\n",
      "[145]\ttraining's auc: 0.845317\tvalid_1's auc: 0.838214\n",
      "[146]\ttraining's auc: 0.845362\tvalid_1's auc: 0.838155\n",
      "[147]\ttraining's auc: 0.845399\tvalid_1's auc: 0.838189\n",
      "[148]\ttraining's auc: 0.84545\tvalid_1's auc: 0.838135\n",
      "[149]\ttraining's auc: 0.845488\tvalid_1's auc: 0.838157\n",
      "[150]\ttraining's auc: 0.845532\tvalid_1's auc: 0.83811\n",
      "[151]\ttraining's auc: 0.845607\tvalid_1's auc: 0.83825\n",
      "[152]\ttraining's auc: 0.845666\tvalid_1's auc: 0.838209\n",
      "[153]\ttraining's auc: 0.845698\tvalid_1's auc: 0.838327\n",
      "[154]\ttraining's auc: 0.845731\tvalid_1's auc: 0.838359\n",
      "[155]\ttraining's auc: 0.845775\tvalid_1's auc: 0.838347\n",
      "[156]\ttraining's auc: 0.845803\tvalid_1's auc: 0.838382\n",
      "[157]\ttraining's auc: 0.845833\tvalid_1's auc: 0.838379\n",
      "[158]\ttraining's auc: 0.845855\tvalid_1's auc: 0.838505\n",
      "[159]\ttraining's auc: 0.84589\tvalid_1's auc: 0.838485\n",
      "[160]\ttraining's auc: 0.845944\tvalid_1's auc: 0.838645\n",
      "[161]\ttraining's auc: 0.846013\tvalid_1's auc: 0.838544\n",
      "[162]\ttraining's auc: 0.846039\tvalid_1's auc: 0.838517\n",
      "[163]\ttraining's auc: 0.846078\tvalid_1's auc: 0.838572\n",
      "[164]\ttraining's auc: 0.846132\tvalid_1's auc: 0.838624\n",
      "[165]\ttraining's auc: 0.846166\tvalid_1's auc: 0.838529\n",
      "[166]\ttraining's auc: 0.846206\tvalid_1's auc: 0.838527\n",
      "[167]\ttraining's auc: 0.846256\tvalid_1's auc: 0.83852\n",
      "[168]\ttraining's auc: 0.846298\tvalid_1's auc: 0.838599\n",
      "[169]\ttraining's auc: 0.846326\tvalid_1's auc: 0.838583\n",
      "[170]\ttraining's auc: 0.846352\tvalid_1's auc: 0.838558\n",
      "[171]\ttraining's auc: 0.846378\tvalid_1's auc: 0.838689\n",
      "[172]\ttraining's auc: 0.846416\tvalid_1's auc: 0.83863\n",
      "[173]\ttraining's auc: 0.846464\tvalid_1's auc: 0.838631\n",
      "[174]\ttraining's auc: 0.846504\tvalid_1's auc: 0.838646\n",
      "[175]\ttraining's auc: 0.846549\tvalid_1's auc: 0.838744\n",
      "[176]\ttraining's auc: 0.846595\tvalid_1's auc: 0.838839\n",
      "[177]\ttraining's auc: 0.846619\tvalid_1's auc: 0.838877\n",
      "[178]\ttraining's auc: 0.846658\tvalid_1's auc: 0.838819\n",
      "[179]\ttraining's auc: 0.846686\tvalid_1's auc: 0.838857\n",
      "[180]\ttraining's auc: 0.84673\tvalid_1's auc: 0.838801\n",
      "[181]\ttraining's auc: 0.846759\tvalid_1's auc: 0.838805\n",
      "[182]\ttraining's auc: 0.846798\tvalid_1's auc: 0.838873\n",
      "[183]\ttraining's auc: 0.846859\tvalid_1's auc: 0.838814\n",
      "[184]\ttraining's auc: 0.846903\tvalid_1's auc: 0.83883\n",
      "[185]\ttraining's auc: 0.84694\tvalid_1's auc: 0.838954\n",
      "[186]\ttraining's auc: 0.846956\tvalid_1's auc: 0.839027\n",
      "[187]\ttraining's auc: 0.847001\tvalid_1's auc: 0.839048\n",
      "[188]\ttraining's auc: 0.84703\tvalid_1's auc: 0.839061\n",
      "[189]\ttraining's auc: 0.847056\tvalid_1's auc: 0.839061\n",
      "[190]\ttraining's auc: 0.847088\tvalid_1's auc: 0.839054\n",
      "[191]\ttraining's auc: 0.847116\tvalid_1's auc: 0.839065\n",
      "[192]\ttraining's auc: 0.847137\tvalid_1's auc: 0.839047\n",
      "[193]\ttraining's auc: 0.847168\tvalid_1's auc: 0.83912\n",
      "[194]\ttraining's auc: 0.847197\tvalid_1's auc: 0.839106\n",
      "[195]\ttraining's auc: 0.847257\tvalid_1's auc: 0.838993\n",
      "[196]\ttraining's auc: 0.847283\tvalid_1's auc: 0.83895\n",
      "[197]\ttraining's auc: 0.847303\tvalid_1's auc: 0.83895\n",
      "[198]\ttraining's auc: 0.847325\tvalid_1's auc: 0.83897\n",
      "[199]\ttraining's auc: 0.847345\tvalid_1's auc: 0.838991\n",
      "[200]\ttraining's auc: 0.847384\tvalid_1's auc: 0.839004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[193]\ttraining's auc: 0.847168\tvalid_1's auc: 0.83912\n",
      "Fold 4 VALID AUC : 0.8391200968280228 ACC : 0.7551839464882943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params={'objective': 'binary', \n",
    "        'metric': ['auc'],\n",
    "        'device':'cpu',\n",
    "        'num_boost_round':200, \n",
    "        'early_stopping_rounds':20\n",
    "        }\n",
    "\n",
    "n_fold=5\n",
    "sfcv=StratifiedGroupKFold(n_splits=n_fold)\n",
    "oof_auc = np.zeros(n_fold)\n",
    "oof_acc = np.zeros(n_fold)\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "for i , (train_idx, val_idx) in enumerate(sfcv.split(X, y, g)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid = X.iloc[val_idx]\n",
    "    X_valid = X_valid[X_valid['userID'] != X_valid['userID'].shift(-1)]\n",
    "    y_valid = X_valid[\"answerCode\"]\n",
    "    lgb_train = lgb.Dataset(X_train[feat], y_train, categorical_feature=[\"KnowledgeTag\"])\n",
    "    lgb_valid = lgb.Dataset(X_valid[feat], y_valid, categorical_feature=[\"KnowledgeTag\"])\n",
    "    wandb.init(project=\"dkt\", config=params)\n",
    "    wandb.run.name = \"fold\"+str(i)+\"lgbm\"\n",
    "    model = lgb.train(\n",
    "                    params, \n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_valid], \n",
    "                    callbacks=[wandb_callback(), lgb.log_evaluation()],\n",
    "                    categorical_feature=[\"KnowledgeTag\"]\n",
    "                    )\n",
    "    #log_summary(model, save_model_checkpoint=True)\n",
    "    #wandb.finish()\n",
    "    preds = model.predict(X_valid[feat])\n",
    "    oof_acc[i] = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "    oof_auc[i] = roc_auc_score(y_valid, preds)\n",
    "    \n",
    "    test_preds+=model.predict(test)/n_fold\n",
    "    \n",
    "    print(f'Fold {i} VALID AUC : {oof_auc[i]} ACC : {oof_acc[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8337498803325818, 0.7556318614774629)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_auc), np.mean(oof_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/2024-01-18 23:16:09 lgbm submission.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, datetime.now(timezone(timedelta(hours=9))).strftime(\"%Y-%m-%d %H:%M:%S\")+\" lgbm submission.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(test_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
