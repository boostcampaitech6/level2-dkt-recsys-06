{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경설정\n",
    "\n",
    "1. 위치\\\n",
    "level2-dkt-recsys-06/code/dkt\n",
    "\n",
    "2. 사용파일: FE_v2.0.csv\\\n",
    "    파일 업데이트 되면 args_total에 컬럼 추가해줘야 합니다\n",
    "\n",
    "3. 데이터를 사전에 로드해놓고, 필요한 feature를 그때그때 slicing만 하는 방식으로 작동\n",
    "\n",
    "3. args에 설명\n",
    "\n",
    "    - feats: 사용할 feature들 전체 목록\n",
    "\n",
    "    - base_feats: 무조건 들어가는 feature들\n",
    "    - base_cat_feats: 무조건 들어가는 범주형 feature들\n",
    "\n",
    "    - new_num_feats: 실험할 ***수치형*** feature들 (반드시 2개 이상 넣어야 합니다)\n",
    "    - new_cat_feats: 실험할 ***범주형*** feature들\n",
    "\n",
    "\n",
    "        1) args_total: 전체 변수들 미리 로드 용\n",
    "        2) args_1, arg_2로 비교\n",
    "\n",
    "> 데이터 불러오기 부터 보시면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from dkt.dkt import trainer\n",
    "# from dkt.dkt.args import parse_args\n",
    "from dkt.dkt.dataloader import Preprocess\n",
    "from dkt.dkt.dataloader import get_loaders\n",
    "from dkt.dkt.utils import get_logger, set_seeds, logging_conf\n",
    "from dkt.dkt.optimizer import get_optimizer\n",
    "from dkt.dkt.scheduler import get_scheduler\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logger = get_logger(logging_conf)\n",
    "korea = pytz.timezone('Asia/Seoul')\n",
    "current_time = datetime.now(korea).strftime(\"%m-%d %H:%M\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    # Create a Namespace instance\n",
    "    args = argparse.Namespace()\n",
    "\n",
    "    # Manually assign values to the attributes\n",
    "    args.seed = 42\n",
    "    args.device = \"cpu\"\n",
    "    args.data_dir = \"/data/ephemeral/home/level2-dkt-recsys-06/data/\"\n",
    "    args.asset_dir = \"asset/\"\n",
    "    args.file_name = \"FE_v2.0.csv\"\n",
    "    args.model_dir = \"models/\"\n",
    "    args.model_name = \"best_model.pt\"\n",
    "    args.output_dir = \"../submit/\"\n",
    "    args.test_file_name = \"test_data.csv\"\n",
    "    args.max_seq_len = 20\n",
    "    args.num_workers = 1\n",
    "    args.hidden_dim = 64\n",
    "    args.n_layers = 2\n",
    "    args.n_heads = 2\n",
    "    args.drop_out = 0.2\n",
    "    args.n_epochs = 20\n",
    "    args.batch_size = 64\n",
    "    args.lr = 0.0001\n",
    "    args.clip_grad = 10\n",
    "    args.patience = 5\n",
    "    args.log_steps = 50\n",
    "    args.model = \"lstm\"\n",
    "    args.optimizer = \"adam\"\n",
    "    args.scheduler = \"plateau\"\n",
    "    args.submission_name = \"dkt_submission.csv\"\n",
    "    args.base_num_feats = []\n",
    "    args.base_cat_feats = [\"userID\", \"assessmentItemID\", \"testId\", \"answerCode\", \"KnowledgeTag\"]\n",
    "\n",
    "    args.n_questions = len(\n",
    "            np.load(os.path.join(args.asset_dir, \"assessmentItemID_classes.npy\"))\n",
    "        )\n",
    "    args.n_tests = len(\n",
    "            np.load(os.path.join(args.asset_dir, \"testId_classes.npy\"))\n",
    "        )\n",
    "    args.n_tags = len(\n",
    "            np.load(os.path.join(args.asset_dir, \"KnowledgeTag_classes.npy\"))\n",
    "        )\n",
    "\n",
    "    args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, args):    \n",
    "    # argument update\n",
    "    args.num_feats = args.base_num_feats + args.new_num_feats\n",
    "    args.cat_feats = args.base_cat_feats + args.new_cat_feats\n",
    "    args.feats = args.cat_feats + args.num_feats\n",
    "    args.n_cat_feats = []\n",
    "    for cat in args.new_cat_feats:    \n",
    "        if args.n_cat_feats:\n",
    "            args.n_cat_feats.append(df[cat].nunique())\n",
    "        else:\n",
    "            args.n_cat_feats = [df[cat].nunique()]\n",
    "    set_seeds(args.seed)\n",
    "\n",
    "\n",
    "    print(\"loading data...\")\n",
    "\n",
    "    # 최종 피처선택\n",
    "    temp = df.copy()\n",
    "    columns = args.feats\n",
    "    print(f\"-----------------------\\ncolumns:{columns}\\n------------------------\")\n",
    "    group = (\n",
    "        temp[args.feats]\n",
    "        .groupby(\"userID\")\n",
    "        .apply(lambda r: tuple([r[col].values for col in columns[1:]]))\n",
    "    ).values\n",
    "\n",
    "    train_data = group\n",
    "\n",
    "    print(\"preprocessing...\")\n",
    "    train_data, valid_data = preprocess.split_data(data=train_data)\n",
    "    train_loader, valid_loader = get_loaders(\n",
    "        args=args, train=train_data, valid=valid_data\n",
    "    )\n",
    "    model: torch.nn.Module = trainer.get_model(args=args).to(args.device)\n",
    "    optimizer = get_optimizer(model=model, args=args)\n",
    "    scheduler = get_scheduler(optimizer=optimizer, args=args)\n",
    "\n",
    "    print(\"training\")\n",
    "    train_loss, train_auc, train_acc, val_auc, val_acc, val_loss = (\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "    for epoch in range(args.n_epochs):\n",
    "        t_auc, t_acc, t_loss = trainer.train(\n",
    "            train_loader=train_loader,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            args=args,\n",
    "        )\n",
    "        train_auc.append(t_auc)\n",
    "        train_acc.append(t_acc)\n",
    "        train_loss.append(t_loss.detach().cpu())\n",
    "\n",
    "        v_auc, v_acc, v_loss = trainer.validate(\n",
    "            valid_loader=valid_loader, model=model, args=args\n",
    "        )\n",
    "        val_auc.append(v_auc)\n",
    "        val_acc.append(v_acc)\n",
    "        val_loss.append(v_loss.detach().cpu())\n",
    "\n",
    "        # if (epoch <= 5) or (epoch % 5 ==0):\n",
    "        #     print(f'{epoch+1}th epoch finished')\n",
    "        #     print(f'train auc:{t_auc}, acc:{t_acc}, loss:{t_loss}')\n",
    "        #     print(f'VAL   auc:{v_auc}, acc:{v_acc}, loss:{v_loss}')\n",
    "\n",
    "    metrics = {\n",
    "        \"train_auc\": train_auc,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_auc\": val_auc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_loss\": val_loss\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 데이터 불러오기\n",
    "\n",
    "- 여기서 전체 컬럼들 목록 분류해서 넣어야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_total = parse_args()\n",
    "\n",
    "args_total.new_cat_feats = ['Month', 'DayOfWeek', 'TimeOfDay']\n",
    "args_total.new_num_feats = ['SolvingTime', 'CumulativeTime''problems_cumulative', 'problems_last7days', 'problems_last30days',\n",
    "       'same_tag_last7days', 'same_tag_last30days', 'same_tag_cumulative','UserCumulativeAnswerRate', 'TagAnswerRate', 'UserAnswerRate',\n",
    "       'ItemAnswerRate', 'TestAnswerRate', 'C_SolvingTime', 'C_ItemAnswerRate',\n",
    "       'C_TagAnswerRate', 'C_TestAnswerRate']\n",
    "\n",
    "args_total.num_feats = args_total.base_num_feats + args_total.new_num_feats\n",
    "args_total.cat_feats = args_total.base_cat_feats + args_total.new_cat_feats\n",
    "args_total.feats = args_total.cat_feats + args_total.num_feats\n",
    "args_total.n_cat_feats = []\n",
    "\n",
    "csv_file_path = os.path.join(args_total.data_dir, args_total.file_name)\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "for cat in args_total.new_cat_feats:    \n",
    "    if args_total.n_cat_feats:\n",
    "        args_total.n_cat_feats.append(df[cat].nunique())\n",
    "    else:\n",
    "        args_total.n_cat_feats = [df[cat].nunique()]\n",
    "\n",
    "preprocess = Preprocess(args_total)\n",
    "df = preprocess._Preprocess__preprocessing(df, is_train=True)  # 범주형 전처리\n",
    "df = df.sort_values(by=[\"userID\", \"Timestamp\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 실험 feature 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수 정하기\n",
    "args1 = parse_args()\n",
    "args2 = parse_args()\n",
    "\n",
    "# featue 목록 1\n",
    "args1.new_cat_feats = []\n",
    "args1.new_num_feats = []\n",
    "\n",
    "# feature 목록 2\n",
    "args2.new_cat_feats = ['DayOfWeek']\n",
    "args2.new_num_feats = ['problems_cumulative','problems_last7days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = train(args=args1, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = train(args=args2, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(20,8), sharex=True)\n",
    "\n",
    "for i, (key,value) in enumerate(metrics_1.items()):\n",
    "        \n",
    "        row, col = int(i%3), i//3\n",
    "\n",
    "        axes[col,row].plot(metrics_1[key], linewidth=5, color='red', label='args 1')\n",
    "        axes[col,row].plot(metrics_2[key], linewidth=5, color='blue', label='args 2')\n",
    "\n",
    "        axes[col,row].set_title(key, fontsize=30)\n",
    "\n",
    "        axes[col,row].legend(loc='right', fontsize=20)\n",
    "        axes[col,row].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"args 1 auc:{metrics_1['val_auc'][-5:]}\")\n",
    "print(f\"args 2 auc:{metrics_2['val_auc'][-5:]}\", end='\\n\\n')\n",
    "\n",
    "print(f\"args 1 acc:{metrics_1['val_acc'][-5:]}\")\n",
    "print(f\"args 2 acc:{metrics_2['val_acc'][-5:]}\", end='\\n\\n')\n",
    "\n",
    "print(f\"args 1 loss:{metrics_1['val_loss'][-5:]}\")\n",
    "print(f\"args 2 loss:{metrics_2['val_loss'][-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
