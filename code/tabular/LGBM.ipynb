{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M_tLPVXsMpJZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import argparse\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "import xgboost as XG\n",
        "from lightgbm import LGBMClassifier\n",
        "import optuna\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "fe=\"Y\" # train시 valid set 쓸건지 안쓸건지 안 쓸꺼면 --fe N\n",
        "trials=10 #랜덤 조합으로 몇번\n",
        "    \n",
        "\n",
        "## EDA 바뀔시 ##\n",
        "file_name=\"FE_v7.csv\"\n",
        "\n",
        "cat_feats=['userID', 'assessmentItemID', 'testId', \n",
        "       'KnowledgeTag', \n",
        "       #'Itemseq', 'SolvingTime', 'CumulativeTime', \n",
        "       'Month',\n",
        "       'DayOfWeek', 'TimeOfDay', 'WeekOfYear', \n",
        "       #'UserAvgSolvingTime',\n",
        "       #'CumulativeItemCount', 'Item_last7days', 'Item_last30days',\n",
        "       #'PastItemCount', 'CumulativeUserItemAnswerRate', 'ItemAnswerRate',\n",
        "       #'AverageItemSolvingTime_Correct', 'AverageItemSolvingTime_Incorrect',\n",
        "       #'AverageItemSolvingTime', 'Difference_SolvingTime_AvgItemSolvingTime',\n",
        "       #'UserTagAvgSolvingTime', 'TagAnswerRate',\n",
        "       #'CumulativeUserTagAverageAnswerRate',\n",
        "       #'CumulativeUserTagExponentialAverage', 'UserCumulativeTagCount',\n",
        "       'UserRecentTagAnswer', 'PreviousItemAnswer', \n",
        "       #'TestAnswerRate',\n",
        "       #'categorize_solvingTime', \n",
        "       'categorize_ItemAnswerRate', \n",
        "       'categorize_TagAnswerRate', 'categorize_TestAnswerRate',\n",
        "       'categorize_CumulativeUserItemAnswerRate',\n",
        "       #'categorize_CumulativeUserTagAverageAnswerRate',\n",
        "       'categorize_CumulativeUserTagExponentialAverage'\n",
        "                                                \n",
        "    ]\n",
        "\n",
        "## 일반 ##\n",
        "n_fold =5\n",
        "seed = 42\n",
        "data_dir =\"../../data/\"\n",
        "model_dir =\"model/\"\n",
        "model_name =\"best_model.pt\"\n",
        "output_dir =\"submit/\"\n",
        "test_file_name =\"test_data.csv\"\n",
        "\n",
        "def set_seeds(seed: int = 42):\n",
        "    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, train: pd.DataFrame):\n",
        "        self.train = train\n",
        "\n",
        "    def restruct_data(self) -> dict:\n",
        "        # train과 test 분할\n",
        "        data = {}\n",
        "        df = self.train\n",
        "        train = df[df[\"answerCode\"] >= 0]\n",
        "        test = df[df[\"answerCode\"] == -1]\n",
        "        data[\"train\"], data[\"test\"] = train, test\n",
        "        return data\n",
        "    \n",
        "    \n",
        "    def split_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        data의 구성\n",
        "        data['train'] : 전체 user_id에 대한 데이터(Test에 있는 User에 대해서는 이미 마지막으로 푼 문제 정보가 없음)\n",
        "        data['train_split'] : 전체 user_id별 마지막으로 푼 문제를 제외한 데이터\n",
        "        data['valid'] : 전체 user_id별 마지막으로 푼 문제에 대한 데이터\n",
        "        \"\"\"\n",
        "        data = self.restruct_data()\n",
        "        FE_train= type_conversion(data[\"train\"])\n",
        "        \n",
        "        train = data['train'].copy()\n",
        "        train[\"is_valid\"] = [False] * train.shape[0]\n",
        "        idx_last = train.drop_duplicates(subset=\"userID\", keep=\"last\").index\n",
        "        train.loc[idx_last, \"is_valid\"] = True\n",
        "\n",
        "        train, valid = train[train[\"is_valid\"] == False], train[train[\"is_valid\"] == True]\n",
        "        data['train'] = train.drop(\"is_valid\", axis=1)\n",
        "        data['valid'] = valid.drop(\"is_valid\", axis=1)\n",
        "\n",
        "        print(f'{data[f\"train\"].shape[0]} train data')\n",
        "        print(f'{data[f\"valid\"].shape[0]} valid data')\n",
        "\n",
        "        return data, FE_train\n",
        "\n",
        "def type_conversion(df):\n",
        "        # [FEAT] integer여도 범주형으로 취급 가능\n",
        "        for feature in cat_feats:\n",
        "                df[feature] = df[feature].astype('category')\n",
        "\n",
        "        return df\n",
        "\n",
        "class Preprocess:\n",
        "    def __init__(self, data: dict):\n",
        "        self.data = data\n",
        "\n",
        "    def preprocess(self,cat_feats) -> dict:\n",
        "        self.data[\"train_x\"] = self.data[\"train\"].drop(\"answerCode\", axis=1)\n",
        "        self.data[\"train_y\"] = self.data[\"train\"][\"answerCode\"]\n",
        "\n",
        "        self.data[\"valid_x\"] = self.data[\"valid\"].drop(\"answerCode\", axis=1)\n",
        "        self.data[\"valid_y\"] = self.data[\"valid\"][\"answerCode\"]\n",
        "\n",
        "        self.data[\"test\"] = self.data[\"test\"].drop(\"answerCode\", axis=1)\n",
        "\n",
        "        # as category: integer여도 범주형으로 취급 가능\n",
        "        for state in [\"train_x\", \"valid_x\", \"test\"]:\n",
        "            df = self.data[state]\n",
        "                \n",
        "            for feature in cat_feats:\n",
        "                df[feature] = df[feature].astype('category')\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        return self.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#logger = get_logger(logger_conf=logging_conf)\n",
        "\n",
        "# optuna\n",
        "def objective(trial, FEATURE,data):\n",
        "    params_LGBM = {\n",
        "        'random_state':seed,\n",
        "        #'objective': 'binary', \n",
        "        'metric': 'auc',  # 평가 지표로 AUC 사용\n",
        "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
        "        'n_estimators' : trial.suggest_int('num_round', 1000, 5000),  \n",
        "        \n",
        "        #'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.3),  # 학습 속도\n",
        "    \n",
        "        }\n",
        "    \n",
        "    score = []\n",
        "    bst = LGBMClassifier(**params_LGBM,force_row_wise=True)\n",
        "    bst.fit(X=data['train_x'][FEATURE], y=data['train_y'], eval_set=[(data['valid_x'][FEATURE], data['valid_y'])])\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_proba = bst.predict_proba(data['valid_x'][FEATURE])[:, 1]\n",
        "    y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred_proba]\n",
        "\n",
        "    # Calculate accuracy and AUC\n",
        "    accuracy = accuracy_score(data['valid_y'], y_pred_binary)\n",
        "    auc = roc_auc_score(data['valid_y'], y_pred_proba)\n",
        "\n",
        "    # Print accuracy and AUC\n",
        "    print('Accuracy: {:.4f}'.format(accuracy))\n",
        "    print('AUC: {:.4f}'.format(auc))\n",
        "  \n",
        "    score.append(auc)\n",
        "\n",
        "    # Calculate and print the average AUC score\n",
        "    result = sum(score) / len(score)\n",
        "    print('Average AUC: {:.4f}'.format(result))\n",
        "\n",
        "    return result  # auc 최대화하는 방향으로\n",
        "\n",
        "\n",
        "class boosting_model:\n",
        "    def __init__(self, FEATURE,data):\n",
        "        self.feature = FEATURE\n",
        "        self.data = data\n",
        "        \n",
        "        # Optuna 최적화\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lambda trial: objective(trial,self.feature, self.data), n_trials=trials)\n",
        "\n",
        "        # 최적 하이퍼파라미터 출력\n",
        "        print('Hyperparameters: {}'.format(study.best_params))\n",
        "            \n",
        "        self.model = LGBMClassifier(\n",
        "               **study.best_params, objective = 'binary', metric = 'auc'\n",
        "            )\n",
        "            \n",
        "\n",
        "\n",
        "    def training(self, data, FEATURE,FE_train):\n",
        "        #logger.info(\"###start MODEL training ###\")\n",
        "        #logger.info(self.feature)\n",
        "\n",
        "\n",
        "        if fe == \"N\":\n",
        "            self.model.fit(\n",
        "                    FE_train[FEATURE],\n",
        "                    FE_train[\"answerCode\"],\n",
        "                    categorical_feature=cat_feats\n",
        "                    )\n",
        "        else:\n",
        "            print(\"Valid Data is used while training\")\n",
        "            score = []\n",
        "            self.model.fit(\n",
        "                        data[\"train_x\"][FEATURE],\n",
        "                        data[\"train_y\"],\n",
        "                        eval_set=(data[\"valid_x\"][FEATURE], data['valid_y']),\n",
        "                   force_row_wise=True\n",
        "                    )\n",
        "\n",
        "            # Prediction\n",
        "            y_pred_proba = self.model.predict(data[\"valid_x\"][FEATURE])\n",
        "            y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred_proba]\n",
        "\n",
        "            # Calculate accuracy and AUC\n",
        "            accuracy = accuracy_score(data['valid_y'], y_pred_binary)\n",
        "            auc = roc_auc_score(data['valid_y'], y_pred_proba)\n",
        "            print('Accuracy: {:.4f}'.format(accuracy))\n",
        "            print('AUC: {:.4f}'.format(auc))\n",
        "\n",
        "            # Append the AUC score to the list\n",
        "            score.append(auc)\n",
        "\n",
        "            # Calculate and print the average AUC score\n",
        "            result = sum(score) / len(score)\n",
        "            print('Average AUC: {:.4f}'.format(result))\n",
        "            model_type = 'LGBM' \n",
        "     \n",
        "        \n",
        "        get_feature_importance(self.model, FEATURE, model_type)    \n",
        "\n",
        "\n",
        "    def inference(self, data,save_time,model_type,output_dir):\n",
        "        # submission 제출하기 위한 코드\n",
        "        #test_pred = self.model.predict(data[\"test\"][self.feature])\n",
        "        test_pred = self.model.predict_proba(data[\"test\"][self.feature])[:, 1]\n",
        "\n",
        "        data[\"test\"][\"prediction\"] = test_pred\n",
        "        submission = data[\"test\"][\"prediction\"].reset_index(drop=True).reset_index()\n",
        "        submission.rename(columns={\"index\": \"id\"}, inplace=True)\n",
        "        submission_filename = f\"{model_type}_{save_time}.csv\"\n",
        "        submission.to_csv(\n",
        "            os.path.join(output_dir, submission_filename), index=False\n",
        "        )\n",
        "\n",
        "\n",
        "def get_feature_importance(model, feature_names, model_type):\n",
        "        importance = model.feature_importances_\n",
        "\n",
        "        feature_importance = np.array(importance)\n",
        "        feature_names = np.array(feature_names)\n",
        "    \n",
        "        # DataFrame 생성하고 정렬\n",
        "        fi_df = pd.DataFrame({'Feature Names': feature_names, 'Feature Importance': feature_importance})\n",
        "        fi_df = fi_df.sort_values(by='Feature Importance', ascending=False)\n",
        "\n",
        "        # Print the results\n",
        "        print(f\"{model_type} Feature Importance:\")\n",
        "        print(fi_df)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### DATA LOAD ###\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2518514 train data\n",
            "7442 valid data\n",
            "### DATA PREPROCESSING ###\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-01-23 07:02:38,617] A new study created in memory with name: no-name-37c39a8d-3625-4953-a8f7-280bd84df356\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### HYPER PARAMETER TUNING - USING OPTUNA ###\n",
            "number of selected features: 29\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 1649969, number of negative: 868545\n",
            "[LightGBM] [Info] Total Bins 20308\n",
            "[LightGBM] [Info] Number of data points in the train set: 2518514, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655136 -> initscore=0.641692\n",
            "[LightGBM] [Info] Start training from score 0.641692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2024-01-23 07:16:41,130] Trial 0 failed with parameters: {'boosting_type': 'gbdt', 'num_round': 4885, 'learning_rate': 0.007762430289977601} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_1410537/2023225261.py\", line 48, in <lambda>\n",
            "    study.optimize(lambda trial: objective(trial,self.feature, self.data), n_trials=trials)\n",
            "  File \"/tmp/ipykernel_1410537/2023225261.py\", line 18, in objective\n",
            "    bst.fit(X=data['train_x'][FEATURE], y=data['train_y'], eval_set=[(data['valid_x'][FEATURE], data['valid_y'])])\n",
            "  File \"/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1187, in fit\n",
            "    super().fit(\n",
            "  File \"/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/engine.py\", line 276, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"/opt/ml/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/basic.py\", line 3891, in update\n",
            "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-01-23 07:16:41,133] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(model_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[5], line 71\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of selected features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(FEATURE))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#wandb.init(project=\"level2-dkt\", config=vars(), entity=\"boostcamp6-recsys6\")\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#wandb.run.name = \"yechance\" + current_time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#wandb.run.save()\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#logger.info(\"Building Model ...\")\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mboosting_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFEATURE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m######################## TRAIN\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### TRAIN ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mboosting_model.__init__\u001b[0;34m(self, FEATURE, data)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Optuna 최적화\u001b[39;00m\n\u001b[1;32m     47\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 최적 하이퍼파라미터 출력\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHyperparameters: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_params))\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mboosting_model.__init__.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Optuna 최적화\u001b[39;00m\n\u001b[1;32m     47\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mtrials)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 최적 하이퍼파라미터 출력\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHyperparameters: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_params))\n",
            "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, FEATURE, data)\u001b[0m\n\u001b[1;32m     16\u001b[0m score \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m bst \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_LGBM,force_row_wise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Predict on the validation set\u001b[39;00m\n\u001b[1;32m     21\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict_proba(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_x\u001b[39m\u001b[38;5;124m'\u001b[39m][FEATURE])[:, \u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/dkt/lib/python3.10/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# python main.py --model    # CAT, XG, LGBM   default=\"CAT\", \n",
        "\n",
        "# Boosting 계열, 수정할수 있는 파라미터\n",
        "# 1. FEATURE 선택\n",
        "# 2. train시 valid set 쓸건지 안쓸건지, default: Y\n",
        "# 3. optuna 시도 횟수, default: n_trials=10, 보통 100번이상이면 수렴됨\n",
        "# 4. optuna params\n",
        "\n",
        "#logger = get_logger(logger_conf=logging_conf)\n",
        "\n",
        "\n",
        "def main():\n",
        "    ######################## SELECT FEATURE\n",
        "    FEATURE = ['userID', 'assessmentItemID', 'testId', \n",
        "       'KnowledgeTag', 'Itemseq', 'SolvingTime', 'CumulativeTime', 'Month',\n",
        "       'DayOfWeek', 'TimeOfDay', 'WeekOfYear', 'UserAvgSolvingTime',\n",
        "       'CumulativeItemCount', 'Item_last7days', 'Item_last30days',\n",
        "       'PastItemCount', \n",
        "       #'CumulativeUserItemAnswerRate', 'ItemAnswerRate',\n",
        "       'AverageItemSolvingTime_Correct', 'AverageItemSolvingTime_Incorrect',\n",
        "       'AverageItemSolvingTime', 'Difference_SolvingTime_AvgItemSolvingTime',\n",
        "       'UserTagAvgSolvingTime', \n",
        "       #'TagAnswerRate',\n",
        "       #'CumulativeUserTagAverageAnswerRate',\n",
        "       #'CumulativeUserTagExponentialAverage', \n",
        "       'UserCumulativeTagCount',\n",
        "       'UserRecentTagAnswer', 'PreviousItemAnswer', \n",
        "       #'TestAnswerRate',\n",
        "       #'categorize_solvingTime', \n",
        "       'categorize_ItemAnswerRate',\n",
        "       'categorize_TagAnswerRate', 'categorize_TestAnswerRate',\n",
        "       'categorize_CumulativeUserItemAnswerRate',\n",
        "       #'categorize_CumulativeUserTagAverageAnswerRate',\n",
        "       'categorize_CumulativeUserTagExponentialAverage'\n",
        "    ]\n",
        "    #wandb.login()\n",
        "\n",
        "    set_seeds(seed)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Time\n",
        "    korea_timezone = pytz.timezone('Asia/Seoul')\n",
        "    now_korea = datetime.now(korea_timezone)\n",
        "    now_date = now_korea.strftime('%Y%m%d')\n",
        "    now_hour = now_korea.strftime('%H%M%S')\n",
        "    save_time = f\"{now_date}_{now_hour}\"\n",
        "    \n",
        "\n",
        "    ######################## DATA LOAD\n",
        "    print(\"### DATA LOAD ###\")\n",
        "    #logger.info(\"Loading data ...\")\n",
        "    train = pd.read_csv(data_dir + 'FE_v7.csv')\n",
        "\n",
        "    data = Dataset(train)\n",
        "    data, FE_train = data.split_data()\n",
        "\n",
        "    ######################## DATA PREPROCESSING\n",
        "    print(\"### DATA PREPROCESSING ###\")\n",
        "    #logger.info(\"Preparing data ...\")\n",
        "    process = Preprocess(data)\n",
        "    data = process.preprocess(cat_feats)\n",
        "\n",
        "    ######################## HYPER PARAMETER TUNING - USING OPTUNA\n",
        "    print(\"### HYPER PARAMETER TUNING - USING OPTUNA ###\")\n",
        "    print(\"number of selected features:\", len(FEATURE))\n",
        "    #wandb.init(project=\"level2-dkt\", config=vars(), entity=\"boostcamp6-recsys6\")\n",
        "    #wandb.run.name = \"yechance\" + current_time\n",
        "    #wandb.run.save()\n",
        "\n",
        "    #logger.info(\"Building Model ...\")\n",
        "    model = boosting_model(FEATURE, data)\n",
        "\n",
        "    ######################## TRAIN\n",
        "    print(\"### TRAIN ###\")\n",
        "    #logger.info(\"Start Training ...\")\n",
        "    model.training(data, FEATURE,FE_train)\n",
        "    \n",
        "    ######################## INFERENCE\n",
        "    print(\"### INFERENCE ###\")\n",
        "    #logger.info(\"\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    model_type = 'LGBM' \n",
        "    model.inference(data,save_time,model_type,output_dir)\n",
        "\n",
        "    print( model_type + \"_\" + save_time + \" submission file has been made\" )\n",
        "    #wandb.finish()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
